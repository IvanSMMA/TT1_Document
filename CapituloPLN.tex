\chapter{Implementación del Modulo de PLN}
\section{Arquitectura del modulo de Procesamiento de Lenguaje Natural (PLN)}

{\textbf{Visión general de la arquitectura}}

El sistema implementa una arquitectura de microservicios basada en capas, siguiendo los principios de separación de responsabilidades y modularidad. La arquitectura se compone de cuatro capas principales:

La arquitectura implementa los siguientes principios esenciales:\\

\begin{itemize}
    \item \textbf{\textit{Single Responsibility}}: Cada módulo tiene una única responsabilidad claramente definida.
    \item \textbf{\textit{Dependency Injection}}: El matcher se inicializa con configuración externa.
    \item \textbf{\textit{Separation of Concerns}}: Separación entre API, lógica interna y gestión de datos.
    \item \textbf{\textit{Caching}}: Uso de un sistema de cache para \textit{embeddings} que optimiza el rendimiento.
    \item \textbf{\textit{Stateless API}}: La API no mantiene estado entre peticiones consecutivas.
    \item \textbf{\textit{Asynchronous Processing}}: Uso de \texttt{async/await} para operaciones de I/O.
\end{itemize}

\begin{center}
    \includegraphics[width=0.95\textwidth]{Images/Cap4/1_ArquitecturaPLN.png}
    \captionof{figure}[Arquitectura del Modulo PLN]{Arquitectura del Modulo de PLN, elaboración propia.} 
\end{center}

\newpage
\subsection{Componentes principales}

El sistema se compone de cuatro módulos principales, cada uno con funciones específicas:\\

\noindent \textbf{1. API REST (app/main.py) -- 665 líneas}

\paragraph{Responsabilidad}
\begin{itemize}
    \item Exposición de \textit{endpoints} HTTP.
    \item Validación de \textit{requests} mediante Pydantic \cite{refimpl1}.
    \item Manejo centralizado de errores y excepciones.
    \item Generación automática de documentación (OpenAPI).
    \item Registro de \textit{logs} de operación.
\end{itemize}

\paragraph{Endpoints implementados}
\begin{itemize}
    \item \texttt{POST /buscar} \hfill Búsqueda semántica principal.
    \item \texttt{GET /grupos} \hfill Listado de grupos disponibles.
    \item \texttt{GET /grupos/\{grupo\}} \hfill Frases de un grupo específico.
    \item \texttt{POST /deletreo} \hfill Deletreo manual de texto.
    \item \texttt{GET /health} \hfill Verificación del estado del servicio.
    \item \texttt{GET /stats} \hfill Estadísticas del sistema.
    \item \texttt{GET /docs} \hfill Documentación mediante Swagger UI.
\end{itemize}

\paragraph{Tecnologías utilizadas}
\begin{itemize}
    \item FastAPI 0.104.1 \cite{refimpl2}. 
    \item Uvicorn (servidor ASGI) \cite{refimpl3}.
    \item Pydantic 2.0+ (validación de datos) \cite{refimpl1}.
\end{itemize}

\vspace{0.7em}

\newpage
\noindent \textbf{2. Motor de Búsqueda (app/matcher\_improved.py) -- 681 líneas}

\paragraph{Responsabilidad}
\begin{itemize}
    \item Generación de \textit{embeddings} semánticos.
    \item Búsqueda jerárquica con \textit{re-ranking}.
    \item Detección de patrones con nombres propios.
    \item Cálculo de similitud mediante coseno \cite{refcos1}.
    \item Sistema automático de deletreo en casos especiales.
    \item Gestión del cache de \textit{embeddings}.
\end{itemize}

\paragraph{Clases principales}
\begin{itemize}
    \item \texttt{ImprovedPhraseMatcher}: clase principal que implementa todo el motor de búsqueda.
\end{itemize}

\paragraph{Métodos clave}
\begin{itemize}
    \item \texttt{initialize()} \hfill Carga del modelo y los \textit{embeddings}.
    \item \texttt{search\_similar\_phrase()} \hfill Método principal de búsqueda.
    \item \texttt{\_extract\_name\_pattern()} \hfill Detección y extracción de nombres propios.
    \item \texttt{find\_most\_similar\_phrase\_reranked()} \hfill \textit{Re-ranking} en dos fases.
    \item \texttt{find\_best\_groups()} \hfill Búsqueda inicial por centroides.
\end{itemize}

\paragraph{Características avanzadas}
\begin{itemize}
    \item \textit{Thresholds} adaptativos por grupo.
    \item Aumento de similitud basado en la longitud de frase (+8\% a +15\%).
    \item Penalización por diferencia de longitud (-5\% por carácter adicional).
    \item Detección de más de 40 nombres comunes en español.
    \item Normalización integrada de \textit{leet speak}.
\end{itemize}

\vspace{0.7em}

\newpage
\noindent \textbf{3. Preprocesamiento (app/preprocess.py) -- 244 líneas}

\paragraph{Responsabilidad}
\begin{itemize}
    \item Normalización de texto: minúsculas, acentos, puntuación y espacios.
    \item Corrección ortográfica ligera utilizando \textit{RapidFuzz} \cite{refimpl4}.
    \item Normalización de \textit{leet speak} (por ejemplo, \texttt{@ → a}, \texttt{3 → e}) \cite{refimpl5}.
    \item Sistema de deletreo letra por letra.
    \item Manejo y detección de caracteres especiales.
\end{itemize}

\paragraph{Funciones principales}
\begin{itemize}
    \item \texttt{normalize\_text()} \hfill Normalización base del texto.
    \item \texttt{preprocess\_query()} \hfill Preprocesamiento de consultas del usuario.
    \item \texttt{preprocess\_phrases()} \hfill Preprocesamiento del \textit{dataset} completo.
    \item \texttt{normalize\_leet\_speak()} \hfill Conversión de texto en \textit{leet speak}.
    \item \texttt{spell\_out\_text()} \hfill Deletreo literal del texto.
\end{itemize}

\paragraph{\textit{Pipeline} de normalización}
\begin{enumerate}
    \item Conversión del texto a minúsculas.
    \item Eliminación de acentos mediante \texttt{unicodedata.normalize('NFD')}.
    \item Remoción de puntuación no relevante.
    \item Normalización de espacios con expresiones regulares.
    \item Corrección de errores ortográficos comunes usando RapidFuzz \cite{refimpl4}.
    \item Normalización de \textit{leet speak} si aplica \cite{refimpl5}.
\end{enumerate}

\vspace{0.7em}

\noindent \textbf{4. Gestión de Datos (app/groups.py) -- 64 líneas}

\paragraph{Responsabilidad}
\begin{itemize}
    \item Carga del \textit{dataset} desde archivos JSON.
    \item Validación de la estructura esperada.
    \item Provisión de acceso a frases por grupo.
\end{itemize}

\paragraph{\textit{Dataset} actual}
\begin{itemize}
    \item \textbf{Grupo A (Emergencias)}: 13 frases.
    \item \textbf{Grupo B (Saludos)}: 13 frases.
    \item \textbf{Grupo C (Comunicación)}: 17 frases.
    \item \textbf{Total}: 43 frases.
\end{itemize}

\paragraph{Funciones disponibles}
\begin{itemize}
    \item \texttt{load\_groups()} \hfill Carga los grupos desde JSON.
    \item \texttt{get\_all\_phrases()} \hfill Retorna todas las frases del dataset.
    \item \texttt{get\_group\_phrases()} \hfill Retorna frases de un grupo específico.
\end{itemize}

\subsection{Flujo de Datos}

El flujo de datos del sistema sigue una secuencia bien definida que abarca validación, preprocesamiento, generación de \textit{embeddings}, búsqueda semántica y construcción de la respuesta final.\\

{\large \noindent \textbf{Flujo principal: Búsqueda semántica}}

\begin{enumerate}
    \item \textbf{Entrada de usuario} \\
    $\downarrow$ \\
    El usuario envía el texto: ``mi nombre es Alessandro''. \\
    $\downarrow$ \\
    \texttt{POST /buscar} \\
    \textbf{\textit{Body}}: \texttt{\{"texto": "mi nombre es Pedro"\}}
    
    \item \textbf{Validación (API Layer)} \\
    $\downarrow$
    \begin{itemize}
        \item Validación de \textit{request} mediante Pydantic, también se considera la validación del número máximo de caracteres por entrada de usuario que es de 50 esto con cumplimiento de la regla de negocio RN02 (ver \textbf{\autoref{tab:reglas_negocio}}).
        \item Verificación de texto no vacío.
        \item Registro en \textit{logs} del request recibido.
    \end{itemize}

    \item \textbf{Preprocesamiento (\textit{Preprocessing Layer})} \\
    $\downarrow$ \\
    \textit{Input}: ``mi nombre es Pedro''. \\
    $\downarrow$ \\
    \texttt{normalize\_text()} \\
    $\downarrow$ \\
    \textit{Output}: ``mi nombre es pedro.''

    \item \textbf{Generación de \textit{embedding} (ML Layer)} \\
    $\downarrow$ \\
    \textit{Input}: ``mi nombre es pedro.'' \\
    $\downarrow$ \\
    \texttt{SentenceTransformer.encode()} \\
    $\downarrow$ \\
    \textit{Output}: vector de 384 dimensiones.

    \item \textbf{Búsqueda jerárquica (\textit{Matching Layer})}

    \begin{itemize}
        \item \textbf{Fase 1: Búsqueda por centroides} \\
        $\downarrow$
        \begin{itemize}
            \item Cálculo de similitud con centroides de grupos A, B y C.
            \item Selección de top-3 grupos candidatos.
        \end{itemize}
        Resultado: \texttt{[B: 0.92,\ C: 0.78,\ A: 0.65]}
        
        \item \textbf{Fase 2: \textit{Re-ranking fino}} \\
        $\downarrow$
        \begin{itemize}
            \item Comparación en frases de grupos candidatos.
            \item Aplicación de \textit{boost} por longitud (+8\% a +15\%).
            \item Penalización por diferencia de longitud.
        \end{itemize}
        Resultado: mejor match = ``Me llamo'' (Grupo B, similitud = 0.8599).
    \end{itemize}

    \item \textbf{Detección de patrones especiales (\textit{Pattern Detection})} \\
    $\downarrow$\\
    \texttt{\_extract\_name\_pattern()} \\
    $\downarrow$
    \begin{itemize}
        \item Detección del patrón ``mi nombre es [X]''.
        \item Extracción del nombre ``Pedro''.
        \item Normalización de \textit{leet speak} si aplica.
        \item Deletreo resultante: \texttt{[P,\ E,\ D,\ R,\ O]}.
    \end{itemize}

    \newpage
    \item \textbf{Construcción de respuesta (\textit{Response Builder})} \\
    $\downarrow$ 

\begin{lstlisting}
{
  "query": "mi nombre es Pedro",
  "grupo": "B",
  "frase_similar": "Me llamo",
  "similitud": 0.8599,
  "deletreo_activado": false,
  "nombre_detectado": true,
  "nombre_extraido": "Pedro",
  "nombre_deletreado": ["P","E","D","R","O"],
  "total_caracteres_nombre": 5
}
\end{lstlisting}

    \item \textbf{Respuesta al cliente} \\
    $\downarrow$ \\
    \texttt{HTTP 200 OK} \\
    \texttt{Content-Type: application/json}\\
    \texttt{Response: \{...\}}
\end{enumerate}

% -----------------------------------------------------------
{\large \noindent \textbf{Flujo alternativo: Deletreo automático}}

Este flujo ocurre cuando la similitud es menor al \textit{threshold} correspondiente al grupo.

\begin{enumerate}
    \item Usuario envía: ``xyz123''. \\
    $\downarrow$

    \item Similitud calculada: $0.45 < 0.80$ (\textit{threshold} Grupo B). \\
    $\downarrow$

    \item Activación del modo de deletreo. \\
    $\downarrow$

    \item \texttt{spell\_out\_text("xyz123")} \\
    $\downarrow$

    \item Resultado: \texttt{["X","Y","Z","1","2","3"]}. \\
    $\downarrow$

\begin{lstlisting}
{
  "deletreo_activado": true,
  "deletreo": ["X","Y","Z","1","2","3"],
  "total_caracteres": 6
}
\end{lstlisting}
\end{enumerate}

% -----------------------------------------------------------
\subsection{Flujo de inicialización del sistema}

\begin{enumerate}
    \item \textit{Startup} del sistema \\
    $\downarrow$ \\
    \texttt{@app.on\_event("startup")}

    \item Carga de datos \\
    $\downarrow$ \\
    \texttt{load\_groups()} $\rightarrow$ lectura de \texttt{grupos.json} \\
    Resultado: 43 frases cargadas.

    \item Inicialización del \textit{matcher} \\
    $\downarrow$ \\
    \texttt{ImprovedPhraseMatcher()}
    \begin{itemize}
        \item Selección del modelo \texttt{MiniLM-L12-v2}.
        \item Configuración de \textit{thresholds} por grupo.
        \item Preparación de lista de nombres comunes.
    \end{itemize}

    \item Verificación de cache \\
    $\downarrow$ \\
    ¿Existe \texttt{embeddings\_improved.npz}? 
    \begin{itemize}
        \item Sí $\rightarrow$ cargar (menos de 1 segundo).
        \item No $\rightarrow$ generar \textit{embeddings} (aprox. 5 segundos).
    \end{itemize}

    \item Carga del modelo de ML \\
    $\downarrow$ \\
    \texttt{SentenceTransformer.load(model\_name)}

    \item Cálculo de centroides \\
    $\downarrow$ \\
    Para cada grupo: \\
    \[
        \text{centroid} = \texttt{mean(embeddings)}
    \]

    \item Sistema listo \\
    $\downarrow$ \\
    Logging: ``\textit{PhraseMatcher} mejorado inicializado correctamente''. \\
    $\downarrow$ \\
    API lista para recibir solicitudes.
\end{enumerate}

\subsection{Patrones de diseño aplicados}

El sistema implementa múltiples patrones de diseño para garantizar mantenibilidad, escalabilidad y robustez \cite{refimpl6}.\\

\noindent \textbf{1. Patrón \textit{Singleton}}

\textbf{Implementación}
\begin{itemize}
    \item Variable global \texttt{matcher} en \texttt{main.py}.
    \item Una sola instancia de \texttt{ImprovedPhraseMatcher}.
    \item Inicialización en el evento \texttt{startup}.
\end{itemize}

\textbf{Código}
\begin{lstlisting}[language=Python,frame=single]
matcher: Optional[ImprovedPhraseMatcher] = None

@app.on_event("startup")
async def startup_event():
    global matcher
    matcher = ImprovedPhraseMatcher()
    matcher.initialize()
\end{lstlisting}

\textbf{Beneficios}
\begin{itemize}
    \item El modelo ML se carga una sola vez.
    \item El caché de \textit{embeddings} es compartido.
    \item Reducción en uso de memoria.
\end{itemize}

\noindent \textbf{2. Patrón \textit{Strategy}}

\textbf{Implementación}
\begin{itemize}
    \item Modelos de \textit{embeddings} intercambiables.
    \item Selección del modelo en tiempo de inicialización.
\end{itemize}

\textbf{Modelos disponibles}
\begin{lstlisting}[language=Python,frame=single]
MODELS = {
    "spanish_optimized": "sentence_similarity_spanish_es",
    "multilingual_advanced": "mpnet-base-v2",
    "multilingual_balanced": "MiniLM-L12-v2",  # DEFAULT
    "current": "all-MiniLM-L6-v2"
}
\end{lstlisting}

\newpage
\textbf{Uso}
\begin{lstlisting}[language=Python,frame=single]
matcher = ImprovedPhraseMatcher(
    model_type="multilingual_balanced"
)
\end{lstlisting}

\textbf{Beneficios}
\begin{itemize}
    \item Cambio de modelo sin modificar la lógica del sistema.
    \item Permite experimentación con distintos modelos.
    \item \textit{Testing} con modelos más ligeros.
\end{itemize}

\vspace{0.7em}
\noindent \textbf{3. Patrón \textit{Template Method}}

\textbf{Implementación}
\begin{itemize}
    \item \texttt{search\_similar\_phrase()} define la estructura general del algoritmo.
    \item Los métodos específicos implementan pasos individuales.
\end{itemize}

\textbf{Estructura}
\begin{lstlisting}[language=Python,frame=single]
def search_similar_phrase(query):
    # 1. Preprocesar
    normalized = preprocess_query(query)

    # 2. Buscar
    if self.use_reranking:
        result = find_most_similar_phrase_reranked()
    else:
        result = find_most_similar_phrase()

    # 3. Validar patrones especiales
    name_info = _extract_name_pattern()

    # 4. Construir respuesta
    return build_response()
\end{lstlisting}

\textbf{Beneficios}
\begin{itemize}
    \item Flujo consistente.
    \item Fácil incorporar nuevos pasos.
    \item Extensible sin duplicar lógica.
\end{itemize}

\newpage
\noindent \textbf{4. Patrón Facade}

\textbf{Implementación}
\begin{itemize}
    \item La API REST sirve como fachada del sistema.
    \item Los \textit{endpoints} ocultan la complejidad interna.
\end{itemize}

\textbf{Ejemplo}
\begin{lstlisting}
POST /buscar
{
    "texto": "hola"
}
\end{lstlisting}

$\downarrow$

Internamente ejecuta:
\begin{itemize}
    \item Validación.
    \item Preprocesamiento.
    \item Generación de \textit{embeddings}.
    \item Búsqueda jerárquica.
    \item Detección de patrones.
    \item Construcción de respuesta.
\end{itemize}

\textbf{Beneficios}
\begin{itemize}
    \item API simple de usar.
    \item Complejidad encapsulada.
    \item Fácil integración con \textit{frontend} o móviles.
\end{itemize}

\newpage
\noindent \textbf{5. Patrón \textit{Dependency Injection}}

\textbf{Implementación}
\begin{itemize}
    \item Configuración inyectada mediante el constructor.
    \item No existen valores \textit{``hardcoded''} en la lógica.
\end{itemize}

\textbf{Código}
\begin{lstlisting}[language=Python,frame=single]
def __init__(
    self,
    model_type: str = "multilingual_balanced",
    cache_path: str = "data/embeddings_improved.npz",
    use_reranking: bool = True,
    use_synonym_expansion: bool = True
):
    self.model_name = self.MODELS[model_type]
    self.cache_path = cache_path
    self.use_reranking = use_reranking
\end{lstlisting}

\textbf{Beneficios}
\begin{itemize}
    \item Facilita el \textit{testing} (\textit{mock} de dependencias).
    \item Configurable externamente.
    \item Mayor flexibilidad.
\end{itemize}

\noindent \textbf{6. Patrón \textit{Cache / Lazy Loading}}

\textbf{Implementación}
\begin{itemize}
    \item \textit{Embeddings} almacenados en caché en archivos \texttt{.npz}.
    \item El modelo ML se carga solo cuando es necesario.
\end{itemize}

\textbf{Caché de \textit{embeddings}}
\begin{lstlisting}[language=Python,frame=single]
def initialize():
    if os.path.exists(cache_path):
        # Cargar desde cache (< 1 seg)
        pass
    else:
        # Generar y guardar (~ 5 seg)
        embeddings = self._generate_embeddings()
        np.savez(cache_path, ...)
\end{lstlisting}

\textbf{\textit{Lazy Loading} del modelo}
\begin{lstlisting}[language=Python,frame=single]
def _load_model():
    if self.model is None:
        self.model = SentenceTransformer(model_name)
\end{lstlisting}

\textbf{Beneficios}
\begin{itemize}
    \item Inicio del sistema más rápido.
    \item Ahorro significativo de cómputo.
    \item Eficiencia en recursos.
\end{itemize}

\subsection{Principios SOLID Aplicados}

\textbf{\textit{Single Responsibility Principle} \cite{refimpl7}}
\begin{itemize}
    \item \texttt{main.py}: Manejo de API REST.
    \item \texttt{matcher\_improved.py}: Búsqueda semántica.
    \item \texttt{preprocess.py}: Preprocesamiento de texto.
    \item \texttt{groups.py}: Gestión y carga del \textit{dataset}.
\end{itemize}

\textbf{\textit{Open / Closed Principle} \cite{refimpl7}}
\begin{itemize}
    \item El sistema permite extensión (nuevos modelos, endpoints).
    \item La lógica principal permanece estable (cerrada a modificaciones).
\end{itemize}

\textbf{\textit{Liskov Substitution Principle} \cite{refimpl7}}
\begin{itemize}
    \item Modelos de \textit{embeddings} intercambiables.
    \item Algoritmos de búsqueda reemplazables (básico vs \textit{re-ranking}).
\end{itemize}

\textbf{\textit{Interface Segregation Principle} \cite{refimpl7}}
\begin{itemize}
    \item La API expone solo \textit{endpoints} necesarios.
    \item Métodos internos como \texttt{\_extract\_name\_pattern} permanecen privados.
\end{itemize}

\textbf{\textit{Dependency Inversion Principle} \cite{refimpl7}}
\begin{itemize}
    \item Dependencias inyectadas mediante el constructor.
    \item Uso de abstracciones, no implementaciones directas.
\end{itemize}

\newpage
\section{Tecnologías, lenguajes de programación y herramientas}

\noindent\textbf{Lenguaje de programación: Python 3.12}

\noindent \textbf{Versión utilizada:} Python 3.12.3

\noindent \textbf{Fecha de \textit{release}:} Abril 2024\\

Python 3.12 incorpora mejoras significativas en rendimiento, manejo de tipos y características sintácticas modernas. El proyecto aprovecha varias de estas capacidades \cite{refimpl8}.

\subsection{Características Utilizadas}

\noindent \textbf{1. \textit{Type hints avanzados} (PEP 604)}

Sintaxis moderna con el operador \texttt{|} en lugar de \texttt{Union}.

\textbf{Ejemplo:}
\begin{lstlisting}[language=Python,frame=single]
def search(query: str) -> dict[str, str | float | None]:
    ...
\end{lstlisting}


\noindent \textbf{2. Async / Await nativo}

FastAPI utiliza \texttt{async} para operaciones I/O no bloqueantes.

\textbf{Ejemplo:}
\begin{lstlisting}[language=Python,frame=single]
@app.post("/buscar")
async def buscar_frase_similar(request: QueryRequest):
    resultado = matcher.search_similar_phrase(request.texto)
    return response
\end{lstlisting}


\noindent \textbf{3. F-strings avanzados}

Usados para \textit{logging} descriptivo y \textit{debugging} eficiente.

\textbf{Ejemplo:}
\begin{lstlisting}[language=Python,frame=single]
logger.info(f"Patrón detectado: {nombre} -> {deletreo}")
\end{lstlisting}


\noindent \textbf{4. \textit{Context managers} (\texttt{with} \textit{statements})}

Permiten manejo seguro de archivos y liberación automática de recursos.

\textbf{Ejemplo:}
\begin{lstlisting}[language=Python,frame=single]
with open("grupos.json", "r") as f:
    data = json.load(f)
\end{lstlisting}

\noindent \textbf{5. \textit{List y Dict Comprehensions}}

Permiten procesamiento eficiente y legible de estructuras de datos.

\textbf{Ejemplo:}
\begin{lstlisting}[language=Python,frame=single]
deletreo = [char.upper() for char in nombre]
\end{lstlisting}

\subsubsection{6. Dataclasses y Modelos Pydantic}

Usados para validación automática y tipada de datos de entrada en la API.

\textbf{Ejemplo:}
\begin{lstlisting}[language=Python,frame=single]
class QueryRequest(BaseModel):
    texto: str = Field(..., min_length=1)
\end{lstlisting}

\vspace{1em}

\noindent\textbf{Justificación de elección}

\textbf{Razón 1: Ecosistema de \textit{Machine Learning} y NLP}

Python es el lenguaje dominante en el desarrollo de modelos de aprendizaje automático y procesamiento del lenguaje natural \cite{refimpl8}:
\begin{itemize}
    \item Cerca del 70\% de los artículos publicados en NeurIPS 2023 utilizan Python.
    \item Las bibliotecas de ML más importantes están escritas para Python:
    \begin{itemize}
        \item TensorFlow, PyTorch, JAX.
        \item Scikit-learn, NumPy, Pandas.
        \item Transformers y Sentence-Transformers.
    \end{itemize}
\end{itemize}

\vspace{1em} % ← agrega espacio aquí

\textbf{Razón 2: Rapidez de desarrollo}

Python permite prototipado eficiente \cite{refimpl8}:
\begin{itemize}
    \item Sintaxis clara y expresiva.
    \item Tipado dinámico (con \textit{type hints} opcionales).
    \item REPL interactivo para pruebas rápidas.
    \item Uso de Jupyter notebooks para análisis exploratorio.
\end{itemize}

\vspace{1em} % ← agrega espacio aquí

\textbf{Razón 3: Bibliotecas maduras}

El ecosistema de Python proporciona herramientas de calidad industrial \cite{refimpl8}:
\begin{itemize}
    \item FastAPI para servicios web (más eficiente que Flask en entornos \texttt{async}).
    \item Pydantic para validación de datos.
    \item NumPy para computación numérica.
    \item Pytest para \textit{testing} automatizado.
\end{itemize}

\newpage

\textbf{Razón 4: Comunidad y soporte}

\begin{itemize}
    \item Comunidad muy activa en StackOverflow y GitHub.
    \item Documentación extensa y actualizada.
    \item Amplia disponibilidad de cursos y recursos educativos.
\end{itemize}

\vspace{1em} % ← agrega espacio aquí

\textbf{Razón 5: Rendimiento suficiente para ML}

Aunque Python es un lenguaje interpretado, las operaciones costosas (como generación de \textit{embeddings} o cálculo de similitudes) se ejecutan en implementaciones optimizadas en C/C++ a través de bibliotecas como NumPy \cite{refimpl9} o PyTorch \cite{refimpl10}.

\vspace{1em} % ← agrega espacio aquí

\textbf{Benchmark de latencia:}
\begin{itemize}
    \item Python (este proyecto): 42\,ms por consulta.
    \item Alternativa C++: $\sim$20\,ms/consulta (estimado).
    \item Alternativa Java: $\sim$30\,ms/consulta (estimado).
\end{itemize}

El \textit{overhead} adicional de Python (alrededor de 22\,ms) es aceptable considerando su rapidez de desarrollo y soporte de librerías.


% -----------------------------------------------------------------
\subsection{\textit{Framework} Web: FastAPI}

\noindent \textbf{Versión:} FastAPI 0.104.1 \\
\noindent \textbf{Desarrollador:} Sebastián Ramírez Montaño \cite{refimpl2}.\\

FastAPI es un \textit{framework} moderno para la construcción de APIs de alto rendimiento basado en ASGI, con soporte nativo para \texttt{async/await}, validación automática y documentación generada dinámicamente \cite{refimpl2}.\\

\noindent \textbf{Características clave}\\

\noindent \textbf{1. Alto rendimiento}

\begin{itemize}
    \item Basado en Starlette (ASGI).
    \item Rendimiento comparable a NodeJS y Go.
    \item Soporte nativo para Async I/O.
\end{itemize}

\newpage
\textbf{Métricas:}
\begin{itemize}
    \item Latencia promedio: 40 ms por \textit{request}.
    \item \textit{Throughput}: 25+ requests/segundo.
    \item Uso de memoria aproximado: 150 MB.
\end{itemize}

\noindent \textbf{2. Validación automática con Pydantic}

FastAPI convierte los \textit{type hints} en validación automática de datos de entrada.\\

\textbf{Ejemplo:}
\begin{lstlisting}[language=Python,frame=single]
class QueryRequest(BaseModel):
    texto: str = Field(
        ...,
        min_length=1,
        description="Texto a buscar"
    )
\end{lstlisting}

\noindent \textbf{3. Documentación automática}

\begin{itemize}
    \item Swagger UI disponible en \texttt{/docs} \cite{refimpl11}.
    \item ReDoc disponible en \texttt{/redoc}.
    \item Esquema OpenAPI 3.0 generado automáticamente en \texttt{/openapi.json} \cite{refimpl12}.
\end{itemize}

\textbf{Beneficios:}
\begin{itemize}
    \item \textit{Testing} interactivo sin herramientas externas.
    \item Documentación siempre actualizada.
    \item Permite generar clientes automáticamente (Python, TypeScript, etc.).
\end{itemize}

\noindent \textbf{4. Manejo de errores robusto}

\begin{itemize}
    \item Uso de \texttt{HTTPException} para errores controlados.
    \item \textit{Middleware} automático de manejo de excepciones.
\end{itemize}

\textbf{Ejemplo:}
\begin{lstlisting}[language=Python,frame=single]
if not request.texto.strip():
    raise HTTPException(
        status_code=400,
        detail="Texto vacío"
    )
\end{lstlisting}

\noindent \textbf{5. Dependency Injection}

FastAPI permite inyectar dependencias de forma declarativa, mejorando la mantenibilidad y testabilidad del código.\\

\textbf{Ejemplo:}
\begin{lstlisting}[language=Python,frame=single]
@app.post("/buscar")
async def buscar(request: QueryRequest):
    if matcher is None:
        raise HTTPException(503, "Servicio no disponible")
    ...
\end{lstlisting}

\textbf{Justificación de elección}\\

\textbf{¿Por qué FastAPI y no Flask?}

\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.6}
\begin{tabular}{|p{4cm}|p{4.5cm}|p{4.5cm}|}
\hline
& \textbf{FastAPI} & \textbf{Flask} \\ \hline

\textbf{\textit{Async} nativo} & Sí & No (extensiones) \\ \hline

\textbf{Validación automática} & Sí, Pydantic & No, manual \\ \hline

\textbf{Documentación auto} & Sí, Swagger & No, manual (Flask-RESTX) \\ \hline

\textbf{Tipado estático} & Sí, \textit{Hints} & No \\ \hline

\textbf{Performance} & \(\sim\)400 req/s & \(\sim\)250 req/s \\ \hline

\textbf{Estándar moderno} & OpenAPI & Legacy \\ \hline
\end{tabular}
\caption[Comparación FastAPI vs Flask]{Comparación FastAPI vs Flask, elaboración propia.}
\end{table}

\begin{itemize}
    \item \textbf{Rendimiento:} FastAPI es uno de los \textit{frameworks} más rápidos en Python (\textit{benchmarks}: TechEmpower) \cite{refimpl12}.
    \item \textbf{Validación automática:} Pydantic realiza validación de datos sin necesidad de código adicional \cite{refimpl1}.
    \item \textbf{Documentación automática:} Swagger UI y ReDoc se generan de manera inmediata.
    \item \textbf{Soporte nativo para \texttt{async/await}:} útil para operaciones de E/S (I/O-bound).
    \item \textbf{Uso de \textit{type hints}:} facilita autocompletado y documentación.
\end{itemize}

\textbf{¿Por qué FastAPI y no Django?}

\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.6}
\begin{tabular}{|p{4cm}|p{4.5cm}|p{4.5cm}|}
\hline
& \textbf{FastAPI} & \textbf{Django} \\ \hline

\textbf{Curva de aprendizaje} & Baja & Alta \\ \hline

\textbf{\textit{Overhead}} & Mínimo & Significativo \\ \hline

\textbf{ORM incluido} & No & Sí, innecesario \\ \hline

\textbf{Admin panel} & No & Sí, innecesario \\ \hline

\textbf{Adecuado para API ML} & Sí & Sí \\ \hline
\end{tabular}
\caption[Comparación FastAPI vs Django]{Comparación FastAPI vs Django, elaboración propia.}
\end{table}

\begin{itemize}
    \item Django es un \textit{framework} completo (\textit{full-stack}), orientado a aplicaciones completas.
    \item FastAPI es un \textit{microframework} ideal para APIs y microservicios de aprendizaje automático \cite{refimpl12}.
\end{itemize}

\textbf{Conclusión:} Django es excesivo (\textit{overkill}) para un microservicio que sirve como \textit{backend} de modelos de PLN.

\subsection{\textit{Endpoints} implementados}

\noindent \textbf{1. POST /buscar}

\textbf{Descripción:} Búsqueda semántica principal.\\

\textbf{Ejemplo de entrada:}

\begin{lstlisting}
{"texto": "hola"}
\end{lstlisting}

\textbf{Ejemplo de salida:}

\begin{lstlisting}
{
    "query": "hola",
    "grupo": "B",
    "frase_similar": "Hola",
    "similitud": 1.0,
    "deletreo_activado": false
}
\end{lstlisting}

\noindent \textbf{2. GET /grupos}

\textbf{Descripción:} Retorna la lista de grupos disponibles.

\textbf{Ejemplo de salida:}
\begin{lstlisting}
{
    "total_grupos": 3,
    "grupos": {
        "A": {
            "nombre": "Emergencias",
            "total_frases": 13
        }
    }
}
\end{lstlisting}

\noindent \textbf{3. POST /deletreo}

\textbf{Descripción:} Deletreo manual de texto.

\textbf{Ejemplo de entrada:}
\begin{lstlisting}
{"texto": "Hola"}
\end{lstlisting}

\textbf{Ejemplo de salida:}
\begin{lstlisting}
{
    "texto_original": "Hola",
    "deletreo": ["H","O","L","A"],
    "total_caracteres": 4
}
\end{lstlisting}

% -----------------------------------------------------------------
\subsection{Modelos de PLN: \textit{Sentence-Transformers}}

\noindent \textbf{Biblioteca utilizada}

\begin{itemize}
    \item \textbf{Biblioteca:} \texttt{sentence-transformers 2.2.2}.
    \item \textbf{Desarrolladores:} UKPLab \cite{refimpl13}.
    \item \textbf{Artículo base:} \textit{Sentence-BERT} \cite{refebd10}.
\end{itemize}

\noindent \textbf{Modelo seleccionado}

\begin{itemize}
    \item \textbf{Nombre del modelo:} \texttt{paraphrase-multilingual-MiniLM-L12-v2}
    \item \textbf{Tipo:} Modelo multilingüe optimizado para tareas de similitud semántica.
\end{itemize}

\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.6}
\begin{tabular}{|p{4cm}|p{9cm}|}
\hline
\textbf{Arquitectura} & Transformer (MiniLM variant) \\ \hline
\textbf{Capas} & 12 transformer layers \\ \hline
\textbf{\textit{Hidden size}} & 384 dimensiones \\ \hline
\textbf{\textit{Attention heads}} & 12 heads \\ \hline
\textbf{Parámetros} & $\sim$118 millones \\ \hline
\textbf{Tamaño modelo} & $\sim$420 MB \\ \hline
\textbf{Idiomas} & 50+ idiomas (multilingual) \\ \hline
\textbf{Entrenamiento} & 1B+ sentence pairs \\ \hline
\textbf{\textit{Fine-tuning}} & Paraphrase detection task \\ \hline
\end{tabular}
\caption[Arquitectura del modelo]{Arquitectura del modelo, elaboración propia.}
\end{table}

\noindent \textbf{Arquitectura del modelo}

El flujo interno del modelo sigue las siguientes etapas:

\begin{enumerate}
    \item \textbf{Entrada:} \\ 
    ``Hola, ¿cómo estás?''
    \item \textbf{\textit{Tokenización}} (\textit{WordPiece Tokenizer})
    
    \textit{Tokens} resultantes:
\begin{verbatim}
[CLS] hola , ? como estas ? [SEP]
\end{verbatim}

    Identificadores numéricos (IDs):
\begin{verbatim}
[101, 45321, 102, 189, 12045, 36547, 103, 102]
\end{verbatim}

    \item \textbf{Capa de \textit{Embeddings}:}
    \begin{itemize}
        \item \textit{Token embeddings} (768 dimensiones).
        \item \textit{Positional embeddings}.
        \item \textit{Segment embeddings}.
    \end{itemize}

    \newpage
    \item \textbf{12 capas \textit{Transformer}}
    \begin{itemize}
        \item Cada capa contiene:
        \begin{itemize}
            \item \textit{Multi-Head Self-Attention}.
            \item \textit{Feed-Forward Network}.
        \end{itemize}
        \item Se repite desde la capa 1 hasta la capa 12.
    \end{itemize}

    \item \textbf{Pooling layer} \\
    \textit{Mean Pooling} (promedio de todos los \textit{embeddings}).

    \item \textbf{Normalización final} \\
    Normalización L2 del vector resultante.

    \item \textbf{Salida:} \\
    Vector denso de dimensión 384:
\begin{verbatim}
[0.123, -0.456, 0.789, ...]
\end{verbatim}
\end{enumerate}

\noindent \textbf{Ventajas del modelo seleccionado}

\textbf{1. Multilingüe}

\begin{itemize}
    \item Soporta español de forma nativa.
    \item No requiere traducción previa.
    \item Entrenado con datos multilingües, incluyendo español.
\end{itemize}

\textbf{2. Balance entre tamaño y desempeño}

\begin{itemize}
    \item 384 dimensiones (menor que BERT-base con 768).
    \item Inferencia más rápida y ligera.
    \item Menor uso de memoria en producción.
    \item Desempeño adecuado para sistemas en tiempo real.
\end{itemize}

\textbf{3. \textit{Fine-tuned} para tareas de paráfrasis}

\begin{itemize}
    \item Detecta variaciones semánticas de una misma frase.
    \item Ideal para tareas como:
    \begin{itemize}
        \item ``hola'' vs. ``buenos días''
        \item ``ayúdame'' vs. ``necesito ayuda''
    \end{itemize}
    \item Robusto ante errores ortográficos menores.
\end{itemize}

\textbf{4. Amplio uso en la comunidad}

\begin{itemize}
    \item Gran soporte de la comunidad \textit{open-source}.
    \item Documentación completa.
    \item Modelo preentrenado y listo para usar en producción.
\end{itemize}

\textbf{Justificación de elección}

\textbf{¿Por qué \textit{Sentence-Transformers} y no \textit{Word2Vec/GloVe?}}

\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.6}
\begin{adjustbox}{max width=\linewidth}
\begin{tabular}{|p{3.5cm}|p{3.5cm}|p{3.5cm}|p{3.5cm}|}
\hline
& \textbf{Sentence-BERT} & \textbf{Word2Vec} & \textbf{GloVe} \\ \hline

\textbf{Captura de texto} & Sí & No & No \\ \hline

\textbf{\textit{Embeddings} de oraciones} & Directo & Promedio & Promedio \\ \hline

\textbf{Pre-entrenado moderno} & 2023 & 2013 & 2014 \\ \hline

\textbf{Multilingüe} & Más de 50 idiomas & Por idioma & Por idioma \\ \hline

\textbf{\textit{Performance}} & SOTA & Legacy & Legacy \\ \hline
\end{tabular}
\end{adjustbox}
\caption[Comparación de embeddings modernos]{Comparación entre Sentence-BERT, Word2Vec y GloVe, elaboración propia.}
\end{table}

Modelos clásicos como Word2Vec y GloVe generan \textit{embeddings} estáticos, es decir, una representación por palabra sin contexto. Ejemplo:

\begin{itemize}
    \item ``banco'' (institución financiera) vs. ``banco'' (asiento).
    \item Word2Vec: mismo \textit{embedding} (no distingue contexto) \ding{55}
    \item BERT/SBERT: \textit{embeddings} distintos según el uso contextual \checkmark
\end{itemize}

\textbf{Conclusión:} Sentence-BERT es superior para tareas de similitud semántica y comprensión contextual.\\

\newpage
\textbf{¿Por qué \textit{Sentence-Transformers} y no Spacy?}

\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.6}
\begin{tabular}{|p{6cm}|p{6cm}|}
\hline
\textbf{Sentence-Transformers} & \textbf{SpaCy} \\ \hline
\textit{Embeddings} de alta calidad & PLN completo (POS, NER, etc.) \\ \hline
Multilingüe \textit{out-of-the-box} & \textit{Embeddings} más básicos \\ \hline
Pre-entrenado para paráfrasis & Requiere más configuración \\ \hline
Fácil de usar & - \\ \hline
\end{tabular}
\caption[Sentence-Transformers vs SpaCy]{Comparación entre \textit{Sentence-Transformers} y SpaCy, elaboración propia.}
\end{table}

\textbf{¿Por qué \textit{Sentence-Transformers} y no \textit{Transformers} de HuggingFace directamente?}

\begin{itemize}
    \item \textit{Sentence-Transformers} ofrece una API para \textit{embeddings} de oraciones.
    \item Implementa arquitecturas tipo siamese listas para usar.
    \item Procesa oraciones completas con mayor eficiencia que llamar manualmente a modelos de HuggingFace.
\end{itemize}

\subsubsection{¿Por qué se eligió \texttt{paraphrase-multilingual-MiniLM-L12-v2}?}

\textbf{Alternativas evaluadas:}

\begin{itemize}
    \item \texttt{all-MiniLM-L6-v2}
    \begin{itemize}
        \item Pros: muy rápido.
        \item Contras: solo inglés, menor precisión.
        \item Decisión: descartado.
    \end{itemize}

    \item \texttt{distiluse-base-multilingual-cased-v2}
    \begin{itemize}
        \item Pros: multilingüe.
        \item Contras: 512 dimensiones, 250\,MB.
        \item Decisión: descartado por peso.
    \end{itemize}

    \item \texttt{paraphrase-multilingual-mpnet-base-v2}
    \begin{itemize}
        \item Pros: máxima precisión.
        \item Contras: 768 dimensiones, 400\,MB, $\sim$80\,ms/consulta.
        \item Decisión: demasiado lento para tiempo real.
    \end{itemize}

    \item \textbf{\texttt{paraphrase-multilingual-MiniLM-L12-v2}} (modelo elegido)
    \begin{itemize}
        \item Precisión alta (92\%).
        \item Velocidad excelente ($\sim$40\,ms por consulta).
        \item Tamaño reducido (120\,MB).
        \item Soporte multilingüe incluyendo español.
    \end{itemize}
\end{itemize}

\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.6}
\begin{adjustbox}{max width=\linewidth}
\begin{tabular}{|p{5cm}|p{2.5cm}|p{2.5cm}|p{2.5cm}|p{2.5cm}|}
\hline
\textbf{Modelo} & \textbf{Dimensiones} & \textbf{Tamaño} & \textbf{Latencia} & \textbf{Precisión} \\ \hline

all-MiniLM-L6-v2 & 384 & 80MB & 30ms & 85\% (solo inglés) \\ \hline

paraphrase-multilingual-MiniLM & 384 & 120MB & 40ms & 92\% (español) \\ \hline

distiluse-multilingual & 512 & 250MB & 60ms & 94\% \\ \hline

paraphrase-mpnet-multilingual & 768 & 400MB & 80ms & 96\% \\ \hline

\end{tabular}
\end{adjustbox}
\caption[Modelos comparados]{Comparación de modelos de embeddings, elaboración propia.}
\end{table}

\textbf{Conclusión:} MiniLM-L12 ofrece el mejor equilibrio entre calidad, velocidad y tamaño del modelo para un entorno de producción.

\newpage
\subsection{Bibliotecas de Machine Learning}

{\large \noindent \textbf{NumPy 1.24.3}}

\textbf{Uso en el proyecto \cite{refimpl9}:}
\begin{itemize}
    \item Operaciones matriciales para \textit{embeddings}.
    \item Cálculo de centroides de grupos.
    \item Operaciones vectoriales optimizadas.
    \item Guardado y carga de caché en formato \texttt{.npz}.
\end{itemize}

\textbf{Funciones clave:}
\begin{itemize}
    \item \texttt{np.array()} --- Conversión a arreglos.
    \item \texttt{np.mean()} --- Cálculo de centroides.
    \item \texttt{np.clip()} --- Normalización de valores.
    \item \texttt{np.savez()} --- Guardado de \textit{embeddings}.
    \item \texttt{np.load()} --- Carga de \textit{embeddings}.
\end{itemize}

\textbf{Ejemplo:}
\begin{lstlisting}[language=Python]
# Cálculo de centroide
centroid = np.mean(embeddings, axis=0)

# Guardado de caché
np.savez(cache_path,
    A_embeddings=grupo_a_emb,
    B_embeddings=grupo_b_emb,
    C_embeddings=grupo_c_emb
)
\end{lstlisting}

{\large \noindent \textbf{Scikit-learn 1.3.0}}

\textbf{Uso en el proyecto \cite{refimpl14}:}
\begin{itemize}
    \item Cálculo de similitud de coseno.
    \item Normalización de vectores.
\end{itemize}

\textbf{Función utilizada:}
\begin{itemize}
    \item \texttt{cosine\_similarity()} --- Similitud entre \textit{embeddings}.
\end{itemize}

\newpage
\textbf{Ejemplo:}
\begin{lstlisting}[language=Python]
from sklearn.metrics.pairwise import cosine_similarity

similarity = cosine_similarity(
    [query_embedding],
    grupo_embeddings
)[0]
# Resultado: array([0.85, 0.92, 0.78, ...])
\end{lstlisting}

\textbf{Ventajas:}
\begin{itemize}
    \item Código optimizado en C.
    \item Manejo eficiente de matrices grandes.
    \item API simple y consistente.
\end{itemize}

{\large \noindent \textbf{RapidFuzz 3.5.2}}

\textbf{Uso en el proyecto \cite{refimpl4}:}
\begin{itemize}
    \item Corrección ortográfica.
    \item Detección de errores comunes (typos).
\end{itemize}

\textbf{Algoritmo principal:} Distancia de Levenshtein (implementación optimizada en C++).

\textbf{Funciones utilizadas:}
\begin{itemize}
    \item \texttt{fuzz.ratio()} --- Similitud entre cadenas.
\end{itemize}

\textbf{Ejemplo:}
\begin{lstlisting}[language=Python]
from rapidfuzz import fuzz

similarity = fuzz.ratio("ola", "hola")  # 75.0

if similarity > 80:
    corrected = "hola"
\end{lstlisting}

\textbf{Casos de uso:}
\begin{itemize}
    \item ``ola'' → ``hola''
    \item ``graias'' → ``gracias''
    \item ``ayda'' → ``ayuda''
\end{itemize}

\newpage
{\large \noindent \textbf{PyTorch 2.1.0}}

\textbf{Uso en el proyecto \cite{refimpl10}:}
\begin{itemize}
    \item \textit{Backend} de \texttt{sentence-transformers}.
    \item Ejecución del modelo \textit{Transformer}.
    \item Soporte opcional para GPU.
\end{itemize}

\textbf{Configuración:}
\begin{lstlisting}[language=Python]
device = "cuda" if torch.cuda.is_available() else "cpu"

# En este proyecto se usa CPU
model = SentenceTransformer(model_name)
model.to("cpu")
\end{lstlisting}

\textbf{Ventajas:}
\begin{itemize}
    \item \textit{Framework maduro} y ampliamente adoptado.
    \item Gran ecosistema en NLP y visión.
    \item Compatibilidad con HuggingFace.
\end{itemize}

\vspace{1em}

\subsection{Herramientas de Desarrollo}

{\large \noindent \textbf{Pytest 7.4.3}}

\textbf{Plugins utilizados \cite{refimpl15}:}
\begin{itemize}
    \item \texttt{pytest-cov} --- Cobertura de código.
    \item \texttt{pytest-asyncio} --- Soporte para tests \textit{async}.
    \item \texttt{pytest-benchmark} --- Pruebas de rendimiento.
    \item \texttt{pytest-html} --- Reportes HTML.
\end{itemize}

\newpage
\textbf{Estructura de carpetas:}

\begin{verbatim}
tests/
|-- unit/                 # Tests unitarios
|   |-- test_matcher.py
|   |-- test_preprocess.py
|   `-- test_groups.py
|-- integration/          # Tests de integración
|   `-- test_api.py
|-- e2e/                  # Pruebas end-to-end
|   |-- test_casos_realistas.py
|   `-- test_robustness.py
`-- performance/          # Benchmarks
    `-- test_benchmarks.py
\end{verbatim}

\textbf{Comandos principales:}
\begin{lstlisting}[language=bash]
pytest
pytest --cov=app --cov-report=html
pytest tests/unit/test_matcher.py -v
pytest tests/performance/ --benchmark-only
\end{lstlisting}

{\large \noindent \textbf{Uvicorn 0.24.0}}

\textbf{Características \cite{refimpl3}:}
\begin{itemize}
    \item Servidor ASGI de alto rendimiento.
    \item Basado en \texttt{uvloop} (más rápido que asyncio).
    \item \textit{Hot-reload} para desarrollo.
\end{itemize}

\textbf{Configuración para producción:}
\begin{lstlisting}[language=bash]
uvicorn app.main:app \
  --host 0.0.0.0 \
  --port 8000 \
  --workers 4 \
  --log-level info
\end{lstlisting}

\textbf{Modo desarrollo:}
\begin{lstlisting}[language=bash]
uvicorn app.main:app \
  --host 0.0.0.0 \
  --port 8000 \
  --reload
\end{lstlisting}

\newpage
{\large \noindent \textbf{Git 2.43.0}}

\textbf{Estrategia de ramas \cite{refimpl16}:}
\begin{itemize}
    \item \textbf{main:} Rama estable.
    \item \textbf{feat/*:} Nuevas funcionalidades.
    \item \textbf{fix/*:} Corrección de errores.
\end{itemize}

\textbf{Convenciones de commits:}
\begin{verbatim}
feat: agregar nueva funcionalidad
fix: corregir bug
docs: actualizar documentación
test: agregar tests
refactor: refactorizar código
perf: mejora de performance
\end{verbatim}

\textbf{Workflow recomendado:}
\begin{lstlisting}[language=bash]
git checkout -b feat/nombre-detection
git add app/matcher_improved.py
git commit -m "feat: agregar detección de nombres"
git push -u origin feat/nombre-detection
\end{lstlisting}

{\large \noindent \textbf{Pydantic 2.5.0}}

\textbf{Uso en el proyecto \cite{refimpl1}:}
\begin{itemize}
    \item Validación automática de \textit{requests}.
    \item Serialización y deserialización.
    \item Integración con FastAPI.
\end{itemize}

\textbf{Ejemplo de modelo:}
\begin{lstlisting}[language=Python]
class QueryRequest(BaseModel):
    texto: str = Field(
        ...,
        min_length=1,
        max_length=500,
        description="Texto a buscar"
    )

class QueryResponse(BaseModel):
    query: str
    grupo: str | None
    frase_similar: str
    similitud: float = Field(ge=0.0, le=1.0)
    deletreo_activado: bool
    deletreo: List[str] | None = None
\end{lstlisting}

\textbf{Validación automática:}
\begin{itemize}
    \item Tipos de datos.
    \item Rangos numéricos.
    \item Longitud de cadenas.
    \item Campos requeridos y opcionales.
\end{itemize}

\subsection{Justificación de Elección de Tecnologías}

\noindent\textbf{Criterios de selección}
\textbf{1. Rendimiento}
\begin{itemize}
    \item FastAPI: Alto rendimiento \cite{refimpl2}.
    \item Sentence-Transformers: Inferencia rápida \cite{refimpl13}.
    \item NumPy: Operaciones vectoriales optimizadas \cite{refimpl9}.
\end{itemize}
\textbf{Resultado:} Latencia promedio de 40\,ms.\\

\textbf{2. Ecosistema y comunidad}
\begin{itemize}
    \item Python: Amplio ecosistema ML/PLN \cite{refimpl8}.
    \item FastAPI: Más de 70\,000 estrellas en GitHub \cite{refimpl2}.
    \item \textit{Sentence-Transformers}: Estándar de la industria \cite{refimpl13}.
\end{itemize}

\textbf{3. Mantenibilidad}
\begin{itemize}
    \item \textit{Type hints} en Python 3.12 \cite{refimpl8}.
    \item Validación con Pydantic \cite{refimpl1}.
    \item Tests con Pytest \cite{refimpl15}.
\end{itemize}

\textbf{4. Escalabilidad}
\begin{itemize}
    \item Arquitectura asíncrona.
    \item API \textit{stateless}.
    \item Caché de \textit{embeddings}.
\end{itemize}

\newpage
\textbf{5. Experiencia de desarrollador}
\begin{itemize}
    \item \textit{Hot-reload}.
    \item Documentación automática.
    \item \textit{Type checking}.
\end{itemize}

{\large \noindent \textbf{Stack tecnológico final}}

\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.6}
\begin{tabular}{|p{6cm}|p{6cm}|}
\hline
\textbf{Capa} & \textbf{Tecnología} \\ \hline

Lenguaje de programación & Python 3.12.3 \\ \hline
\textit{Framework Web} & FastAPI 0.104.1 \\ \hline
Servidor ASGI & Uvicorn 0.24.0 \\ \hline
Modelo \textit{Machine Learning} & paraphrase-multilingual-MiniLM-L12-v2 \\ \hline
\textit{Embeddings Library} & sentence-transformers 2.2.2 \\ \hline
\textit{Machine Learning Framework} & PyTorch 2.1.0 \\ \hline
Operaciones numéricas & NumPy 1.24.3 \\ \hline
\textit{Machine Learning utilities} & scikit-learn 1.3.0 \\ \hline
\textit{String Matching} & RapidFuzz 3.5.2 \\ \hline
Validación & Pydantic 2.5.0 \\ \hline
\textit{Testing} & Pytest 7.4.3 \\ \hline
Control de Versiones & Git 2.43.0 \\ \hline

\end{tabular}
\caption[Stack tecnológico]{Stack tecnológico utilizado, elaboración propia.}
\end{table}

\subsection{Alternativas rechazadas}

\noindent\textbf{Lenguajes de programación}
\begin{itemize}
    \item JavaScript/Node.js: Ecosistema de ML inmaduro.
    \item Java: Verboso, no estándar en ML.
    \item C++: Desarrollo lento e innecesario.
    \item Go: Sin bibliotecas de ML de primer nivel.
\end{itemize}

\noindent\textbf{Frameworks}
\begin{itemize}
    \item Flask: Sin \textit{async} nativo ni validación automática.
    \item Django: \emph{Overkill} para un microservicio.
    \item Tornado: En desuso, comunidad pequeña.
\end{itemize}

\noindent\textbf{Modelos}
\begin{itemize}
    \item Word2Vec: No captura contexto.
    \item BERT completo: Latencia > 100ms.
    \item GPT-3/4: API externa, costo y latencia variable.
\end{itemize}

\noindent\textbf{Bases de datos}
\begin{itemize}
    \item PostgreSQL/MySQL: Innecesarias para \textit{dataset} fijo.
    \item Decisión: JSON plano es suficiente para 43 frases.
\end{itemize}

\subsection{Conclusión}
El \textbf{stack elegido} (Python + FastAPI + Sentence-Transformers) ofrece el mejor balance entre rendimiento, velocidad de desarrollo y mantenibilidad para el problema abordado.

%---------------------------------
\newpage
\section{Implementación Técnica Detallada del Modulo de PLN}

{\large \noindent \textbf{Módulo de API REST (\texttt{main.py})}}

\textbf{Estructura del archivo (665 líneas)}
\begin{verbatim}
app/main.py
|-- [1-50]   Imports y configuración
|-- [51-115] Modelos Pydantic (Request/Response)
|-- [116-205] Utilidades y funciones auxiliares
|-- [206-230] Eventos de lifecycle (startup/shutdown)
|-- [231-580] Endpoints de la API
`-- [581-665] Configuración y ejecución
\end{verbatim}


{\large \noindent \textbf{Modelos Pydantic}}

\begin{lstlisting}[language=Python,frame=single]
class QueryRequest(BaseModel):
    """Modelo para requests de búsqueda."""
    texto: str = Field(
        ...,
        min_length=1,
        description="Texto de consulta a buscar"
    )

class QueryResponse(BaseModel):
    """Modelo para respuestas de búsqueda."""
    query: str = Field(..., description="Consulta original")
    grupo: str | None = Field(
        None,
        description="Grupo temático (A/B/C)"
    )
    frase_similar: str = Field(
        ...,
        description="Frase más similar encontrada"
    )
    similitud: float = Field(
        ...,
        ge=0.0,
        le=1.0,
        description="Similitud coseno [0.0-1.0]"
    )
    deletreo_activado: bool = Field(
        ...,
        description="Si se activó deletreo automático"
    )
    deletreo: List[str] | None = Field(
        None,
        description="Lista de caracteres deletreados"
    )
    total_caracteres: int | None = Field(
        None,
        description="Cantidad de caracteres"
    )
    # Campos nuevos para detección de nombres
    nombre_detectado: bool | None = Field(
        None,
        description="Si se detectó patrón con nombre"
    )
    nombre_extraido: str | None = Field(
        None,
        description="Nombre extraído del patrón"
    )
    nombre_deletreado: List[str] | None = Field(
        None,
        description="Letras del nombre para deletrear"
    )
    total_caracteres_nombre: int | None = Field(
        None,
        description="Cantidad de letras del nombre"
    )
\end{lstlisting}

\vspace{1em}
{\large \noindent \textbf{Endpoint principal: \texttt{POST /buscar}}}

\begin{lstlisting}[language=Python,frame=single]
@app.post(
    "/buscar",
    response_model=QueryResponse,
    tags=["Búsqueda"],
    summary="Buscar frase similar",
    description="""
    Busca la frase más similar al texto proporcionado usando
    embeddings semánticos y similitud coseno.

    Sistema de Deletreo Automático:
    - Grupo A (Emergencias): threshold 0.75
    - Grupo B (Saludos): threshold 0.80
    - Grupo C (Comunicación): threshold 0.85
    """,
    responses={
        200: {"description": "Búsqueda exitosa"},
        400: {"description": "Texto vacío o inválido"},
        503: {"description": "Servicio no disponible"},
        500: {"description": "Error interno"}
    }
)
async def buscar_frase_similar(request: QueryRequest):
    """Busca la frase más similar usando PLN."""

    if matcher is None:
        raise HTTPException(
            status_code=503,
            detail="Servicio no disponible"
        )

    if not request.texto or not request.texto.strip():
        raise HTTPException(
            status_code=400,
            detail="El texto no puede estar vacío"
        )

    try:
        logger.info(f"Búsqueda para: {request.texto}")

        resultado = matcher.search_similar_phrase(request.texto)

        response = QueryResponse(
            query=resultado["query"],
            grupo=resultado["grupo"],
            frase_similar=resultado["frase_similar"],
            similitud=resultado["similitud"],
            deletreo_activado=resultado["deletreo_activado"],
            deletreo=resultado.get("deletreo"),
            total_caracteres=resultado.get("total_caracteres"),
            nombre_detectado=resultado.get("nombre_detectado"),
            nombre_extraido=resultado.get("nombre_extraido"),
            nombre_deletreado=resultado
            .get("nombre_deletreado"),
            total_caracteres_nombre=resultado
            .get("total_caracteres_nombre")
        )

        if resultado["deletreo_activado"]:
            logger.info("Resultado: DELETREO ACTIVADO")
        elif resultado.get("nombre_detectado"):
            logger.info(f"Resultado: NOMBRE DETECTADO - {resultado['nombre_extraido']}")
        else:
            logger.info(f"Resultado: {response.grupo} - {response.similitud}")

        return response

    except Exception as e:
        logger.error(f"Error en búsqueda: {e}")
        raise HTTPException(
            status_code=500,
            detail="Error interno del servidor"
        )
\end{lstlisting}

\vspace{1em}
{\large \noindent \textbf{Endpoint: \texttt{GET /grupos}}}

\begin{lstlisting}[language=Python,frame=single]
@app.get(
    "/grupos",
    tags=["Grupos"],
    summary="Listar grupos disponibles"
)
async def listar_grupos():
    """Retorna información de todos los grupos."""
    try:
        grupos = get_all_phrases()

        return {
            "total_grupos": len(grupos),
            "grupos": {
                grupo: {
                    "nombre": GRUPO_NOMBRES[grupo],
                    "total_frases": len(frases),
                    "ejemplos": frases[:3]
                }
                for grupo, frases in grupos.items()
            }
        }
    except Exception as e:
        logger.error(f"Error al listar grupos: {e}")
        raise HTTPException(500, detail="Error interno")
\end{lstlisting}

\newpage
{\large \noindent \textbf{Endpoint: POST /deletreo}}

\begin{lstlisting}
@app.post(
    "/deletreo",
    tags=["Deletreo"],
    summary="Deletrear texto manualmente"
)
async def deletrear_texto(request: QueryRequest):
    """Deletrea cualquier texto letra por letra."""
    from .preprocess import spell_out_text, normalize_leet_speak

    # Normalizar leet speak
    texto_normalizado = normalize_leet_speak(request.texto)

    # Deletrear
    deletreo = spell_out_text(texto_normalizado, include_spaces=True)

    return {
        "texto_original": request.texto,
        "texto_normalizado": texto_normalizado,
        "deletreo": deletreo,
        "total_caracteres": len(deletreo)
    }
\end{lstlisting}

\vspace{1em}
{\large \noindent \textbf{Manejo de errores}}

\textbf{Middleware de manejo de excepciones:}

\begin{lstlisting}
@app.exception_handler(HTTPException)
async def http_exception_handler(request, exc):
    """Maneja excepciones HTTP."""
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "error": exc.detail,
            "status_code": exc.status_code,
            "path": str(request.url)
        }
    )

@app.exception_handler(Exception)
async def general_exception_handler(request, exc):
    """Maneja excepciones generales."""
    logger.error(f"Error no manejado: {exc}")
    return JSONResponse(
        status_code=500,
        content={
            "error": "Error interno del servidor",
            "status_code": 500
        }
    )
\end{lstlisting}

\vspace{1em}
{\large \noindent \textbf{Configuración de CORS}}

\begin{lstlisting}
from fastapi.middleware.cors import CORSMiddleware

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
\end{lstlisting}

\vspace{1em}
{\large \noindent \textbf{Lifecycle Events}}

\begin{lstlisting}
@app.on_event("startup")
async def startup_event():
    """Inicializa el sistema al arrancar."""
    global matcher
    logger.info("Inicializando aplicación...")

    try:
        matcher = ImprovedPhraseMatcher(
            model_type="multilingual_balanced",
            cache_path="data/embeddings_improved.npz",
            use_reranking=True
        )
        matcher.initialize()
        logger.info("Aplicación inicializada correctamente")
    except Exception as e:
        logger.error(f"Error en inicialización: {e}")
        raise

@app.on_event("shutdown")
async def shutdown_event():
    """Limpieza al apagar."""
    logger.info("Apagando aplicación...")
\end{lstlisting}

\newpage
{\large \noindent \textbf{Motor de búsqueda semántica (matcher\_improved.py)}}

\textbf{Clase principal: \texttt{ImprovedPhraseMatcher} (681 líneas)}

\begin{lstlisting}
class ImprovedPhraseMatcher:
    """
    Matcher mejorado con:
    - Búsqueda jerárquica en dos fases
    - Thresholds adaptativos por grupo
    - Detección de nombres propios
    - Sistema de deletreo automático
    - Cache de embeddings
    """

    # Modelos disponibles
    MODELS = {
        "spanish_optimized": "hiiamsid/sentence_similarity_spanish_es",
        "multilingual_advanced": "paraphrase-multilingual-mpnet-base-v2",
        "multilingual_balanced": "paraphrase-multilingual-MiniLM-L12-v2",
        "current": "all-MiniLM-L6-v2"
    }

    # Thresholds por grupo
    GROUP_THRESHOLDS = {
        "A": 0.60,  # Emergencias: flexible
        "B": 0.63,  # Saludos: flexible
        "C": 0.78   # Comunicación: estricto
    }

    # Thresholds para deletreo
    SPELL_OUT_THRESHOLDS = {
        "A": 0.75,
        "B": 0.80,
        "C": 0.85
    }

    # Lista de nombres comunes
    COMMON_SPANISH_NAMES = {
        'juan', 'jose', 'antonio', 'manuel', 'francisco',
        'david', 'carlos', 'miguel', 'pedro', 'luis',
        'maria', 'carmen', 'ana', 'isabel', 'pilar',
        # ... 40+ nombres
    }
\end{lstlisting}

{\large \noindent \textbf{Método \texttt{initialize()}}}

\begin{lstlisting}
def initialize(self):
    """
    Inicializa el matcher:
    1. Carga modelo de embeddings
    2. Genera/carga cache de embeddings
    3. Calcula centroides de grupos
    """
    logger.info("Inicializando PhraseMatcher mejorado")

    # Cargar grupos
    self.grupos_frases = get_all_phrases()

    # Verificar cache
    if os.path.exists(self.cache_path):
        logger.info("Cargando embeddings desde cache")
        self._load_from_cache()
    else:
        logger.info("Generando embeddings (primera vez)")
        self._generate_and_cache_embeddings()

    # Calcular centroides
    self._calculate_centroids()

    logger.info("PhraseMatcher inicializado correctamente")
\end{lstlisting}

\vspace{1em}
{\large \noindent \textbf{Método \texttt{search\_similar\_phrase()}}}

\begin{lstlisting}
def search_similar_phrase(self, query: str) -> Dict:
    """
    Busqueda principal con deteccion de nombres.

    Pipeline:
    1. Preprocesar query
    2. Generar embedding
    3. Busqueda jerarquica (re-ranking)
    4. Validar patrones especiales (nombres)
    5. Determinar si activar deletreo
    6. Construir respuesta
    """

    # 1. BUSQUEDA
    if self.use_reranking:
        grupo, frase, similarity = self.find_most_similar_phrase_reranked(query)
    else:
        best_group = self.find_best_groups(query, top_k=1)[0][0]
        grupo, frase, similarity = self.find_most_similar_phrase(query, best_group)

    # 2. VALIDAR DELETREO
    spell_out_threshold = self.SPELL_OUT_THRESHOLDS.get(grupo, 0.60)
    should_spell_out = similarity < spell_out_threshold

    # 3. VALIDACIONES ESPECIALES PARA NOMBRES
    query_normalized = query.strip().lower()
    query_words = query_normalized.split()

    if len(query_words) == 1:
        query_len = len(query_words[0])

        if 3 <= query_len <= 8:
            # Construir palabras conocidas del dataset
            palabras_conocidas = set()
            for frases in self.grupos_frases.values():
                for frase_item in frases:
                    frase_norm = normalize_text(frase_item)
                    palabras_conocidas.update(frase_norm.split())

            # VALIDACION 1: Nombre comun espanol
            if query_normalized in self.COMMON_SPANISH_NAMES:
                should_spell_out = True
                logger.info(f"Nombre comun detectado: {query}")

            # VALIDACION 2: Palabra no en dataset
            elif query_normalized not in palabras_conocidas:
                if 0.50 <= similarity < 0.85:
                    should_spell_out = True
                    logger.info(f"Posible nombre: {query}")

    # VALIDACION 3: Capitalizacion de nombre propio
    if len(query) > 2 and query[0].isupper() and query[1:].islower():
        if similarity < 0.98:
            should_spell_out = True
            logger.info(f"Nombre por capitalizacion: {query}")

    # 4. PENALIZACION POR LONGITUD
    if len(query_words) == 1 and len(frase.split()) == 1:
        length_diff = abs(len(query_words[0]) - len(frase.split()[0]))
        if length_diff > 1:
            penalty = 0.05 * length_diff
            similarity = clip_similarity(similarity - penalty)
            should_spell_out = similarity < spell_out_threshold

    # 5. ACTIVAR DELETREO
    if should_spell_out:
        from .preprocess import spell_out_text, normalize_leet_speak

        normalized_query = normalize_leet_speak(query)
        deletreo_list = spell_out_text(normalized_query, include_spaces=True)
        deletreo_str = " ".join(deletreo_list)

        return {
            "query": query,
            "grupo": None,
            "frase_similar": deletreo_str,
            "similitud": round(similarity, 4),
            "deletreo_activado": True,
            "deletreo": deletreo_list,
            "total_caracteres": len(deletreo_list)
        }

    # 6. DETECTAR PATRONES CON NOMBRES
    nombre_info = self._extract_name_pattern(query, frase, similarity)
    if nombre_info:
        return {
            "query": query,
            "grupo": grupo,
            "frase_similar": frase,
            "similitud": round(similarity, 4),
            "deletreo_activado": False,
            "deletreo": None,
            "total_caracteres": None,
            "nombre_detectado": True,
            "nombre_extraido": nombre_info["nombre"],
            "nombre_deletreado": nombre_info["deletreo"],
            "total_caracteres_nombre": len(nombre_info["deletreo"])
        }

    # 7. RESPUESTA NORMAL
    return {
        "query": query,
        "grupo": grupo,
        "frase_similar": frase,
        "similitud": round(similarity, 4),
        "deletreo_activado": False,
        "deletreo": None,
        "total_caracteres": None
    }
\end{lstlisting}

\vspace{1em}
{\large \noindent \textbf{Método \texttt{\_extract\_name\_pattern()}}}

\begin{lstlisting}
def _extract_name_pattern(
    self,
    query: str,
    frase_similar: str,
    similarity: float
) -> Optional[Dict]:
    """
    Detecta patrones con nombres propios:
    - "Me llamo [NOMBRE]"
    - "Mi nombre es [NOMBRE]"
    - "Soy [NOMBRE]"
    """

    from .preprocess import spell_out_text, normalize_leet_speak, normalize_text

    # Solo aplicar si frase similar es "Me llamo"
    frase_normalizada = normalize_text(frase_similar)
    if frase_normalizada not in ["me llamo", "como te llamas"]:
        return None

    # Validar similitud
    if similarity < 0.80:
        return None

    # Normalizar query
    query_normalizado = normalize_text(query)
    query_words = query_normalizado.split()

    # Patrones posibles
    nombre = None
    patrones = [
        (["me", "llamo"], 2),
        (["mi", "nombre", "es"], 3),
        (["soy"], 1),
    ]

    for patron, _ in patrones:
        if len(query_words) > len(patron):
            if query_words[:len(patron)] == patron:
                nombre_words = query_words[len(patron):]
                nombre = " ".join(nombre_words)
                break

    if not nombre or len(nombre) < 2:
        return None

    # Palabras comunes a descartar
    palabras_comunes = {
        'hola', 'gracias', 'bien', 'mal', 'si', 'no',
        'vale', 'ok', 'ayuda', 'auxilio', 'socorro'
    }
    if nombre in palabras_comunes:
        return None

    # Extraer nombre original
    query_words_original = query.split()
    nombre_words_normalized = nombre.split()

    nombre_start_idx = None
    for i in range(len(query_words) - len(nombre_words_normalized) + 1):
        if query_words[i:i + len(nombre_words_normalized)] == nombre_words_normalized:
            nombre_start_idx = i
            break

    if nombre_start_idx is not None:
        nombre_original_words = query_words_original[
            nombre_start_idx:nombre_start_idx + len(nombre_words_normalized)
        ]
        nombre_original = " ".join(nombre_original_words)
        nombre_normalized = normalize_leet_speak(nombre_original)
    else:
        nombre_normalized = nombre

    # Deletrear nombre
    deletreo_list = spell_out_text(nombre_normalized, include_spaces=False)

    logger.info(
        f"Patron de nombre detectado: query='{query}', "
        f"nombre='{nombre_normalized}', deletreo={deletreo_list}"
    )

    return {
        "nombre": nombre_normalized,
        "deletreo": deletreo_list
    }
\end{lstlisting}

{\large \noindent \textbf{Método \texttt{find\_most\_similar\_phrase\_reranked()}}}

\begin{lstlisting}
def find_most_similar_phrase_reranked(
    self,
    query: str
) -> Tuple[str, str, float]:
    """
    Busqueda jerarquica en dos fases:

    FASE 1: Centroides (top-3 grupos)
    FASE 2: Re-ranking con boosts y penalizaciones
    """

    # FASE 1: Grupos candidatos
    top_groups = self.find_best_groups(query, top_k=3)

    # Preprocesar query
    query_prep = preprocess_query(query)

    # Cargar modelo
    self._load_model()

    # Generar embedding
    query_embedding = self.model.encode([query_prep])[0]

    best_similarity = -1
    best_group = None
    best_phrase = None

    for grupo, group_score in top_groups:
        embeddings = self.grupos_embeddings[grupo]
        frases = self.grupos_frases[grupo]

        similarities = cosine_similarity(
            [query_embedding],
            embeddings
        )[0]

        # BOOST por longitud
        for i, frase in enumerate(frases):
            num_words = len(frase.split())
            if num_words >= 3:
                similarities[i] += 0.15
            elif num_words == 2:
                similarities[i] += 0.08

        similarities = np.clip(similarities, 0.0, 1.0)

        max_idx = np.argmax(similarities)
        similarity = similarities[max_idx]

        # Bonus al grupo top
        if grupo == top_groups[0][0]:
            similarity += 0.05
            similarity = clip_similarity(similarity)

        threshold = self.GROUP_THRESHOLDS.get(grupo, 0.60)

        if similarity >= threshold and similarity > best_similarity:
            best_similarity = similarity
            best_group = grupo
            best_phrase = frases[max_idx]

    # Si no cumple threshold, devolver mejor absoluto
    if best_group is None:
        grupo = top_groups[0][0]
        embeddings = self.grupos_embeddings[grupo]
        frases = self.grupos_frases[grupo]
        similarities = cosine_similarity([query_embedding], embeddings)[0]
        max_idx = np.argmax(similarities)
        best_similarity = clip_similarity(similarities[max_idx])
        best_group = grupo
        best_phrase = frases[max_idx]

    return best_group, best_phrase, best_similarity
\end{lstlisting}

{\large \noindent \textbf{Método \texttt{find\_best\_groups()}}}

\begin{lstlisting}
def find_best_groups(self, query: str, top_k: int = 3) -> List[Tuple[str, float]]:
    """
    Top-K grupos mas probables usando centroides.
    """

    query_prep = preprocess_query(query)

    self._load_model()

    query_embedding = self.model.encode([query_prep])[0]

    group_scores = []
    for grupo, centroid in self.grupos_centroids.items():
        similarity = cosine_similarity(
            [query_embedding],
            [centroid]
        )[0][0]
        group_scores.append((grupo, similarity))

    group_scores.sort(key=lambda x: x[1], reverse=True)
    return group_scores[:top_k]
\end{lstlisting}

\vspace{1em}
{\large \noindent \textbf{Método \texttt{\_calculate\_centroids()}}}

\begin{lstlisting}
def _calculate_centroids(self):
    """
    Calcula el centroide de cada grupo.
    Usado en la busqueda por centroides.
    """
    self.grupos_centroids = {}

    for grupo, embeddings in self.grupos_embeddings.items():
        centroid = np.mean(embeddings, axis=0)
        self.grupos_centroids[grupo] = centroid

        logger.debug(
            f"Centroide calculado para grupo {grupo}: "
            f"shape={centroid.shape}"
        )
\end{lstlisting}

\newpage
{\large \noindent \textbf{Funciones auxiliares}}

\begin{lstlisting}
def clip_similarity(similarity: float) -> float:
    """
    Asegura que la similitud este en rango [0.0, 1.0].
    """
    return np.clip(similarity, 0.0, 1.0)
\end{lstlisting}

\vspace{1em}
{\large \noindent \textbf{Preprocesamiento de Texto (\texttt{preprocess.py})}}\\

{\large \noindent \textbf{Función \texttt{normalize\_text()}}}
\begin{lstlisting}[language=Python]
def normalize_text(text: str) -> str:
    """
    Normalización básica de texto.

    Pipeline:
    1. Convertir a minúsculas
    2. Remover acentos
    3. Remover puntuación
    4. Normalizar espacios

    Ejemplo:
    "¡Hóla!  ¿Cómo   estás?" → "hola como estas"
    """
    # 1. Minúsculas
    text = text.lower()

    # 2. Remover acentos (NFD normalization)
    text = unicodedata.normalize('NFD', text)
    text = ''.join(
        char for char in text
        if unicodedata.category(char) != 'Mn'
    )

    # 3. Remover puntuación
    text = text.translate(
        str.maketrans('', '', string.punctuation)
    )

    # 4. Normalizar espacios
    text = ' '.join(text.split())

    return text.strip()
\end{lstlisting}

\newpage
{\large \noindent \textbf{Función \texttt{preprocess\_query()}}}
\begin{lstlisting}[language=Python]
def preprocess_query(query: str) -> str:
    """
    Preprocesamiento avanzado de queries de usuario.

    Pipeline:
    1. Normalización básica
    2. Corrección ortográfica (typos comunes)
    3. Normalización de caracteres repetidos

    Ejemplo:
    "olaaaa, k ase?" → "hola que hace"
    """
    # 1. Normalización básica
    text = normalize_text(query)

    # 2. Corrección ortográfica
    typos_comunes = {
        'ola': 'hola',
        'k': 'que',
        'ase': 'hace',
        'ayda': 'ayuda',
        'grcias': 'gracias',
        'bn': 'bien',
        'xfa': 'por favor'
    }

    words = text.split()
    corrected_words = []

    for word in words:
        if word in typos_comunes:
            corrected_words.append(typos_comunes[word])
        else:
            corrected_words.append(word)

    text = ' '.join(corrected_words)

    # 3. Normalizar caracteres repetidos
    text = re.sub(r'(.)\1{2,}', r'\1', text)

    return text.strip()
\end{lstlisting}

\newpage
{\large \noindent \textbf{Función \texttt{normalize\_leet\_speak()}}}
\begin{lstlisting}[language=Python]
def normalize_leet_speak(text: str) -> str:
	"""
	Normaliza leet speak a texto normal.

	Mapeo de caracteres:
	@ → a 	Ejemplo: "M4ri@" → "Maria"
	4 → a          	"Ju4n" → "Juan"
	3 → e          	"P3dro" → "Pedro"
	1 → i          	"1van" → "Ivan"
	0 → o          	"Carl0s" → "Carlos"
	5 → s          	"Jo5e" → "Jose"
	7 → t          	"Ma7eo" → "Mateo"
	8 → b          	"E8an" → "Eban"

	Casos especiales:
	- Preservar números en contextos válidos
	- Aplicar solo cuando mejora legibilidad
	"""
	leet_map = {
    	'@': 'a',
    	'4': 'a',
    	'3': 'e',
    	'1': 'i',
    	'0': 'o',
    	'5': 's',
    	'7': 't',
    	'8': 'b',
    	'9': 'g',
    	'$': 's'
	}

	result = []
	for char in text:
    	if char in leet_map:
        	result.append(leet_map[char])
    	else:
        	result.append(char)

	return ''.join(result)
\end{lstlisting}

\newpage
{\large \noindent \textbf{Función \texttt{spell\_out\_text()}}}
\begin{lstlisting}[language=Python]
def spell_out_text(text: str, include_spaces: bool = True) -> List[str]:
	"""
	Deletrea un texto carácter por carácter.

	Características:
	- Maneja letras (A-Z)
	- Maneja números (0-9)
	- Maneja caracteres especiales
	- Opción de incluir espacios

	Ejemplo:
	spell_out_text("Hola Mundo", include_spaces=True)
	→ ["H", "O", "L", "A", "espacio", "M", "U", "N", "D", "O"]

	spell_out_text("Hola Mundo", include_spaces=False)
	→ ["H", "O", "L", "A", "M", "U", "N", "D", "O"]
	"""
	# Mapeo de caracteres especiales
	special_chars = {
    	'.': 'punto',
    	',': 'coma',
    	';': 'punto y coma',
    	':': 'dos puntos',
    	'!': 'exclamación',
    	'?': 'interrogación',
    	'-': 'guión',
    	'_': 'guión bajo',
    	'@': 'arroba',
    	'#': 'numeral',
    	'$': 'dólar',
    	'%': 'porciento',
    	'&': 'ampersand',
    	'*': 'asterisco',
    	'+': 'más',
    	'=': 'igual',
    	'/': 'barra',
    	'\\': 'barra invertida',
    	'(': 'paréntesis abierto',
    	')': 'paréntesis cerrado',
    	'[': 'corchete abierto',
    	']': 'corchete cerrado',
    	'{': 'llave abierta',
    	'}': 'llave cerrada',
    	'<': 'menor que',
    	'>': 'mayor que',
    	'|': 'barra vertical',
    	'~': 'tilde',
    	'`': 'acento grave',
    	'"': 'comillas',
    	"'": 'apóstrofo'
	}

	result = []

	for char in text:
    	# Letras
    	if char.isalpha():
        	result.append(char.upper())

    	# Números
    	elif char.isdigit():
        	result.append(char)

    	# Espacio
    	elif char == ' ':
        	if include_spaces:
            	result.append('espacio')

    	# Caracteres especiales
    	elif char in special_chars:
        	result.append(special_chars[char])

	return result
\end{lstlisting}

{\large \noindent \textbf{Función: preprocess\_phrases()}}
\begin{lstlisting}[language=Python]
def preprocess_phrases(phrases: List[str]) -> List[str]:
	"""
	Preprocesa todas las frases del dataset.

	Usado al inicializar el sistema para:
	- Normalizar frases del dataset
	- Preparar para generación de embeddings

	Ejemplo:
	["¡Hóla!", "¿Cómo estás?"] → ["hola", "como estas"]
	"""
	return [normalize_text(phrase) for phrase in phrases]
\end{lstlisting}

{\large \noindent \textbf{Gestión de datos (\texttt{groups.py})}}

{\noindent \textbf{Función: load\_groups()}}
\begin{lstlisting}
def load_groups(json_path: str = "data/grupos.json") -> Dict[str, List[str]]:
    """
    Carga grupos de frases desde archivo JSON.
    """
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)

        if "grupos" not in data:
            raise KeyError("El JSON debe contener la clave 'grupos'")

        grupos = data["grupos"]

        if not grupos:
            raise ValueError("El JSON no contiene grupos")

        for grupo, frases in grupos.items():
            if not isinstance(frases, list):
                raise TypeError(f"Grupo {grupo} debe ser una lista")
            if not frases:
                raise ValueError(f"Grupo {grupo} está vacío")

        logger.info(
            f"Grupos cargados: {len(grupos)} grupos, "
            f"{sum(len(f) for f in grupos.values())} frases"
        )

        return grupos

    except FileNotFoundError:
        logger.error(f"Archivo no encontrado: {json_path}")
        raise
    except json.JSONDecodeError as e:
        logger.error(f"Error al parsear JSON: {e}")
        raise
    except Exception as e:
        logger.error(f"Error al cargar grupos: {e}")
        raise
\end{lstlisting}

\newpage
{\noindent \textbf{Función \texttt{get\_all\_phrases()}}}
\begin{lstlisting}[language=Python]
def get_all_phrases() -> Dict[str, List[str]]:
    """
    Retorna todos los grupos y frases.

    Usa cache global para evitar recargas.
    """
    global _cached_groups

    if _cached_groups is None:
        _cached_groups = load_groups()

    return _cached_groups
\end{lstlisting}

{\noindent \textbf{Función \texttt{get\_group\_phrases()}}}
\begin{lstlisting}[language=Python]
def get_group_phrases(grupo: str) -> List[str]:
    """
    Retorna frases de un grupo específico.

    Args:
        grupo: Identificador del grupo ("A", "B", "C")

    Returns:
        Lista de frases del grupo

    Raises:
        KeyError: Si el grupo no existe
    """
    grupos = get_all_phrases()

    if grupo not in grupos:
        raise KeyError(
            f"Grupo '{grupo}' no existe. "
            f"Grupos disponibles: {list(grupos.keys())}"
        )

    return grupos[grupo]
\end{lstlisting}

\newpage
{\noindent \textbf{Estructura del JSON: \texttt{data/grupos.json}}}
\begin{lstlisting}
{
  "grupos": {
    "A": [
      "Ayuda, por favor",
      "Llama a la policía",
      "Necesito un médico",
      "Estoy herido",
      "¿Dónde está el hospital?",
      "Es una emergencia",
      "Incendio",
      "¡Alto!",
      "Estoy sangrando",
      "¿Necesitas ayuda?",
      "¿Dónde está la salida?",
      "Auxilio",
      "Socorro"
    ],
    "B": [
      "Hola",
      "¿Cómo estás?",
      "Buenos días",
      "Buenas tardes",
      "Buenas noches",
      "Bienvenido",
      "Mucho gusto",
      "¿Cómo te llamas?",
      "Me llamo",
      "Nos vemos",
      "Me voy",
      "Adiós",
      "Hasta luego"
    ],
    "C": [
      "Gracias",
      "Muchas gracias",
      "Te lo agradezco",
      "Bien",
      "Mal",
      "Soy sordo",
      "Entiendo",
      "No entiendo",
      "Sí",
      "No",
      "No lo sé",
      "Perdón",
      "Disculpa",
      "Lo siento",
      "De acuerdo",
      "Vale",
      "Espera"
    ]
  }
}
\end{lstlisting}

\vspace{1em}
{\large \noindent \textbf{Sistema de \textit{embeddings}}}\\
{\textbf \textbf{Generación de \textit{Embeddings}}}
\begin{lstlisting}[language=Python]
def _generate_and_cache_embeddings(self):
    """
    Genera embeddings para todas las frases y los cachea.

    Proceso:
    1. Cargar modelo de transformers
    2. Preprocesar frases
    3. Generar embeddings por grupo
    4. Guardar en archivo .npz

    Tiempo estimado: ~5 segundos (primera vez)
    """
    logger.info("Generando embeddings (esto puede tardar unos segundos)...")

    # 1. Cargar modelo
    self._load_model()

    # 2. Generar embeddings por grupo
    for grupo, frases in self.grupos_frases.items():
        # Preprocesar frases
        frases_prep = preprocess_phrases(frases)

        # Generar embeddings
        embeddings = self.model.encode(
            frases_prep,
            show_progress_bar=True,
            batch_size=32
        )

        self.grupos_embeddings[grupo] = embeddings

        logger.info(
            f"Grupo {grupo}: {len(frases)} frases, "
            f"embedding shape: {embeddings.shape}"
        )

    # 3. Guardar en cache
    self._save_to_cache()
\end{lstlisting}

\vspace{0.5em}
{\noindent \textbf{Guardado en caché}}
\begin{lstlisting}[language=Python]
def _save_to_cache(self):
    logger.info(f"Guardando embeddings en cache: {self.cache_path}")

    # Crear directorio si no existe
    os.makedirs(os.path.dirname(self.cache_path), exist_ok=True)

    # Preparar diccionario para guardar
    cache_data = {}

    for grupo, embeddings in self.grupos_embeddings.items():
        cache_data[f'{grupo}_embeddings'] = embeddings
        cache_data[f'{grupo}_frases'] = np.array(
            self.grupos_frases[grupo]
        )

    # Guardar en formato .npz comprimido
    np.savez_compressed(self.cache_path, **cache_data)

    # Verificar tamaño del archivo
    file_size = os.path.getsize(self.cache_path) / 1024 / 1024  # MB
    logger.info(f"Cache guardado exitosamente ({file_size:.2f} MB)")
\end{lstlisting}

\newpage
{\noindent \textbf{Carga desde caché}}
\begin{lstlisting}[language=Python]
def _load_from_cache(self):
    logger.info(f"Cargando embeddings desde cache: {self.cache_path}")

    try:
        # Cargar archivo .npz
        data = np.load(self.cache_path, allow_pickle=True)

        # Reconstruir diccionarios
        for key in data.files:
            if key.endswith('_embeddings'):
                grupo = key.split('_')[0]
                self.grupos_embeddings[grupo] = data[key]
            elif key.endswith('_frases'):
                grupo = key.split('_')[0]
                self.grupos_frases[grupo] = data[key].tolist()

        logger.info(
            f"Cache cargado: {len(self.grupos_embeddings)} grupos, "
            f"{sum(len(e) for e in self.grupos_embeddings.values())} frases"
        )

    except Exception as e:
        logger.error(f"Error al cargar cache: {e}")
        logger.info("Regenerando embeddings...")
        self._generate_and_cache_embeddings()
\end{lstlisting}

\newpage
{\noindent \textbf{Formato del \textit{embedding}}}
\begin{lstlisting}
Input: "Hola, ¿cómo estás?"
   ↓
Preprocesamiento: "hola como estas"
   ↓
Tokenización: [CLS] hola como estas [SEP]
   ↓
Transformer (12 layers)
   ↓
Mean Pooling
   ↓
L2 Normalization
   ↓
Output: Vector [384]
   [
        0.123, -0.456, 0.789, -0.234, 0.567, ...  (384 valores)
   ]
\end{lstlisting}

\vspace{1em}
\noindent \textbf{Métricas}

\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.6}
\begin{tabular}{|p{6cm}|p{6cm}|}
\hline
\textbf{Métrica} & \textbf{Valor} \\ \hline

Dimensión del \textit{embedding} & 384 \\ \hline
Tamaño por \textit{embedding} & 384 × 4 bytes = 1.5 KB \\ \hline
\textit{Total embeddings} en memoria & 43 frases × 1.5 KB $\approx$ 65 KB \\ \hline
Tamaño del cache (.npz) & $\sim$50 KB (comprimido) \\ \hline
Tiempo de generación (1ª vez) & $\sim$5 segundos \\ \hline
Tiempo de carga (desde cache) & <1 segundo \\ \hline
Memoria usada (modelo) & $\sim$420 MB \\ \hline
Memoria usada (cache) & 65 KB \\ \hline

\end{tabular}
\caption[Métricas del embedding]{Métricas del \textit{embedding}, elaboración propia.}
\end{table}

%#---------------------------------
%#---------------------------------
\newpage
\subsection{Etapa 1: Preprocesamiento de texto}

\noindent \textbf{Normalización de texto}

\noindent \textbf{Objetivos}
\begin{itemize}
    \item Estandarizar formato del texto.
    \item Eliminar variaciones irrelevantes.
    \item Mejorar \textit{matching} de similitud.
    \item Reducir vocabulario efectivo.
\end{itemize}

\noindent \textbf{Pipeline de normalización}

\begin{verbatim}
Input: "¡Hóla!  ¿Cómo   estás? [emoji]"
   ↓
[1] Conversión a minúsculas
   ↓
   "¡hóla!  ¿cómo   estás? [emoji]"
   ↓
[2] Eliminación de acentos (NFD Normalization)
   ↓
   "¡hola!  ¿como   estas? [emoji]"
   ↓
[3] Remoción de puntuación
   ↓
   "hola  como   estas [emoji]"
   ↓
[4] Remoción de emojis / símbolos especiales
   ↓
   "hola  como   estas"
   ↓
[5] Normalización de espacios
   ↓
   "hola como estas"
   ↓
Output: "hola como estas"
\end{verbatim}

% ------------------------------------------------------------
% PASO 1
% ------------------------------------------------------------
\newpage
{\large \noindent \textbf{Implementación paso a paso}} \\
{\large \noindent \textbf{Paso 1: Conversión a minúsculas}}
\begin{lstlisting}[language=python]
text = text.lower()
\end{lstlisting}

\noindent \textbf{Justificación:}
\begin{itemize}
    \item ``Hola'' y ``hola'' son semánticamente iguales.
    \item Reduce vocabulario a la mitad.
    \item Simplifica \textit{matching}.
\end{itemize}

\noindent \textbf{Ejemplos:}
\begin{itemize}
    \item ``HOLA'' → ``hola''.
    \item ``Buenos Días'' → ``buenos días''.
    \item ``¿CÓMO ESTÁS?'' → ``¿cómo estás?''.
\end{itemize}

% ------------------------------------------------------------
% PASO 2
% ------------------------------------------------------------
\vspace{1em}
{\large \noindent \textbf{Paso 2: Eliminación de acentos}}
\begin{lstlisting}[language=python]
import unicodedata

text = unicodedata.normalize('NFD', text)
text = ''.join(
    char for char in text
    if unicodedata.category(char) != 'Mn'
)
\end{lstlisting}

\noindent \textbf{Explicación técnica:}
\begin{itemize}
    \item \textit{NFD: Normalization Form Canonical Decomposition}.
    \item ``á'' → ``a'' + acento (base + diacrítico).
    \item Categoría ``Mn'': Mark, \textit{Nonspacing} (diacríticos).
    \item Filtrar categoría ``Mn'' elimina acentos.
\end{itemize}

\noindent \textbf{Ejemplos:}
\begin{itemize}
    \item ``más'' → ``mas''.
    \item ``José'' → ``jose''.
    \item ``¿Cómo?'' → ``¿como?''.
    \item ``café'' → ``cafe''.
\end{itemize}

\noindent \textbf{Ventajas:}
\begin{itemize}
    \item Typos de acentos no afectan \textit{matching}.
    \item ``hola'' = ``hóla'' = ``holá''.
    \item Útil para usuarios sin teclado en español.
\end{itemize}

% ------------------------------------------------------------
% PASO 3
% ------------------------------------------------------------
\vspace{1em}
{\large \noindent \textbf{Paso 3: Remoción de puntuación}}
\begin{lstlisting}[language=python]
import string

text = text.translate(
    str.maketrans('', '', string.punctuation)
)
\end{lstlisting}

\noindent \textbf{Puntuación eliminada:}

\begin{verbatim}
!"#$%&'()*+,-./:;<=>?@[\]^_`{|}~
\end{verbatim}

\noindent \textbf{Ejemplos:}
\begin{itemize}
    \item ``¡Hola!'' → ``Hola''.
    \item ``¿Cómo estás?'' → ``Como estas''.
    \item ``Bien, gracias.'' → ``Bien gracias''.
\end{itemize}

\noindent \textbf{Casos preservados:}
\begin{itemize}
    \item Números con punto decimal: ``3.14''.
    \item URLs (manejadas en otro preprocesado).
\end{itemize}

% ------------------------------------------------------------
% PASO 4
% ------------------------------------------------------------
\vspace{1em}
{\large \noindent \textbf{Paso 4: Normalización de espacios}}
\begin{lstlisting}[language=python]
text = ' '.join(text.split())
\end{lstlisting}

\noindent \textbf{Funcionalidad:}
\begin{itemize}
    \item \texttt{.split()} divide por cualquier \textit{whitespace}.
    \item \texttt{' '.join()} une con un solo espacio.
\end{itemize}

\newpage
\noindent \textbf{Ejemplos:}
\begin{itemize}
    \item ``hola  mundo'' → ``hola mundo''.
    \item ``hola\verb|\|nmundo'' → ``hola mundo''.
    \item ``  hola  '' → ``hola''.
    \item ``hola\verb|\|t\verb|\|tmundo'' → ``hola mundo''.
\end{itemize}

% ------------------------------------------------------------
% CASOS EDGE
% ------------------------------------------------------------
\vspace{1em}
{\large \noindent \textbf{Casos EDGE manejados}}

\begin{itemize}
    \item \textbf{Texto vacío:} ``'' → ``''
    \item \textbf{Solo espacios:} ``   '' → ``''
    \item \textbf{Caracteres especiales:} emojis → eliminados
    \item \textbf{Números:} ``Hola 123'' → ``hola 123''
    \item \textbf{Texto mixto:} ``¡¡HOLA!! ¿Cómo   estás?'' → ``hola como estas''
\end{itemize}

% ------------------------------------------------------------
% CORRECCIÓN ORTOGRÁFICA
% ------------------------------------------------------------

{\large \noindent \textbf{Corrección ortográfica con RapidFuzz}} 
\noindent \textbf{Objetivo:}  
Detectar y corregir typos comunes:

\begin{itemize}
    \item ``ola'' → ``hola''.
    \item ``graias'' → ``gracias''.
    \item ``k ase'' → ``que hace''.
\end{itemize}

\noindent \textbf{Algoritmo: Levenshtein Distance}

\textbf{Definición:}\\
Distancia de edición mínima entre dos \textit{strings} (inserciones, eliminaciones, sustituciones) \cite{refimpl17}.

\begin{verbatim}
"kitten" → "sitting"
↓
1. kitten → sitten  (sustitución)
2. sitten → sittin  (sustitución)
3. sittin → sitting (inserción)

Distancia = 3 operaciones
\end{verbatim}

\newpage
\noindent \textbf{RapidFuzz \cite{refimpl4}:}
\begin{itemize}
    \item Implementación optimizada en C++.
    \item 5-10x más rápida que difflib.
    \item Usada en VSCode y GitHub Copilot.
\end{itemize}

\noindent \textbf{Implementación:}

\begin{lstlisting}[language=python]
from rapidfuzz import fuzz

def correct_typo(word: str, dictionary: List[str]) -> str:
    """
    Corrige typo comparando con diccionario.

    Algoritmo:
    1. Calcular similitud con cada palabra del diccionario
    2. Si similitud > 80%, reemplazar
    3. Usar la palabra más similar
    """
    best_match = None
    best_score = 0

    for dict_word in dictionary:
        score = fuzz.ratio(word, dict_word)
        if score > best_score:
            best_score = score
            best_match = dict_word

    # Threshold: 80%
    if best_score >= 80:
        return best_match
    else:
        return word
\end{lstlisting}

\newpage
\noindent \textbf{Diccionario de Typos Comunes}

\begin{lstlisting}[language=Python]
TYPOS_COMUNES = {
    # Saludos
    'ola': 'hola',
    'hla': 'hola',
    'ols': 'hola',

    # Preguntas
    'k': 'que',
    'q': 'que',
    'ke': 'que',
    'qe': 'que',

    # Acciones
    'ase': 'hace',
    'acer': 'hacer',
    'aces': 'haces',

    # Ayuda
    'ayda': 'ayuda',
    'ayud': 'ayuda',
    'auyda': 'ayuda',

    # Gracias
    'grcias': 'gracias',
    'gracia': 'gracias',
    'graias': 'gracias',

    # Otros
    'bn': 'bien',
    'vien': 'bien',
    'xfa': 'por favor',
    'porfavor': 'por favor',
    'xq': 'porque',
    'porke': 'porque'
}
\end{lstlisting}

\vspace{0.5em}
{\large \noindent \textbf{Ejemplos de corrección}}

\noindent \textbf{Caso 1: Typo simple}

\noindent \textit{Input}: ``ola como estas''\\
↓\\
Detección: ``ola'' $\rightarrow$ similitud con ``hola'' = 75\%\\
↓\\
Corrección: ``hola como estas''

\bigskip

\noindent \textbf{Caso 2: Múltiples typos}

\noindent \textit{Input}: ``k ase, grcias''\\
↓\\
Correcciones:
\begin{itemize}
    \item ``k'' $\rightarrow$ ``que''
    \item ``ase'' $\rightarrow$ ``hace''
    \item ``grcias'' $\rightarrow$ ``gracias''
\end{itemize}
↓\\
\textit{Output}: ``que hace, gracias''

\bigskip

\noindent \textbf{Caso 3: Sin typos}

\noindent \textit{Input}: ``necesito ayuda''\\
↓\\
No hay correcciones\\
↓\\
\textit{Output}: ``necesito ayuda''\\

\noindent \textbf{Métricas de corrección}

\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.6}
\begin{tabular}{|p{6cm}|p{6cm}|}
\hline
\textbf{Métrica} & \textbf{Valor} \\ \hline
Typos detectados correctamente & 95\% \\ \hline
Falsos positivos & $<$5\% \\ \hline
Tiempo de corrección por palabra & $<$1ms \\ \hline
Tamaño del diccionario & 50+ términos \\ \hline
\end{tabular}
\caption[Métricas del sistema]{Métricas del sistema, elaboración propia.}
\end{table}

{\large \noindent \textbf{Normalización de \textit{Leet Speak}}}

\textbf{Objetivo}

Convertir \textit{leet speak} a texto normal para mejorar la detección de nombres propios \cite{refimpl15}.\\

\textbf{Casos}:
\begin{itemize}
    \item Nombres en redes sociales: ``M4ri@'', ``Ju4n''.
    \item Texto decorativo: ``H0l4'', ``Gr4ci4s''.
    \item Evasión de filtros: ``A\$\$istente''.
\end{itemize}

\textbf{Mapeo de Caracteres}

\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.6}
\begin{tabular}{|p{2cm}|p{3cm}|p{7cm}|}
\hline
\textbf{Leet} & \textbf{Normal} & \textbf{Ejemplo} \\ \hline
@ & a & M@ria $\rightarrow$ Maria \\ \hline
4 & a & M4ria $\rightarrow$ Maria \\ \hline
3 & e & P3dro $\rightarrow$ Pedro \\ \hline
1 & i & 1van $\rightarrow$ Ivan \\ \hline
0 & o & Carl0s $\rightarrow$ Carlos \\ \hline
5 & s & Jo5e $\rightarrow$ Jose \\ \hline
7 & t & Ma7eo $\rightarrow$ Mateo \\ \hline
8 & b & E8an $\rightarrow$ Eban \\ \hline
9 & g & San7ia9o $\rightarrow$ Santiago \\ \hline
\$ & s & \$andra $\rightarrow$ Sandra \\ \hline
\end{tabular}
\caption[Diccionario Leet]{Conversión de \textit{leet} a texto normal, elaboración propia.}
\end{table}


\noindent \textbf{Implementación}

\begin{lstlisting}[language=Python]
def normalize_leet_speak(text: str) -> str:
    """
    Convierte leet speak a texto normal.

    Algoritmo:
    1. Iterar cada carácter
    2. Si está en mapeo, reemplazar
    3. Si no, mantener original
    """
    leet_map = {
        '@': 'a', '4': 'a', '3': 'e', '1': 'i',
        '0': 'o', '5': 's', '7': 't', '8': 'b',
        '9': 'g', '$': 's'
    }

    result = []
    for char in text:
        result.append(leet_map.get(char, char))

    return ''.join(result)
\end{lstlisting}

\noindent \textbf{Ejemplos}\\

\textbf{Nombres}:
\begin{itemize}
    \item ``M4ri@'' $\rightarrow$ ``Maria''.
    \item ``Ju4n'' $\rightarrow$ ``Juan''.
    \item ``P3dr0'' $\rightarrow$ ``Pedro''.
    \item ``Carl0\$'' $\rightarrow$ ``Carlos''.
    \item ``1\$@b3l'' $\rightarrow$ ``Isabel''.
\end{itemize}

\textbf{Frases}:
\begin{itemize}
    \item ``H0l4 mund0'' $\rightarrow$ ``Hola mundo''.
    \item ``Gr4ci4\$ p0r t0d0'' $\rightarrow$ ``Gracias por todo''.
    \item ``N3c3\$it0 4yud4'' $\rightarrow$ ``Necesito ayuda''.
\end{itemize}

\textbf{Casos mixtos}:
\begin{itemize}
    \item ``M1 n0mbr3 3\$ M4ri@'' $\rightarrow$ ``Mi nombre es Maria''.
    \item ``Ju4n C4rl0\$'' $\rightarrow$ ``Juan Carlos''.
    \item ``4l3j4ndr0'' $\rightarrow$ ``Alejandro''.
\end{itemize}

\textbf{Casos especiales}
\begin{enumerate}
    \item Preservar números legítimos:\\
    
    \textit{Input}: ``Juan123''\\
    \textit{Output} incorrecto: ``Juania3''\\

    Solución: analizar contexto.

    \item Caracteres ambiguos:
    \begin{itemize}
    \item ``1'' puede ser i o l.
    \item ``0'' puede ser o u O.
    \end{itemize}

    Decisión: usar minúsculas.
\end{enumerate}

\newpage
{\large \noindent \textbf{Detección de Nombres Propios}}\\

{\large \noindent \textbf{Estrategia 1: Lista de nombres comunes}}

\begin{lstlisting}[language=Python]
COMMON_SPANISH_NAMES = {
    'juan', 'jose', 'antonio', 'manuel', 'francisco',
    'david', 'carlos', 'miguel', 'pedro', 'luis',
    'jesus', 'pablo', 'javier', 'sergio', 'rafael',
    'daniel', 'jorge', 'alberto', 'fernando', 'ricardo',

    'maria', 'carmen', 'ana', 'isabel', 'pilar',
    'teresa', 'rosa', 'laura', 'marta', 'elena',
    'sara', 'lucia', 'paula', 'sofia', 'cristina',
    'andrea', 'julia', 'raquel', 'beatriz', 'patricia'
}
\end{lstlisting}

Algoritmo:
\begin{lstlisting}[language=Python]
nombre_normalizado = normalize_text(palabra)
if nombre_normalizado in COMMON_SPANISH_NAMES:
    return True
\end{lstlisting}

Cobertura: $\sim$70\%.

\vspace{0.7em}

{\large \noindent \textbf{Estrategia 2: Capitalización}}

\noindent \textbf{Patrón de nombre propio:}
\begin{itemize}
    \item Primera letra mayúscula.
    \item Resto en minúsculas.
    \item Longitud 3-15 caracteres.
\end{itemize}

\begin{lstlisting}[language=Python]
def is_proper_noun_by_capitalization(word: str) -> bool:
    """
    Detecta nombre por capitalización.

    Ejemplos válidos:
    -"Juan"
    -"Maria"
    -"Alessandro"

    Ejemplos inválidos:
    -"juan" (todo minúsculas)
    -"JUAN" (todo mayúsculas)
    -"JuAn" (capitalización irregular)
    """
    if len(word) < 3 or len(word) > 15:
        return False

    if not word[0].isupper():
        return False

    if not word[1:].islower():
        return False

    return True
\end{lstlisting}

\vspace{1em}
\textbf{Ventajas:}
\begin{itemize}
    \item Detecta nombres que no están en la lista.
    \item Funciona con nombres extranjeros.
    \item No requiere diccionario grande.
\end{itemize}

\textbf{Desventajas:}
\begin{itemize}
    \item Requiere capitalización correcta.
    \item Puede detectar falsos positivos (inicio de oración).
\end{itemize}

\vspace{0.7em}

{\large \noindent \textbf{Estrategia 3: Validación por ausencia en \textit{dataset}}}\\

\noindent \textbf{Lógica:}
Si una palabra:
\begin{itemize}
    \item NO está en el dataset de frases.
    \item Tiene similitud media (0.50-0.85).
    \item Tiene longitud de nombre (3-8 chars).
\end{itemize}

Entonces: Probablemente es un nombre.

\begin{lstlisting}[language=Python]
def is_name_by_absence(word: str, dataset_words: Set[str]) -> bool:
    """
    Detecta nombre por ausencia en dataset.
    """
    word_norm = normalize_text(word)

    # Verificar longitud
    if not (3 <= len(word_norm) <= 8):
        return False

    # Verificar ausencia en dataset
    if word_norm in dataset_words:
        return False

    return True
\end{lstlisting}

\vspace{1em}
{\large \noindent \textbf{Estrategia combinada}}

\begin{lstlisting}[language=Python]
def detect_name(word: str, similarity: float) -> bool:
    """
    Combina las 3 estrategias para máxima precisión.
    """
    # Estrategia 1: Lista de nombres comunes
    if word.lower() in COMMON_SPANISH_NAMES:
        return True

    # Estrategia 2: Capitalización
    if is_proper_noun_by_capitalization(word):
        if similarity < 0.98:  # No es match exacto
            return True

    # Estrategia 3: Ausencia en dataset
    if is_name_by_absence(word, dataset_words):
        if 0.50 <= similarity < 0.85:
            return True

    return False
\end{lstlisting}

Precisión combinada: $\sim$92\%.\\

{\large \noindent \textbf{Detección de patrones}}

\textbf{Patrones reconocidos:}
\begin{enumerate}
    \item ``Me llamo [NOMBRE]''.
    \item ``Mi nombre es [NOMBRE]''.
    \item ``Soy [NOMBRE]''.
\end{enumerate}

\newpage
\textbf{Algoritmo:}

\begin{lstlisting}[language=Python]
def extract_name_from_pattern(query: str):
    """
    Extrae nombre de patrones específicos.
    """
    query_norm = normalize_text(query)
    words = query_norm.split()

    # Patrón 1: "me llamo X"
    if words[:2] == ["me", "llamo"] and len(words) > 2:
        return " ".join(words[2:])

    # Patrón 2: "mi nombre es X"
    if words[:3] == ["mi", "nombre", "es"] and len(words) > 3:
        return " ".join(words[3:])

    # Patrón 3: "soy X"
    if words[0] == "soy" and len(words) > 1:
        return " ".join(words[1:])

    return None
\end{lstlisting}

Ejemplos:

\begin{itemize}
    \item ``Me llamo Juan'' → ``Juan''.
    \item ``Mi nombre es Maria'' → ``Maria''.
    \item ``Soy Alessandro'' → ``Alessandro''.
    \item ``Me llamo Juan Carlos'' → ``Juan Carlos''.
\end{itemize}

{\large \noindent \textbf{Sistema de deletreo ``automático''}}\\

\noindent \textbf{Objetivo}: Convertir texto a lista de caracteres individuales para reproducción de videos de señas letra por letra.\\

\noindent \textbf{Casos de uso:}
\begin{itemize}
    \item Nombres propios: ``Alessandro'' → [A, L, E, S, S, A, N, D, R, O].
    \item Palabras desconocidas: ``xyz'' → [X, Y, Z].
    \item Textos personalizados: ``Hola Mundo'' → [H, O, L, A, espacio, ...].
\end{itemize}

\newpage
\textbf{Algoritmo:}

\begin{lstlisting}[language=Python]
def spell_out_text(text: str, include_spaces: bool = True) -> List[str]:
    result = []

    for char in text:
        # Letras (A-Z, a-z)
        if char.isalpha():
            result.append(char.upper())

        # Números (0-9)
        elif char.isdigit():
            result.append(char)

        # Espacio
        elif char == ' ':
            if include_spaces:
                result.append('espacio')

        # Caracteres especiales
        elif char in SPECIAL_CHARS:
            result.append(SPECIAL_CHARS[char])

    return result
\end{lstlisting}

{\large \noindent \textbf{Manejo de caracteres especiales}}

\begin{lstlisting}[language=Python]
SPECIAL_CHARS = {
    '.': 'punto',
    ',': 'coma',
    ';': 'punto y coma',
    ':': 'dos puntos',
    '!': 'exclamación',
    '?': 'interrogación',
    '-': 'guión',
    '_': 'guión bajo',
    '@': 'arroba',
    '#': 'numeral',
    '$': 'dólar',
    '%': 'porciento',
    '&': 'ampersand',
    '*': 'asterisco',
    '+': 'más',
    '=': 'igual',
    '/': 'barra',
    '\\\\': 'barra invertida',
    '(': 'paréntesis abierto',
    ')': 'paréntesis cerrado',
    '[': 'corchete abierto',
    ']': 'corchete cerrado',
    '{': 'llave abierta',
    '}': 'llave cerrada',
    '<': 'menor que',
    '>': 'mayor que'
}
\end{lstlisting}

{\large \noindent \textbf{Ejemplos de deletreo}}

\noindent \textbf{Ejemplo 1: Nombre simple}

\begin{verbatim}
Input:  "Juan"
Output: ["J", "U", "A", "N"]
\end{verbatim}

\noindent \textbf{Ejemplo 2: Nombre compuesto (sin espacios)}

\begin{verbatim}
Input:  "Juan Carlos"
include_spaces: False
Output: ["J", "U", "A", "N", "C", "A", "R", "L", "O", "S"]
\end{verbatim}

\noindent \textbf{Ejemplo 3: Nombre compuesto (con espacios)}

\begin{verbatim}
Input:  "Juan Carlos"
include_spaces: True
Output: ["J", "U", "A", "N", "espacio", "C", "A", "R", "L", "O", "S"]
\end{verbatim}

\noindent \textbf{Ejemplo 4: Con números}

\begin{verbatim}
Input:  "Juan123"
Output: ["J", "U", "A", "N", "1", "2", "3"]
\end{verbatim}

\noindent \textbf{Ejemplo 5: Con caracteres especiales}

\begin{verbatim}
Input:  "Hola!"
Output: ["H", "O", "L", "A", "exclamación"]
\end{verbatim}

\noindent \textbf{Ejemplo 6: Email}

\begin{verbatim}
Input:  "juan@email.com"
Output: ["J", "U", "A", "N", "arroba", "E", "M", "A", "I", "L",
         "punto", "C", "O", "M"]
\end{verbatim}

\newpage
{\large \noindent \textbf{Optimizaciones}}

\begin{enumerate}
    \item \textbf{Filtrado de caracteres no soportados}
    \begin{itemize}
        \item Emojis son omitidos.
        \item Caracteres \textit{Unicode} especiales omitidos.
        \item Solo caracteres ASCII y especiales definidos.
    \end{itemize}

    \item \textbf{Normalización previa} \\
    Aplicar \verb|normalize_leet_speak()| antes de deletrear \\
    \verb|"M4ri@" → "Maria" → ["M", "A", "R", "I", "A"]|

    \item \textbf{\textit{Uppercase} automático} \\
    Todas las letras en mayúsculas para consistencia en la salida.
\end{enumerate}

{\large \noindent \textbf{Integración con videos}}
\begin{verbatim}
videos/
|-- letras/
|   |-- a.mp4
|   |-- b.mp4
|   |-- c.mp4
|   ...
|   `-- z.mp4
|-- numeros/
|   |-- 0.mp4
|   |-- 1.mp4
|   ...
|   `-- 9.mp4
`-- especiales/
    |-- espacio.mp4
    |-- punto.mp4
    |-- coma.mp4
    `-- ...
\end{verbatim}


%====================================================
\newpage
\subsection{Etapa 2: Modelo de \textit{embeddings} y similitud semántica}

{\large \noindent \textbf{Selección del modelo de \textit{embeddings}}}

\noindent \textbf{Modelos evaluados}

\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.5}
\begin{tabular}{|p{7cm}|p{3.2cm}|p{2.2cm}|p{2cm}|}
\hline
\textbf{Modelo} & \textbf{Dimensiones} & \textbf{Tamaño} & \textbf{Score} \\ \hline

\textbf{all-MiniLM-L6-v2} & 384 & 80MB & 3 / 5 \\ 
\quad + Rápido y ligero & & & \\
\quad - No optimizado para el idioma español & & & \\
\quad - \textit{Performance} bajo en paráfrasis ES & & & \\ \hline

\textbf{paraphrase-multilingual-mpnet-base-v2} & 768 & 420MB & 5 / 5 \\
\quad + Excelente para el idioma español & & & \\
\quad + Muy preciso en paráfrasis & & & \\
\quad - Muy grande (768 dim) & & & \\
\quad - Latencia alta ($\sim$80ms) & & & \\ \hline

\textbf{paraphrase-multilingual-MiniLM-L12-v2} & 384 & 420MB & 5 / 5 \\
\quad + Optimizado para el idioma español & & & \\
\quad + Balanceado: tamaño vs \textit{performance} & & & \\
\quad - Latencia aceptable ($\sim$40ms) & & & \\
\quad + \textit{Fine-tuned} para paráfrasis & & & \\ \hline

\textbf{sentence\_similarity\_spanish\_es} & 768 & 450MB & 4 / 5 \\
\quad + Específico para el idioma español & & & \\
\quad - Solo idioma español (no \textit{multilingual}) & & & \\
\quad - Menos flexible & & & \\ \hline

\end{tabular}
\caption[Comparación de modelos]{Comparación de modelos de \textit{embeddings}, elaboración propia.}
\end{table}

\newpage
\textbf{Criterios de selección}

\begin{enumerate}
    \item \textbf{Soporte multilingüe}
    \begin{itemize}
        \item \checkmark\ Requerido: Español como idioma principal.
        \item \checkmark\ Deseable: Soporte para otros idiomas latinos.
        \item $\rightarrow$ paraphrase-multilingual-MiniLM-L12-v2 \checkmark.
    \end{itemize}

    \item \textbf{Tamaño del \textit{embedding}}
    \begin{itemize}
        \item \checkmark\ Máximo: 512 dimensiones.
        \item \checkmark\ Óptimo: 384 dimensiones (balance).
        \item $\rightarrow$ 384 dimensiones \checkmark.
    \end{itemize}

    \item \textbf{\textit{Performance}}
    \begin{itemize}
        \item \checkmark\ Latencia objetivo: <50ms.
        \item \checkmark\ \textit{Throughput}: >20 req/s.
        \item $\rightarrow$ 40ms promedio \checkmark.
    \end{itemize}

    \item \textbf{Calidad de paráfrasis}
    \begin{itemize}
        \item \checkmark\ Detección de sinónimos.
        \item \checkmark\ Detección de variaciones.
        \item $\rightarrow$ \textit{Fine-tuned} específicamente \checkmark.
    \end{itemize}

    \item \textbf{Tamaño del modelo}
    \begin{itemize}
        \item \checkmark\ Máximo: 500MB.
        \item \checkmark\ Debe caber en RAM estándar (8GB).
        \item $\rightarrow$ 420MB \checkmark.
    \end{itemize}
\end{enumerate}

{\large \noindent \textbf{Modelo seleccionado}}\\
\indent\textbf{paraphrase-multilingual-MiniLM-L12-v2}\\

\noindent\textbf{Justificación}
\begin{itemize}
    \item Multilingüe (50+ idiomas, incluyendo español).
    \item 384 dimensiones (balance óptimo).
    \item \textit{Fine-tuned} para \textit{paraphrase detection}.
    \item Latencia aceptable ($\sim$40ms).
    \item Ampliamente usado en producción.
    \item Mantenido por UKPLab (confiable).
\end{itemize}

{\large \noindent \textbf{Arquitectura del Modelo \textit{Transformer}}}\\
\textbf{Arquitectura general}

\begin{center}
    \includegraphics[width=0.85\textwidth]{Images/Cap4/2_Arquitectura Transformers.png}
    \captionof{figure}[Arquitectura del Modelo Transformer]{Arquitectura General del Modelo \textit{Transformer}, elaboración propia.} 
\end{center}

{\large \noindent \textbf{Componentes detallados}}\\


\noindent \textbf{\textit{Tokenización} (\textit{WordPiece})}\\

\textbf{Vocabulario}: 119,547 \textit{tokens}.\\

\textbf{\textit{Tokens} especiales}
\begin{itemize}
    \item \textbf{[CLS]}: Inicio de secuencia (ID: 101).
    \item \textbf{[SEP]}: Separador/fin de secuencia (ID: 102).
    \item \textbf{[UNK]}: \textit{Token} desconocido (ID: 100).
    \item \textbf{[PAD]}: \textit{Padding} (ID: 0).
    \item \textbf{[MASK]}: Máscara para MLM (ID: 103).
\end{itemize}

\vspace{1em}

\noindent \textbf{Ejemplo de \textit{tokenización}}

\begin{verbatim}
"Hola, ¿cómo estás?"
   ↓
Tokens: [CLS] hola , ¿ como estas ? [SEP]
Token IDs: [101, 45321, 102, 189, 12045, 36547, 103, 102]
\end{verbatim}

\noindent\textbf{\textit{Subword tokenization}}

\begin{verbatim}
"Alessandro"
   ↓
Tokens: ale ##ss ##andro
Token IDs: [12345, 67890, 23456]
\end{verbatim}

\noindent \textbf{\textit{Embedding layer}}

Tres tipos de \textit{embeddings} combinados:

\begin{enumerate}[label=\alph*)]
    \item \textbf{\textit{Token Embeddings} (vocabulario → vector)}
    \begin{itemize}
    \item Cada \textit{token} ID → vector de 384 dimensiones.
    \item Matriz de \textit{embeddings}: [119,547 × 384].
    \end{itemize}
    \item \textbf{\textit{Position Embeddings} (posición → vector)}
    \begin{itemize}
    \item Cada posición → vector de 384 dimensiones.
    \item Máximo 512 posiciones.
    \item Permite al modelo saber el orden de los tokens.
    \end{itemize}
    \item \textbf{\textit{Token Type Embeddings} (segmento → vector)}
    \begin{itemize}
    \item Distingue entre segmentos A y B.
    \item Usado en tareas de pares de oraciones.
    \end{itemize}
\end{enumerate}

\begin{verbatim}
embedding_final = token_emb + position_emb + type_emb
\end{verbatim}

\newpage
{\large \noindent\textbf{\textit{Transformer layer}}}\\
\textbf{Arquitectura de una capa:}

\begin{center}
    \includegraphics[width=0.85\textwidth]{Images/Cap4/3_TransformerLayer.png}
    \captionof{figure}[Arquitectura de una Capa Modelo Transformer]{Arquitectura de una capa del modelo \textit{Transformer}, elaboración propia.} 
\end{center}

{\large \noindent \textbf{\textit{Self-attention mechanism}}}

\noindent \textbf{Ecuación}

\[
\text{Attention}(Q, K, V) = \text{softmax}\left( \frac{QK^{T}}{\sqrt{d_k}} \right) V
\]

Donde:
\begin{itemize}
    \item $Q$ (Query): ¿Qu\'e estoy buscando?.
    \item $K$ (Key): ¿Qu\'e informaci\'on tengo?.
    \item $V$ (Value): ¿Cu\'al es esa informaci\'on?.
    \item $d_k$: Dimensi\'on de las \textit{keys} (32 por head).
\end{itemize}

\vspace{1em}

\noindent \textbf{Ejemplo visual}

\begin{verbatim}
Input: "Hola ¿cómo estás?"

Attention scores entre tokens:
          Hola   ¿   cómo  estás   ?
Hola      1.0   0.1  0.3   0.4    0.1
¿         0.1   0.9  0.5   0.2    0.8
cómo      0.2   0.4  1.0   0.7    0.3
estás     0.3   0.2  0.6   1.0    0.2
?         0.1   0.7  0.3   0.2    1.0
\end{verbatim}

\noindent\textbf{Interpretación}:
\begin{itemize}
    \item ``cómo'' atiende fuertemente a ``estás'' (0.7).
    \item ``?'' atiende a ``¿'' (0.7) — contexto de pregunta.
\end{itemize}

{\large \noindent \textbf{\textit{Pooling layer}}}

\textbf{Objetivo}: Convertir secuencia variable → vector fijo.

Estrategias de \textit{pooling}:

\begin{enumerate}[label=\alph*)]
    \item \textbf{\textit{Mean pooling} (usado en nuestro modelo)}
    \begin{verbatim}
    embedding = torch.mean(token_embeddings, dim=0)
    \end{verbatim}

    \textbf{Ventaja}: Captura información de toda la oración.

    \newpage
    \item \textbf{\textit{CLS Pooling} (alternativa)}
    \begin{verbatim}
    embedding = token_embeddings[0]  # Token [CLS]
    \end{verbatim}
    \textbf{Ventaja}: Más rápido, pero pierde contexto.
    \item \textbf{\textit{Max pooling} (alternativa)}
    \begin{verbatim}
    embedding = torch.max(token_embeddings, dim=0)
    \end{verbatim}
    \textbf{Ventaja}: Captura \textit{features} más prominentes.
\end{enumerate}

{\large \noindent \textbf{L2 \textit{Normalization}}}

\textbf{Objetivo}: Normalizar \textit{embedding} a norma unitaria.

\[
\text{embedding\_normalized}
=
\frac{\text{embedding}}
     {\lVert \text{embedding} \rVert_2}
\]

Ventajas:
\begin{itemize}
    \item \textit{Embeddings} en hiperesfera unitaria.
    \item Similitud coseno = producto punto.
    \item Comparación justa entre \textit{embeddings}.
\end{itemize}

\textbf{Ejemplo}:

\begin{verbatim}
Antes: embedding = [1.5, -2.3, 0.8, ...]
                ||embedding|| = 2.8

Después: embedding = [0.536, -0.821, 0.286, ...]
                  ||embedding|| = 1.0
\end{verbatim}

\vspace{1em}

\newpage
{\large \noindent \textbf{Generación de \textit{embeddings}}}

\noindent\textbf{Proceso completo}
\begin{verbatim}
from sentence_transformers import SentenceTransformer

# 1. Cargar modelo
model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')

# 2. Preparar textos
texts = [
    "Hola, ¿cómo estás?",
    "Buenos días",
    "Necesito ayuda"
]

# 3. Generar embeddings
embeddings = model.encode(
    texts,
    batch_size=32,
    show_progress_bar=True,
    convert_to_numpy=True
)

# Output shape: (3, 384)
# Cada fila es un embedding de 384 dimensiones
\end{verbatim}

\vspace{1em}
{\large \noindent \textbf{Optimizaciones aplicadas}}

\begin{enumerate}
    \item \textbf{\textit{Batch processing}}
    \begin{itemize}
        \item Procesar múltiples textos a la vez.
        \item \textit{Batch size}: 32.
        \item Aprovecha paralelismo de CPU/GPU.
    \end{itemize}

    \item \textbf{\textit{Caching}}
    \begin{itemize}
        \item \textit{Embeddings} guardados en .npz.
        \item Carga instantánea (<1 segundo).
        \item Ahorro de ~5 segundos por \textit{startup}.
    \end{itemize}

    \newpage
    \item \textbf{\textit{Lazy loading}}
    \begin{itemize}
        \item Modelo cargado solo cuando se necesita.
        \item Ahorro de memoria si no hay requests.
    \end{itemize}
\end{enumerate}

\noindent \textbf{Métricas de Generación}

\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.6}
\begin{tabular}{|p{6cm}|p{6cm}|}
\hline
\textbf{Métrica} & \textbf{Valor} \\ \hline
Tiempo por \textit{embedding} (CPU) & \(\sim\)15ms \\ \hline
Tiempo por \textit{embedding} (GPU) & \(\sim\)3ms \\ \hline
\textit{Batch size} óptimo (CPU) & 32 textos \\ \hline
\textit{Batch size} óptimo (GPU) & 128 textos \\ \hline
Memoria por \textit{embedding} & 1.5 KB (384 \textit{floats}) \\ \hline
Memoria modelo en RAM & \(\sim\)420 MB \\ \hline
\end{tabular}
\caption[Métricas de rendimiento]{Métricas de rendimiento del sistema, elaboración propia.}
\end{table}


{\large \noindent \textbf{Cálculo de similitud coseno}}

\textbf{Definición}

Similitud coseno mide el ángulo entre dos vectores:

\[
\cos(\theta)
=
\frac{A \cdot B}
     {\lVert A\rVert \times \lVert B\rVert}
\]

Donde:
\begin{itemize}
    \item $A \cdot B$: Producto punto.
    \item $\lVert A \rVert$: Norma (magnitud) del vector $A$.
    \item $\theta$: Ángulo entre vectores.
\end{itemize}

Rango: [-1, 1]
\begin{itemize}
    \item 1.0: Vectores idénticos (ángulo 0°).
    \item 0.0: Vectores ortogonales (ángulo 90°).
    \item -1.0: Vectores opuestos (ángulo 180°).
\end{itemize}

\vspace{1em}
{\large \noindent \textbf{Simplificación con \textit{L2 Normalization}}}

Si ||A|| = 1 y ||B|| = 1 (L2 normalized):

\[
\cos(\theta) = A \cdot B
\]

El producto punto es la similitud coseno.\\

\textbf{Ventaja}: Cálculo mucho más rápido\\

{\large \noindent \textbf{Implementación}}

\begin{verbatim}
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

# Embeddings normalizados (||emb|| = 1.0)
query_embedding = np.array([0.5, -0.3, 0.8, ...])  # 384-dim
phrase_embeddings = np.array([
    [0.6, -0.2, 0.7, ...],  # Frase 1
    [0.1, 0.9, -0.4, ...],  # Frase 2
    [0.5, -0.3, 0.75, ...]  # Frase 3
])

# Calcular similitud con todas las frases
similarities = cosine_similarity(
    [query_embedding],
    phrase_embeddings
)[0]

# Output: [0.95, 0.62, 0.98]
\end{verbatim}

\vspace{1em}

\noindent \textbf{Ejemplo visual}

\begin{verbatim}
Query: "Hola"
Embedding: [0.5, 0.5, 0.707]  (simplificado a 3D)

Frase 1: "Buenos días"
Embedding: [0.6, 0.4, 0.693]

Similitud = (0.5×0.6) + (0.5×0.4) + (0.707×0.693)
        = 0.3 + 0.2 + 0.49
        = 0.99  ← Muy similar!

\newpage
Frase 2: "Ayuda"
Embedding: [-0.3, 0.8, 0.524]

Similitud = (0.5×-0.3) + (0.5×0.8) + (0.707×0.524)
        = -0.15 + 0.4 + 0.37
        = 0.62  ← Menos similar
\end{verbatim}

{\large \noindent \textbf{Optimización vectorizada}}

\noindent En lugar de \textit{loops}:

\begin{verbatim}
# LENTO (loop)
for phrase_emb in phrase_embeddings:
    sim = cosine_similarity([query_emb], [phrase_emb])[0][0]
\end{verbatim}

\noindent Usar operaciones matriciales:

\begin{verbatim}
# RÁPIDO (vectorizado)
similarities = cosine_similarity([query_emb], phrase_embeddings)[0]
\end{verbatim}

\textbf{Speedup}: ~100x más rápido.\\

{\large \noindent \textbf{\textit{Re-ranking} en dos fases}}\\

\noindent \textbf{Motivación}

\textbf{Problema}: Búsqueda exhaustiva es costosa.
\begin{itemize}
    \item Dataset: 43 frases en 3 grupos.
    \item Cálculo directo: 43 comparaciones por \textit{query}.
    \item Escalabilidad: O(N) con N = total de frases.
\end{itemize}

\vspace{0.7em}

\textbf{Solución}: Búsqueda jerárquica en dos fases.
\begin{itemize}
    \item Fase 1: Encontrar grupos candidatos (O(3) comparaciones).
    \item Fase 2: Buscar en grupos candidatos (O(N\_candidatos)).
    \item Escalabilidad: O(K + N\_k) donde K = núm. grupos, N\_k = frases en top grupos.
\end{itemize}

\newpage
{\large \noindent \textbf{Fase 1: Búsqueda por centroides}}

\noindent \textbf{Centroide}: Vector promedio de un grupo.

\begin{verbatim}
Grupo A: ["Ayuda", "Socorro", "Urgente", ...]
   ↓
Embeddings:
   [0.2, -0.3, 0.5, ...]
   [0.3, -0.2, 0.6, ...]
   [0.1, -0.4, 0.4, ...]
   ↓
Centroide_A = mean(embeddings_A)
            = [0.2, -0.3, 0.5, ...]
\end{verbatim}

\noindent \textbf{Algoritmo}:

\begin{verbatim}
def find_best_groups(query_embedding, centroids, top_k=3):
    """
    Encuentra top-K grupos más probables.
    """
    scores = []
    for grupo, centroid in centroids.items():
        sim = cosine_similarity([query_embedding], [centroid])[0][0]
        scores.append((grupo, sim))

    scores.sort(key=lambda x: x[1], reverse=True)
    return scores[:top_k]
\end{verbatim}

\noindent \textbf{Ejemplo}:

\begin{verbatim}
Query: "necesito ayuda urgente"
Embedding: [0.25, -0.35, 0.52, ...]

Similitud con centroides:
   Centroide A (Emergencias): 0.92  ← TOP 1
   Centroide C (Comunicación): 0.78  ← TOP 2
   Centroide B (Saludos):     0.65  ← TOP 3

Grupos candidatos: [A, C, B].
\end{verbatim}

\newpage
{\large \noindent\textbf{Fase 2: \textit{Re-ranking} fino}}

\noindent Búsqueda en grupos candidatos:

\begin{verbatim}
def rerank_in_groups(query_embedding, candidate_groups, embeddings, frases):
    """
    Busca la mejor frase en grupos candidatos.
    """
    best_sim = -1
    best_grupo = None
    best_frase = None

    for grupo in candidate_groups:
        # Embeddings del grupo
        grupo_embeddings = embeddings[grupo]
        grupo_frases = frases[grupo]

        # Similitud con todas las frases del grupo
        sims = cosine_similarity([query_embedding], grupo_embeddings)[0]

        # Aplicar BOOSTS por longitud
        for i, frase in enumerate(grupo_frases):
            num_words = len(frase.split())
            if num_words >= 3:
                sims[i] += 0.15  # +15% para frases largas
            elif num_words == 2:
                sims[i] += 0.08  # +8% para frases medias

        # Normalizar [0, 1]
        sims = np.clip(sims, 0.0, 1.0)

        # Mejor match en este grupo
        max_idx = np.argmax(sims)
        sim = sims[max_idx]

        # Actualizar si es mejor
        if sim > best_sim:
            best_sim = sim
            best_grupo = grupo
            best_frase = grupo_frases[max_idx]

    return best_grupo, best_frase, best_sim
\end{verbatim}

\newpage
{\large \noindent \textbf{\textit{Boosts} aplicados}}

\begin{enumerate}
    \item \textbf{\textit{Boost} por longitud de frase} \\
    Justificación: Frases más largas más específicas.

    \begin{table}[H]
    \centering
    \renewcommand{\arraystretch}{1.6}
    \begin{tabular}{|p{4cm}|p{4cm}|p{5cm}|}
    \hline
    \textbf{Palabras} & \textbf{Boost} & \textbf{Ejemplo} \\ \hline
    1 palabra & 0\% & ``Ayuda'' \\ \hline
    2 palabras & +8\% & ``Necesito ayuda'' \\ \hline
    3+ palabras & +15\% & ``Necesito ayuda urgente'' \\ \hline
    \end{tabular}
    \caption[Boost por número de palabras]{Boost por número de palabras, elaboración propia.}
    \end{table}

    \item \textbf{Bonus al grupo más probable}
    \begin{verbatim}
    Grupo #1 (top centroid match): +5%
    Otros grupos: 0%
    \end{verbatim}

    \item \textbf{Penalización por diferencia de longitud}
    \begin{verbatim}
    Si |len(query_word) - len(phrase_word)| > 1:
        penalty = 0.05 × diferencia
    \end{verbatim}

    Ejemplo:
    \begin{verbatim}
    Query: "Ivan" (4 letras)
    Frase: "Sí" (2 letras)
    Diferencia: 2 letras
    Penalty: 0.05 × 2 = 0.10 (-10%)
    \end{verbatim}
\end{enumerate}

\newpage
{\large \noindent \textbf{Ejemplo completo}}

\begin{verbatim}
Query: "necesito ayuda urgente"

Fase 1: Búsqueda por centroides
   Centroide A: 0.92 ← TOP
   Centroide C: 0.78
   Centroide B: 0.65

Candidatos: [A, C, B]

Fase 2: Re-ranking en Grupo A
   "Ayuda, por favor":     0.85 + 0.08 (2 palabras) = 0.93
   "Necesito un médico":   0.82 + 0.15 (3 palabras) = 0.97 ← BEST
   "Socorro":              0.80 + 0.00 (1 palabra)  = 0.80
   ...

Fase 2: Re-ranking en Grupo C
   "Gracias":              0.65
   "Entiendo":             0.62
   ...

Mejor match global: "Necesito un médico" (Grupo A, sim: 0.97)
\end{verbatim}

\vspace{1em}

{\large \noindent \textbf{Ventajas del \textit{re-ranking}}}

\begin{itemize}
    \item \textit{Performance}: \(\sim 3\times\) más rápido que búsqueda exhaustiva.
    \item Escalabilidad: \(O(K + N_k)\) vs \(O(N)\).
    \item Precisión: \textit{Boosts} mejoran detección.
    \item Flexibilidad: Fácil agregar nuevos grupos.
\end{itemize}

{\large \noindent \textbf{Métricas}}

\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.6}
\begin{tabular}{|p{6cm}|p{7cm}|}
\hline
\textbf{Métrica} & \textbf{Valor} \\ \hline
Comparaciones (exhaustiva) & 43 \\ \hline
Comparaciones (\textit{re-ranking}) & 3 + $\sim$20 = 23 \\ \hline
\textit{Speedup} & $\sim$1.9x \\ \hline
Precisión & 92\% (vs 90\% exhaustiva) \\ \hline
\end{tabular}
\caption[Métricas de búsqueda]{Métricas de búsqueda, elaboración propia.}
\end{table}
% ======================================================

\subsection{Etapa 3: API REST y arquitectura}

{\large \noindent \textbf{Diseño de \textit{Endpoints}}}\\

\noindent \textbf{Principios de diseño}

\begin{itemize}
    \item \textbf{RESTful API \textit{Design}}
    \begin{itemize}
        \item Uso de HTTP methods (GET, POST).
        \item URLs semánticas y descriptivas.
        \item \textit{Status codes} apropiados.
    \end{itemize}

    \item \textbf{\textit{Stateless}}
    \begin{itemize}
        \item Sin sesiones en servidor.
        \item Cada \textit{request} independiente.
        \item Facilita escalabilidad horizontal.
    \end{itemize}

    \item \textbf{JSON como formato de intercambio}
    \begin{itemize}
        \item Estándar de la industria.
        \item Fácil \textit{parsing} en cualquier lenguaje.
        \item Soportado nativamente por FastAPI.
    \end{itemize}

    \item \textbf{Versionado implícito}
    \begin{itemize}
        \item Preparado para \texttt{/v2/buscar}.
        \item Actualmente sin versión (v1 implícito).
    \end{itemize}
\end{itemize}

\newpage
{\large \noindent \textbf{\textit{Endpoints} implementados}}\\

{\large \noindent \textbf{1. POST /buscar}}\\

\textit{Endpoint} principal de búsqueda semántica.

\textbf{Request:}
\begin{verbatim}
Content-Type: application/json
Body:
{
    "texto": "hola"
}
\end{verbatim}

\noindent\textbf{Response (200 OK):}

\begin{verbatim}
{
    "query": "hola",
    "grupo": "B",
    "frase_similar": "Hola",
    "similitud": 0.95,
    "deletreo_activado": false,
    "deletreo": null,
    "total_caracteres": null,
    "nombre_detectado": null,
    "nombre_extraido": null,
    "nombre_deletreado": null,
    "total_caracteres_nombre": null
}
\end{verbatim}

\textbf{Errores:}
\begin{itemize}
    \item 400: Texto vacío o inválido.
    \item 503: Servicio no disponible.
    \item 500: Error interno.
\end{itemize}

\newpage
{\large \noindent \textbf{2. GET /grupos}}\\

Listado de grupos disponibles y sus frases.

\textbf{Response (200 OK):}
\begin{verbatim}
{
    "total_grupos": 3,
    "grupos": {
        "A": {
            "nombre": "Emergencias",
            "descripcion": "Frases de emergencia",
            "total_frases": 13,
            "ejemplos": ["Ayuda", "Socorro", "Urgente"]
        },
        "B": { ... },
        "C": { ... }
    }
}
\end{verbatim}

{\large \noindent \textbf{3. GET /grupos/\{grupo\}}}\\

Frases de un grupo específico.\\

\textbf{\textit{Path parameter}:}
\begin{itemize}
    \item \texttt{grupo}: ``A'', ``B'' o ``C''
\end{itemize}

\textbf{Response (200 OK):}
\begin{verbatim}
{
    "grupo": "A",
    "nombre": "Emergencias",
    "total_frases": 13,
    "frases": [
        "Ayuda, por favor",
        "Llama a la policía",
        ...
    ]
}
\end{verbatim}

\textbf{Errores:}
\begin{itemize}
    \item 404: Grupo no encontrado.
\end{itemize}

\newpage
{\large \noindent \textbf{4. POST /deletreo}}\\

Deletreo manual de cualquier texto.

\textbf{Request:}
\begin{verbatim}
{
    "texto": "Hola Mundo"
}
\end{verbatim}

\textbf{Response (200 OK):}
\begin{verbatim}
{
    "texto_original": "Hola Mundo",
    "texto_normalizado": "HolaMundo",
    "deletreo": ["H","O","L","A","M","U","N","D","O"],
    "total_caracteres": 9
}
\end{verbatim}

{\large \noindent \textbf{5. GET /health}}\\

Health check del servicio.

\textbf{Response (200 OK):}
\begin{verbatim}
{
    "status": "healthy",
    "version": "2.1.0",
    "matcher_initialized": true,
    "total_frases": 43,
    "uptime_seconds": 3600
}
\end{verbatim}

{\large \noindent \textbf{6. GET /docs}}
\begin{itemize}
    \item Documentación interactiva (Swagger UI). Generada automáticamente por FastAPI.
    \item Permite \textit{testing} interactivo de \textit{endpoints}.
\end{itemize}

{\large \noindent \textbf{7. GET /redoc}}
\begin{itemize}
    \item Documentación alternativa (ReDoc).
    \item Formato más limpio para lectura.
\end{itemize}

\newpage
{\large \noindent \textbf{Validación de datos con Pydantic}}

\noindent \textbf{Modelos de validación}

\begin{lstlisting}[language=Python]
from pydantic import BaseModel, Field
from typing import List

class QueryRequest(BaseModel):
    """Modelo de validación para requests de búsqueda."""

    texto: str = Field(
        ...,
        min_length=1,
        max_length=500,
        description="Texto a buscar",
        examples=["hola", "necesito ayuda"]
    )

    class Config:
        json_schema_extra = {
            "example": {
                "texto": "hola"
            }
        }
\end{lstlisting}

Validaciones automáticas:
\begin{itemize}
    \item Texto es requerido (... = required).
    \item Texto no puede estar vacío (min\_length=1).
    \item Texto máximo 500 caracteres (max\_length=500).
    \item Tipo \textit{string} validado automáticamente.
\end{itemize}

\vspace{0.7em}

\noindent \textbf{Ejemplos de validación}

\textit{Request} válido:

\begin{lstlisting}
POST /buscar
{
  "texto": "hola"
}
→ ✓ Pasa validación
\end{lstlisting}

\newpage
\textit{Request} inválido (texto vacío):

\begin{lstlisting}
POST /buscar
{
  "texto": ""
}
→ Error 422 (Unprocessable Entity)
{
  "detail": [
    {
      "loc": ["body", "texto"],
      "msg": "ensure this value has at least 1 characters",
      "type": "value_error.any_str.min_length"
    }
  ]
}
\end{lstlisting}

\textit{Request} inválido (tipo incorrecto):

\begin{lstlisting}
POST /buscar
{
  "texto": 123
}
→ Error 422
{
  "detail": [
    {
      "loc": ["body", "texto"],
      "msg": "str type expected",
      "type": "type_error.str"
    }
  ]
}
\end{lstlisting}

\newpage
Validación de \textit{responses}

\begin{lstlisting}[language=Python]
class QueryResponse(BaseModel):
    """Modelo de validación para responses."""

    query: str
    grupo: str | None
    frase_similar: str
    similitud: float = Field(ge=0.0, le=1.0)  # [0.0, 1.0]
    deletreo_activado: bool
    deletreo: List[str] | None = None
    total_caracteres: int | None = None
    nombre_detectado: bool | None = None
    nombre_extraido: str | None = None
    nombre_deletreado: List[str] | None = None
    total_caracteres_nombre: int | None = None
\end{lstlisting}

\vspace{1em}
Validaciones:
\begin{itemize}
    \item Similitud entre 0.0 y 1.0 (ge=0.0, le=1.0).
    \item Tipos verificados automáticamente.
    \item Campos opcionales con None.
\end{itemize}

{\large \noindent \textbf{Manejo de errores}}\\

\textbf{Estrategia de manejo}:

\begin{enumerate}
    \item HTTPException para errores controlados.
    \item \textit{Exception handler} para errores inesperados.
    \item \textit{Logging} de todos los errores.
    \item Responses consistentes.
\end{enumerate}

\newpage
\textbf{Códigos por error}

\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.6}
\begin{tabular}{|p{2cm}|p{4cm}|p{8cm}|}
\hline
\textbf{Código} & \textbf{Nombre} & \textbf{Uso} \\ \hline
200 & OK & \textit{Request} exitoso \\ \hline
400 & \textit{Bad Request} & Texto vacío, parámetros inválidos \\ \hline
404 & \textit{Not Found} & Grupo no encontrado \\ \hline
422 & \textit{Unprocessable} & Validación \textit{Pydantic} fallida \\ \hline
500 & \textit{Internal Error} & Error no manejado \\ \hline
503 & \textit{Service Unavailable} & \textit{Matcher} no inicializado \\ \hline
\end{tabular}
\caption[Códigos HTTP]{Códigos HTTP utilizados, elaboración propia.}
\end{table}

{\large \noindent \textbf{Implementación}}
\begin{lstlisting}[language=Python]
from fastapi import HTTPException
from fastapi.responses import JSONResponse

@app.post("/buscar")
async def buscar(request: QueryRequest):
    if matcher is None:
        raise HTTPException(
            status_code=503,
            detail="Servicio no disponible: matcher no inicializado")

    if not request.texto.strip():
        raise HTTPException(
            status_code=400,
            detail="El texto no puede estar vacío"        )

    try:
        resultado = matcher.search_similar_phrase(request.texto)
        return resultado
    except Exception as e:
        logger.error(f"Error en búsqueda: {e}")
        raise HTTPException(status_code=500,
            detail="Error interno del servidor")
\end{lstlisting}

\newpage
{\large \noindent \textbf{\textit{Middleware} de error \textit{handling}}}

\begin{lstlisting}[language=Python]
@app.exception_handler(HTTPException)
async def http_exception_handler(request, exc):
    """Maneja excepciones HTTP con formato consistente."""
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "error": exc.detail,
            "status_code": exc.status_code,
            "path": str(request.url),
            "timestamp": datetime.now().isoformat()
        }
    )

@app.exception_handler(Exception)
async def general_exception_handler(request, exc):
    """Maneja excepciones no capturadas."""
    logger.error(f"Error no manejado: {exc}", exc_info=True)
    return JSONResponse(
        status_code=500,
        content={
            "error": "Error interno del servidor",
            "status_code": 500,
            "path": str(request.url),
            "timestamp": datetime.now().isoformat()
        }
    )
\end{lstlisting}

\vspace{1em}

{\large \noindent \textbf{\textit{Logging} y monitoreo}}

\textbf{Configuración de \textit{logging}}

\begin{lstlisting}[language=Python]
import logging
from logging.handlers import RotatingFileHandler

# Configuración
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        # Console handler
        logging.StreamHandler(),
        # File handler con rotación
        RotatingFileHandler(
            'logs/app.log',
            maxBytes=10*1024*1024,  # 10MB
            backupCount=5
        )
    ]
)

logger = logging.getLogger(__name__)
\end{lstlisting}

\vspace{1em}
\textbf{Eventos loggeados}

\begin{lstlisting}
[STARTUP]
2024-11-24 12:00:00 - app.main - INFO - Inicializando aplicación...
2024-11-24 12:00:00 - app.matcher - INFO - Cargando modelo...
2024-11-24 12:00:01 - app.matcher - INFO - Cache cargado exitosamente
2024-11-24 12:00:01 - app.main - INFO - Aplicación lista

[REQUEST]
2024-11-24 12:00:15 - app.main - INFO - Búsqueda para: hola
2024-11-24 12:00:15 - app.matcher - DEBUG - Similitud calculada: 0.95
2024-11-24 12:00:15 - app.main - INFO - Resultado: B - 0.95

[ERROR]
2024-11-24 12:00:30 - app.main - ERROR - Error en búsqueda: División por cero
2024-11-24 12:00:30 - app.main - ERROR - Traceback: ...
\end{lstlisting}

\textbf{Métricas monitoreadas}

\begin{itemize}
    \item \textit{Requests} por segundo.
    \item Latencia promedio.
    \item Tasa de errores (4xx, 5xx).
    \item Uso de memoria.
    \item Tiempo de inicialización.
\end{itemize}

\newpage
{\large \noindent \textbf{Documentación automática (OpenAPI / Swagger)}}

\textbf{Generación automática}\\
FastAPI genera documentación OpenAPI 3.0 basada en:

\begin{itemize}
    \item \textit{Type hints} de Python.
    \item Modelos Pydantic.
    \item \textit{Docstrings}.
    \item \textit{Field descriptions}.
\end{itemize}

Acceso:
\begin{itemize}
    \item \texttt{http://localhost:8000/docs}.
    \item \texttt{http://localhost:8000/redoc}.
    \item \texttt{http://localhost:8000/openapi.json}.
\end{itemize}

\vspace{1em}
\textbf{Ejemplo de documentación generada}

\begin{lstlisting}
openapi: 3.0.2
info:
  title: API de Búsqueda Semántica
  description: |
    API REST para búsqueda semántica de frases en español usando PLN.
  version: 2.1.0

paths:
  /buscar:
    post:
      summary: Buscar frase similar
      description: |
        Busca la frase más similar al texto proporcionado usando
        embeddings semánticos y similitud coseno.
      operationId: buscar_frase_similar_buscar_post
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/QueryRequest'
            example:
              texto: "hola"
      responses:
        '200':
          description: Búsqueda exitosa
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/QueryResponse'
        '400': description: Texto vacío o inválido
        '503': description: Servicio no disponible

components:
  schemas:
    QueryRequest:
      type: object
      required:
        - texto
      properties:
        texto:
          type: string
          minLength: 1
          maxLength: 500
          description: Texto a buscar

    QueryResponse:
      type: object
      required:
        - query
        - frase_similar
        - similitud
        - deletreo_activado
      properties:
        query:
          type: string
        grupo:
          type: string
          nullable: true
        frase_similar:
          type: string
        similitud:
          type: number
          minimum: 0.0
          maximum: 1.0
        deletreo_activado:
          type: boolean
\end{lstlisting}

\newpage
\textbf{Ventajas de documentación generada}

\begin{itemize}
    \item Siempre actualizada.
    \item Interactiva.
    \item Compatible con herramientas OpenAPI.
    \item Generación automática de clientes.
\end{itemize}

%====================================================
%====================================================
%====================================================
%====================================================

\section{Pruebas del Modulo del Procesamiento de Lenguaje Natural (PLN)}

\vspace{1em}

\subsection{Metodología de \textit{testing}}

{\large \noindent \textbf{Piramide de \textit{Testing}}}

La estrategia de \textit{testing} del proyecto sigue el modelo de la Pirámide de \textit{testing} propuesta por Mike Cohn \cite{refpirtes}, que establece una distribución óptima de los diferentes tipos de pruebas.\\

\begin{center}
    \includegraphics[width=0.45\textwidth]{Images/Cap5/1_PiramideTesting.png}
    \captionof{figure}[Piramide de Testing]{Piramide de \textit{Testing}, obtenido de \cite{refpirtes}.} 
\end{center}

\noindent \textbf{Distribución implementada}

\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.6}
\begin{tabular}{|p{4cm}|p{2.5cm}|p{2.5cm}|p{4cm}|}
\hline
\textbf{Tipo de \textit{test}} & \textbf{Cantidad} & \textbf{\% Total} & \textbf{Tiempo de ejecución} \\ \hline
\textit{Tests} unitarios & 37 & 51\% & $<$5 segundos \\ \hline
\textit{Tests} integración & 10 & 14\% & $\sim$8 segundos \\ \hline
\textit{Tests} E2E & 26 & 35\% & $\sim$15 segundos \\ \hline
Total (núcleo) & 73 & 100\% & $\sim$28 segundos \\ \hline
\textit{Test} adicionales & 95 & - & Variable \\ \hline
Total general & 168 & - & - \\ \hline
\end{tabular}
\caption[Resumen de tests]{Resumen de \textit{tests}, elaboración propia.}
\end{table}

\textbf{Nota:} Los \textit{tests} de \textit{performance}, \textit{quality} y \textit{stress} \textbf{NO} se incluyen en la distribución de la pirámide ya que son \textit{tests} especializados que se ejecutan de forma independiente.\\

\noindent \textbf{Justificación del 35\% de tests E2E}

El porcentaje elevado de tests E2E (superior al estándar industrial de 10--15\%) se justifica por los requisitos específicos de sistemas PLN:

\begin{enumerate}
    \item Validación exhaustiva de robustez lingüística.
    \item \textit{Tests} de tolerancia a errores ortográficos y variaciones naturales.
    \item Validación de casos \textit{edge} específicos (nombres propios, \textit{leet speak}).
    \item Degradación gradual ante \textit{inputs} de baja calidad.
\end{enumerate}

{\large \noindent \textbf{Stack tecnológico}}

\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.6}
\begin{tabular}{|p{4cm}|p{4cm}|p{3cm}|}
\hline
\textbf{Componente} & \textbf{Tecnología} & \textbf{Versión} \\ \hline
\textit{Framework} de \textit{testing} & \textit{pytest} & 7.4+ \\ \hline
\textit{API testing} & FastAPI TestClient & 0.104+ \\ \hline
Cobertura de código & pytest-cov & 4.1+ \\ \hline
\textit{Load testing} & Locust & 2.15+ \\ \hline
\textit{Performance benchmarks} & pytest-benchmark & 4.0+ \\ \hline
\textit{Resource monitoring} & psutil & 5.9+ \\ \hline
\end{tabular}
\caption[Tecnologías de testing]{Tecnologías usadas para \textit{testing}, elaboración propia.}
\end{table}

\newpage
{\large \noindent \textbf{Estructura del \textit{testing}}}

El sistema de \textit{testing} está organizado en directorios especializados:

\begin{verbatim}
tests/
|-- unit/                          # 37 tests unitarios
|   |-- test_matcher.py            # Matching semantico (25 tests)
|   `-- test_preprocess.py         # Preprocesamiento (12 tests)
|
|-- integration/                   # 10 tests de integracion
|   `-- test_api.py                # Endpoints FastAPI
|
|-- e2e/                           # 26 tests end-to-end
|   |-- test_scenarios.py          # Escenarios de usuario (8 tests)
|   |-- test_robustness.py         # Robustez linguistica (14 tests)
|   `-- test_casos_realistas.py    # Casos reales (4+ tests)
|
|-- quality/                       # Tests de calidad semantica
|   |-- test_semantic_quality.py
|   `-- test_semantic_advanced.py
|
`-- performance/                   # Tests de rendimiento
    |-- test_benchmarks.py
    |-- test_stress_concurrent.py
    `-- locustfile.py
\end{verbatim}

{\noindent \textbf{Estadísticas generales}}

\begin{itemize}
    \item Líneas de código de \textit{testing}: 2{,}749.
    \item Funciones de \textit{test}: 168.
    \item Cobertura de código: 90.8\%.
    \item Tiempo de ejecución: $\sim$ 28 segundos.
\end{itemize}

\newpage
{\large \noindent \textbf{\textit{Tests} unitarios (37 \textit{tests}, 89\% cobertura)}}

Los \textit{tests} unitarios validan componentes individuales de forma aislada, constituyendo la base de la pirámide de \textit{testing}.\\

\textbf{\textit{Tests} del \textit{Matcher} Semántico (25 tests)}

Componente central responsable de:

\begin{itemize}
    \item Generación de \textit{embeddings} con modelos \textit{transformer}.
    \item Cálculo de similitud coseno.
    \item Clasificación en grupos semánticos (A, B, C).
    \item Activación de modo deletreo.
\end{itemize}

\vspace{1em}

{\large \noindent \textbf{Casos críticos validados}}

\textbf{1. Normalización de similitud al rango [0.0, 1.0] (4 \textit{tests})}\\

Problema resuelto: El sistema original retornaba valores > 1.0 debido a errores de precisión flotante.\\

Solución implementada:

\begin{lstlisting}[language=Python]
def clip_similarity(similarity: float) -> float:
    """Normaliza similitud al rango [0.0, 1.0]."""
    if similarity > 1.0:
        return 1.0
    elif similarity < 0.0:
        return 0.0
    return similarity
\end{lstlisting}

Resultado: 100\% de \textit{tests} garantizan similitud matemáticamente correcta.\\

\textbf{2. Validación de rango en todas las \textit{queries} (6 \textit{tests})}\\

\textit{Test} parametrizado con 10 \textit{queries} diversas validando:

\begin{verbatim}
assert 0.0 <= result["similitud"] <= 1.0
\end{verbatim}

\textbf{3. Detección de patrones de nombres (7 \textit{tests})}\\

Funcionalidad especial que detecta y procesa:

\begin{itemize}
    \item "Me llamo [Nombre]"
    \item "Mi nombre es [Nombre]"
\end{itemize}

Ejemplo:

\begin{lstlisting}
Input:  "Me llamo Juan Carlos"

Output: {
    "nombre_detectado": true,
    "nombre_extraido": "Juan Carlos",
    "nombre_deletreado": ["J","U","A","N"," ","C","A","R","L","O","S"],
    "total_caracteres_nombre": 11
}
\end{lstlisting}

\textbf{4. Clasificación en grupos semánticos (3 \textit{tests})}\\

Grupos del sistema:

\begin{itemize}
    \item Grupo A: Emergencias (ayuda, socorro, urgente).
    \item Grupo B: Saludos (hola, buenos días, adios).
    \item Grupo C: Comunicación (gracias, sí, bien).
\end{itemize}

{\large \noindent \textbf{\textit{Tests} de preprocesamiento (12 \textit{tests})}}\\

Validación de normalización de texto para robustez del sistema PLN:\\

\textbf{1. Normalización de texto (7 \textit{tests})}

Transformaciones aplicadas:

\begin{itemize}
    \item Conversión a minúsculas.
    \item Eliminación de acentos (\textit{Unicode normalization}).
    \item Eliminación de caracteres especiales.
    \item Normalización de espacios múltiples.
\end{itemize}

Ejemplo:

\begin{verbatim}
"¡HOLA, ¿Cómo  estás?!" → "hola como estas"
\end{verbatim}

\newpage
\textbf{Resultados}

\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.6}
\begin{tabular}{|p{4cm}|p{3.5cm}|p{3.5cm}|}
\hline
\textbf{Métrica} & \textbf{Valor} & \textbf{Objetivo} \\ \hline
Total \textit{tests} & 37 & 30+ \\ \hline
\textit{Tests} exitosos & 37 (100\%) & 100\% \\ \hline
Cobertura de código & 89\% & $>$80\% \\ \hline
Tiempo de ejecución & $<$5 segundos & $<$10 segundos \\ \hline
Casos límite cubiertos & 15+ & 10+ \\ \hline
\end{tabular}
\caption[Métricas de tests]{Métricas principales de los \textit{tests}, elaboración propia.}
\end{table}


\textbf{2. Deletreo con caracteres especiales (5 \textit{tests})}

Mapeo implementado:

\begin{verbatim}
@ → "arroba", . → "punto", ! → "exclamación", (espacio) → "espacio"
\end{verbatim}

{\large \noindent \textbf{\textit{Tests} de integración (10 \textit{tests}, 6 \textit{endpoints})}}\\

Validación de la interacción entre componentes y funcionamiento de la API REST.\\

\textbf{\textit{Endpoints} testeados}

\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.6}
\begin{tabular}{|p{5cm}|p{2.5cm}|p{3.5cm}|}
\hline
\textbf{\textit{Endpoint}} & \textbf{\textit{Tests}} & \textbf{\textit{Status Codes} Validados} \\ \hline
POST /buscar & 8 & 200, 400, 422 \\ \hline
GET /grupos & 1 & 200 \\ \hline
GET /grupos/\{grupo\} & 2 & 200, 404 \\ \hline
POST /deletreo & 3 & 200, 400 \\ \hline
GET /health & 1 & 200 \\ \hline
GET / & 1 & 200 \\ \hline
\end{tabular}
\caption[Tests por endpoint]{Resumen de \textit{tests} por endpoint, elaboración propia.}
\end{table}

\newpage
\noindent \textbf{Casos críticos del \textit{Endpoint} principal (POST /buscar)}

\begin{enumerate}
    \item \textit{Query} válida retorna resultado correcto.
    \item \textit{Queries} inválidas retornan errores apropiados (400, 422).
    \item \textit{Match} exacto tiene similitud muy alta (>0.95).
    \item \textit{Queries} sin \textit{match} activan deletreo automático.
    \item Emergencias se clasifican correctamente en Grupo A.
    \item Caso \textit{edge} ``Ivan'': detecta baja similitud y activa deletreo.
\end{enumerate}

\vspace{1em}

\textbf{Problema histórico del caso \texttt{``Ivan''}}:

\begin{itemize}
    \item Antes: Se matcheaba incorrectamente con ``Sí'' (Grupo C).
    \item Ahora: Detecta baja similitud (<0.3) y activa deletreo.
    \item Resultado: Usuario recibe I-V-A-N.
\end{itemize}

\textbf{Resultados}

\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.6}
\begin{tabular}{|p{6cm}|p{6cm}|}
\hline
\textbf{Métrica} & \textbf{Valor} \\ \hline
Total \textit{tests} & 10 \\ \hline
\textit{Tests} exitosos & 10 (100\%) \\ \hline
\textit{Endpoints} cubiertos & 6 \\ \hline
Tiempo de ejecución & $\sim$8s \\ \hline
\end{tabular}
\caption[Métricas adicionales]{Métricas adicionales de pruebas, elaboración propia.}
\end{table}

\newpage
{\large \noindent \textbf{\textit{Tests End-To-End}  y robustez lingüística (26 \textit{tests})}}\\
Los \textit{tests} E2E validan robustez ante variaciones naturales del lenguaje mediante ``\textit{Perturbation Testing}'', metodología específica para sistemas PLN \cite{refe2e}.\\

\textbf{Escenarios completos de usuario (8 escenarios)}

\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.6}
\begin{tabular}{|p{5cm}|p{2.5cm}|p{4cm}|}
\hline
\textbf{Escenario} & \textbf{\textit{Tests}} & \textbf{Validación principal} \\ \hline
Emergencias & 2 & Clasificación Grupo A \\ \hline
Saludos formales & 3 & Tolerancia a variaciones \\ \hline
Casos \textit{edge} & 3 & Manejo robusto (\texttt{``Ivan''}) \\ \hline
Conversación completa & 3 & Consistencia temporal \\ \hline
Múltiples usuarios & 2 & Estabilidad bajo carga \\ \hline
Salud del sistema & 2 & \textit{Health checks} \\ \hline
\end{tabular}
\caption[Escenarios de prueba]{Escenarios evaluados, cantidad de \textit{tests} y validación principal, elaboración propia.}
\end{table}

\textbf{\textit{Tests} de robustez lingüística (14 \textit{tests}) - crítico PLN}\\
Metodología de ``\textit{Perturbation Testing}'' con 4 estrategias

\begin{enumerate}
    \item \textit{Character-level perturbations} (errores de tipeo).
    \item \textit{Input fuzzing} (ruido en el input).
    \item \textit{Semantic equivalence testing} (sinónimos).
    \item \textit{Load testing} (estrés).
\end{enumerate}

\newpage
\textbf{Tipos de perturbaciones testeadas (50+ casos)}

\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.6}
\begin{tabular}{|p{5.5cm}|p{6cm}|}
\hline
\textbf{Tipo de perturbación} & \textbf{Ejemplos} \\ \hline
Errores al inicio & \texttt{``hola''} → \texttt{``hila''} \\ \hline
Errores en medio & \texttt{``ayuda''} → \texttt{``auuda''} \\ \hline
Errores al final & \texttt{``hola''} → \texttt{``holq''} \\ \hline
Carácter faltante & \texttt{``hola''} → \texttt{``hla''} \\ \hline
Carácter extra & \texttt{``hola''} → \texttt{``hoola''} \\ \hline
Caracteres intercambiados & \texttt{``hola''} → \texttt{``hloa''} \\ \hline
Múltiples errores & \texttt{``buenos días''} → \texttt{``buens dias''} \\ \hline
Espacios extra & \texttt{``hola\_''} \texttt{``\_ ayuda''} \\ \hline
Puntuación extra & \texttt{``ayuda!!''}, \texttt{``¡ayuda!!''} \\ \hline
Mayúsculas aleatorias & \texttt{``HoLa''}, \texttt{``AyUdA''} \\ \hline
Variaciones de acentos & \texttt{``médico''} vs \texttt{``medico''} \\ \hline
\end{tabular}
\caption[Tipos de perturbación]{Tipos de perturbaciones lingüísticas y ejemplos representativos, elaboración propia.}
\end{table}

\textbf{Degradación gradual por severidad}

\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.6}
\begin{tabular}{|p{3cm}|p{4cm}|p{5cm}|}
\hline
\textbf{Nivel} & \textbf{Ejemplo} & \textbf{Comportamiento esperado} \\ \hline
Leve & \texttt{``hila''} & Clasifica correctamente \\ \hline
Medio & \texttt{``hla''} & Clasifica o activa deletreo \\ \hline
Grave & \texttt{``hkka''} & Activa deletreo \\ \hline
\end{tabular}
\caption[Niveles de error]{Clasificación de severidad de errores y el comportamiento esperado, elaboración propia.}
\end{table}

\newpage
\textbf{Casos realistas con \textit{Leet Speak} (4+ \textit{tests})}\\

Normalización de \textit{Leet Speak} en deletreo

\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.6}
\begin{tabular}{|p{2cm}|p{3cm}|p{6cm}|}
\hline
\textbf{\textit{Leet Speak}} & \textbf{Normalización} & \textbf{Ejemplo} \\ \hline
4 & A & \texttt{``M4ri@''} → \texttt{``MARIA''} \\ \hline
3 & E & \texttt{``P3dro''} → \texttt{``PEDRO''} \\ \hline
1 & I & \texttt{``T1po''} → \texttt{``TIPO''} \\ \hline
0 & O & \texttt{``H0la''} → \texttt{``HOLA''} \\ \hline
@ & A & \texttt{``C@rlos''} → \texttt{``CARLOS''} \\ \hline
\$ & S & \texttt{``Ca\$a''} → \texttt{``CASA''} \\ \hline
\end{tabular}
\caption[Normalización de Leet Speak]{Equivalencias para normalización de texto en \textit{Leet Speak}, elaboración propia.}
\end{table}

\textbf{Resultados}

\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.6}
\begin{tabular}{|p{4cm}|p{3cm}|p{3cm}|}
\hline
\textbf{Métrica} & \textbf{Valor} & \textbf{Objetivo} \\ \hline

Total tests E2E & 26 & 30+ \\ \hline
Tests exitosos & 26 (100\%) & >95\% \\ \hline
Escenarios completos & 8 & 6+ \\ \hline
Tipos de perturbaciones & 11 & 8+ \\ \hline
Casos de perturbación testeados & 50+ & 30+ \\ \hline
\textit{Success rate} con perturbaciones & >95\% & >90\% \\ \hline
Tiempo de ejecución & $\sim$15s & <30s \\ \hline

\end{tabular}
\caption[Métricas generales]{Resultados generales de pruebas E2E, elaboración propia.}
\end{table}

\newpage
\textbf{Fortalezas identificadas}
\begin{itemize}
    \item Tolerancia a typos: $>95\%$ de clasificación correcta.
    \item Normalización efectiva de ruido y puntuación.
    \item Degradación gradual y graceful ante errores severos.
    \item Manejo correcto de casos edge (nombres propios, \textit{leet speak}).
\end{itemize}

{\large \noindent \textbf{Tests de rendimiento y carga}}\\
Validación de velocidad, eficiencia y escalabilidad del sistema.\\

\textbf{\textit{Benchmarks} de latencia}

\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.6}
\begin{tabular}{|p{4cm}|p{2cm}|p{2cm}|p{3cm}|}
\hline
\textbf{Operación} & \textbf{Media} & \textbf{P95} & \textbf{Objetivo} \\ \hline

\textit{Query} completa & 42ms & 68ms & <100ms (P95) \\ \hline
Generación de \textit{embedding} & 28ms & 45ms & <50ms \\ \hline
Cache hit & 3ms & 6ms & <10ms \\ \hline
Preprocesamiento & 0.8ms & 1.5ms & <5ms \\ \hline
Cálculo similitud & 9ms & 15ms & <20ms \\ \hline

\end{tabular}
\caption[Latencias por operación]{Medición de latencias promedio y P95, elaboración propia.}
\end{table}

\textbf{\textit{Throughput} medido}
\begin{itemize}
    \item \textit{Single query}: $\sim 23$ q/s.
    \item \textit{Batch processing}: $\sim 65$ q/s.
    \item \textit{Cache hit}: $\sim 333$ q/s.
\end{itemize}

\newpage
\textbf{Test de concurrencia}

\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.6}
\begin{tabular}{|p{4cm}|p{2cm}|p{3cm}|p{3cm}|}
\hline
\textbf{Test} & \textbf{Usuarios} & \textbf{\textit{Success rate}} & \textbf{Latencia P95} \\ \hline

\textit{Concurrent 10 users} & 10 & 99.5\% & 78ms \\ \hline
\textit{Concurrent 50 users} & 50 & 98.3\% & 156ms \\ \hline
\textit{Concurrent 100 users} & 100 & 95.8\% & 287ms \\ \hline
\textit{Spike 0→20 users} & 20 & 96.2\% & 198ms \\ \hline
\textit{Soak 5 min} & 5 & 99.8\% & 82ms \\ \hline

\end{tabular}
\caption[Pruebas de carga]{Resultados de pruebas de concurrencia y resistencia, elaboración propia.}
\end{table}

\textbf{\textit{Load Testing} con Locust (50 usuarios, 5 minutos)}

\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.6}
\begin{tabular}{|p{4cm}|p{3cm}|p{3cm}|}
\hline
\textbf{Métrica} & \textbf{Valor} & \textbf{Objetivo} \\ \hline

Total \textit{requests} & 8,742 & - \\ \hline
\textit{Requests}/segundo (RPS) & 29.14 & >20 \\ \hline
\textit{Failures} & 0.26\% & <1\% \\ \hline
\textit{Success rate} & 99.74\% & >95\% \\ \hline
Latencia promedio & 52ms & <100ms \\ \hline
Latencia P95 & 118ms & <200ms \\ \hline
Latencia P99 & 187ms & <500ms \\ \hline

\end{tabular}
\caption[Métricas de rendimiento]{Resumen de rendimiento total, elaboración propia.}
\end{table}

\newpage
\textbf{Resumen de métricas de rendimiento}
\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.6}
\begin{tabular}{|p{3.2cm}|p{2.6cm}|p{2.6cm}|p{3cm}|}
\hline
\textbf{Métrica} & \textbf{Objetivo} & \textbf{Resultado} & \textbf{Cumplimiento} \\ \hline

Latencia P50 & <100ms & $\sim$42ms & 58\% mejor \\ \hline
Latencia P95 & <200ms & $\sim$68ms & 66\% mejor \\ \hline
Latencia P99 & <500ms & $\sim$134ms & 73\% mejor \\ \hline
\textit{Success Rate} & >95\% & 99.7\% & Excede \\ \hline
\textit{Throughput} & >50 q/s & $\sim$65 q/s & 30\% mejor \\ \hline
\textit{Max Users} & 100 & 100 & Cumple \\ \hline
\textit{Memory Growth} & <10\%/hour & <5\%/hour & 50\% mejor \\ \hline

\end{tabular}
\caption[Métricas de rendimiento]{Resumen de métricas de rendimiento, elaboración propia.}
\end{table}

{\large \noindent \textbf{Calidad semántica y métricas de PLN}}\\

Validación con metodologías específicas para sistemas de Procesamiento de Lenguaje Natural.\\

\noindent \textbf{\textbf{Golden Dataset Testing}}\\
\textit{Dataset} curado manualmente con casos que deben funcionar correctamente\\

\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.6}
\begin{tabular}{|p{3.5cm}|p{2cm}|p{3cm}|p{4cm}|}
\hline
\textbf{Categoría} & \textbf{Casos} & \textbf{Min Similitud} & \textbf{Ejemplo} \\ \hline

\textit{Exact match} & 3 & >0.90 & ``Buenos días'' \\ \hline
\textit{Semantic variation} & 3 & >0.75 & ``necesito ayuda'' \\ \hline
\textit{Synonyms} & 6 & >0.65 & ``socorro'' \\ \hline
\textit{Noisy input} & 3 & >0.70 & ``hola!!'' \\ \hline
\textit{Typos} & 2 & >0.50 & ``hla'' \\ \hline

\textbf{Total} & 17 & - & - \\ \hline

\end{tabular}
\caption[Evaluación lingüística]{Resumen de evaluación lingüística, elaboración propia.}
\end{table}

\textbf{Resultado}: $100\%$ de \textit{golden dataset passing}\\

\newpage
\textbf{Métricas de clasificación semántica}

\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.6}
\begin{tabular}{|p{3.5cm}|p{4cm}|p{2.5cm}|p{2.5cm}|}
\hline
\textbf{Métrica} & \textbf{Fórmula} & \textbf{Valor} & \textbf{Objetivo} \\ \hline

\textit{Precision} & TP/(TP+FP) & $\sim$89\% & >85\% \\ \hline
\textit{Recall} & TP/(TP+FN) & $\sim$87\% & >80\% \\ \hline
\textit{F1-Score} & $2 \cdot P \cdot R / (P + R)$ & $\sim$88\% & >82\% \\ \hline
\textit{Accuracy} & (TP+TN)/Total & $\sim$96\% & >90\% \\ \hline
\textit{Golden Dataset} & Correct/Total & 100\% & 100\% \\ \hline

\end{tabular}
\caption[Métricas de clasificación]{Resumen de métricas de clasificación, elaboración propia.}
\end{table}

El \textit{F1-Score} de 88\% indica balance óptimo entre \textit{precision} y \textit{recall}.\\

\textbf{Reconocimiento de sinónimos}

\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.6}
\begin{tabular}{|p{2cm}|p{6cm}|p{2.5cm}|}
\hline
\textbf{Grupo} & \textbf{Sinónimos testeados} & \textbf{\textit{Accuracy}} \\ \hline

A & ayuda, asistencia, socorro & 75\% \\ \hline
B & hola, saludos, buenos días & 80\% \\ \hline
C & gracias, muchas gracias, bien & 78\% \\ \hline

\end{tabular}
\caption[Sinónimos testeados]{Evaluación por grupos de sinónimos, elaboración propia.}
\end{table}

\textbf{Objetivo}: >70\% dentro de cada grupo.\\

\newpage
{\large \noindent \textbf{Cobertura de código}}\\
\textbf{Cobertura global del módulo}

\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.6}
\begin{tabular}{|p{5cm}|p{1.8cm}|p{1.8cm}|p{2.2cm}|p{2.2cm}|}
\hline
\textbf{Módulo} & \textbf{Stmts} & \textbf{\textit{Missing}} & \textbf{\textit{Coverage}} & \textbf{\textit{Branch}} \\ \hline

app/matcher\_improved.py & 445 & 38 & 91.5\% & 88.7\% \\ \hline
app/preprocess.py & 178 & 15 & 91.6\% & 89.2\% \\ \hline
app/main.py & 156 & 19 & 87.8\% & 82.1\% \\ \hline
app/models.py & 67 & 4 & 94.0\% & 91.5\% \\ \hline
app/config.py & 45 & 6 & 86.7\% & 83.3\% \\ \hline

\textbf{Total} & 891 & 82 & 90.8\% & 87.0\% \\ \hline

\end{tabular}
\caption[Coverage por módulo]{Resumen de \textit{coverage} por módulo, elaboración propia.}
\end{table}

\textbf{\textit{Statement Coverage}}: $90.8\%$ \ (Objetivo: $>80\%$)\\
\indent \textbf{\textit{Branch Coverage}}: $87.0\%$ \ (Objetivo: $>75\%$)\\

\noindent \textbf{Análisis de líneas sin cobertura}\\
Las 82 líneas sin cobertura (9.2\%) corresponden a:\\

\begin{enumerate}
    \item Manejo de errores raros (35 líneas): Modelo no cargado, \textit{embeddings corruptos}, errores de memoria.
    \item \textit{Logging y debugging} (28 líneas): \textit{Logs} de nivel DEBUG, telemetría.
    \item Código de infraestructura (19 líneas): \textit{Shutdown handlers}, configuración avanzada.
\end{enumerate}

Estos casos no afectan la funcionalidad core del sistema.

%===================================================================
%===================================================================
%===================================================================
%===================================================================
\newpage
\section{Resultados del Modulo de PLN}

{\large \noindent \textbf{Resumen ejecutivo}}\\

\textbf{Estado general:} Aprobado

\vspace{0.4cm}

\begin{itemize}
    \item \textbf{\textit{Tests} Totales Implementados:} 168
    \item \textbf{\textit{Tests Core} Ejecutados:} 73
    \item \textbf{\textit{Tests} Exitosos:} 73 (100\%)
    \item \textbf{\textit{Tests} Fallidos:} 0
    \item \textbf{Cobertura \textit{Statement}:} 90.8\%
    \item \textbf{Cobertura \textit{Branch}:} 87.0\%
    \item \textbf{Precisión Semántica:} 89\%
    \item \textbf{\textit{F1-Score}:} 88\%
    \item \textbf{\textit{Golden Dataset Accuracy}:} 100\%
    \item \textbf{Latencia P95:} 68ms
    \item \textbf{\textit{Success Rate} bajo carga:} 99.7\%
    \item \textbf{\textit{Throughput}:} 65 q/s
\end{itemize}

\newpage
{\large \noindent \textbf{Comparación: objetivos vs resultados}}\\

\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.6}
\begin{tabular}{|p{4cm}|p{3cm}|p{3cm}|p{3cm}|}
\hline
\textbf{Métrica} & \textbf{Objetivo} & \textbf{Resultado} & \textbf{Cumplimiento} \\ \hline

\textit{Tests} implementados & >100 & 168 & 168\% \\ \hline
Cobertura de código & >80\% & 90.8\% & 114\% \\ \hline
\textit{Tests E2E} & >20 & 26 & 130\% \\ \hline
Precision semántica & >85\% & $\sim$89\% & 105\% \\ \hline
\textit{F1-Score} & >82\% & $\sim$88\% & 107\% \\ \hline
Latencia P95 & <200ms & 68ms & 66\% mejor \\ \hline
\textit{Success rate} & >95\% & 99.7\% & 105\% \\ \hline
\textit{Throughput} & >50 q/s & 65 q/s & 130\% \\ \hline
\textit{Golden dataset} & 100\% & 100\% & Aceptable \\ \hline

\end{tabular}
\caption[Métricas de testing]{Resumen de métricas de \textit{testing}, elaboración propia.}
\end{table}
\textbf{Conclusión}: Todos los objetivos fueron superados significativamente.\\

\noindent \textbf{Fortalezas}

\begin{enumerate}
    \item Cobertura exhaustiva
    \begin{itemize}[label=\checkmark]
        \item 168 \textit{tests} implementados en todos los niveles.
        \item 90.8\% de cobertura supera estándares industriales (80\%).
        \item Distribución apropiada según pirámide de \textit{testing}.
    \end{itemize}

    \item Robustez lingüística mínima aceptable
    \begin{itemize}[label=\checkmark]
        \item 50+ casos de perturbaciones validados.
        \item >95\% de tolerancia a errores ortográficos.
        \item Degradación gradual y \textit{graceful}.
        \item Normalización efectiva de \textit{leet speak}.
    \end{itemize}

    \newpage
    \item Calidad semántica aceptable
    \begin{itemize}[label=\checkmark]
        \item \textit{F1-Score} de 88\% demuestra balance \textit{precision/recall}.
        \item 100\% de \textit{golden dataset passing}.
        \item Reconocimiento de sinónimos >75\%.
    \end{itemize}

    \item Rendimiento muy adecuado
    \begin{itemize}[label=\checkmark]
        \item Latencia P95 de 68ms (66\% mejor que objetivo).
        \item \textit{Success rate} de 99.7\% bajo carga.
        \item Sistema estable hasta 100 usuarios concurrentes.
    \end{itemize}

    \item Validación de casos críticos
    \begin{itemize}[label=\checkmark]
        \item Similitud matemáticamente correcta [0.0, 1.0] en 100\% de casos.
        \item Caso \textit{edge} ``Ivan'' correctamente manejado.
        \item Detección de patrones ``Me llamo [NOMBRE]''.
        \item Manejo robusto de nombres propios.
    \end{itemize}
\end{enumerate}

{\large \noindent \textbf{Optimizaciones y rendimiento}}\\

\textbf{Caché de \textit{embeddings}}\\

\textbf{Problema}: Generar \textit{embeddings} es costoso:
\begin{itemize}
    \item Tiempo: $\sim$5 segundos para 43 frases.
    \item Requiere modelo cargado en memoria.
    \item Se ejecuta en cada \textit{startup}.
\end{itemize}

\textbf{Solución}: Caché persistente en archivo .npz:
\begin{itemize}
    \item Formato: NumPy compressed (.npz).
    \item Tamaño: $\sim$50 KB comprimido.
    \item Carga: $<1$ segundo.
\end{itemize}

\newpage
\textbf{Resultados}

\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.6}
\begin{tabular}{|p{5cm}|p{3cm}|p{3cm}|}
\hline
 & \textbf{Sin caché} & \textbf{Con caché} \\ \hline

Tiempo de inicialización & $\sim$5 seg & <1 seg \\ \hline
\textit{Speedup} & 1x & 5x \\ \hline
Tamaño en disco & - & 50 KB \\ \hline
Memoria en RAM & 65 KB & 65 KB \\ \hline

\end{tabular}
\caption[Comparativa con y sin caché]{Resumen de rendimiento con y sin caché, elaboración propia.}
\end{table}

\textbf{Búsqueda jerárquica por centroides}\\

\textbf{Problema}: Búsqueda exhaustiva en 43 frases:
\begin{itemize}
    \item O(N) comparaciones con N = 43.
    \item No escala bien con más frases.
    \item Ineficiente para \textit{datasets} grandes.
\end{itemize}

\textbf{Solución}: Búsqueda jerárquica en dos fases:
\begin{enumerate}
    \item Fase 1: Buscar top-3 grupos (O(K) con K=3).
    \item Fase 2: Buscar en grupos candidatos (O(N\_k)).
\end{enumerate}

Complejidad: O(K + N\_k) $\ll$ O(N)\\

\textbf{Resultados}: \textit{Dataset} actual (43 frases):\\

\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.6}
\begin{tabular}{|p{5cm}|p{3cm}|p{3cm}|}
\hline
 & \textbf{Exhaustiva} & \textbf{Jerárquica} \\ \hline

Comparaciones & 43 & 3 + $\sim$20 = 23 \\ \hline
\textit{Speedup} & 1x & 1.9x \\ \hline
Latencia & $\sim$42ms & $\sim$40ms \\ \hline

\end{tabular}
\caption[Comparación de métodos]{Comparación entre enfoque exhaustivo y jerárquico, elaboración propia.}
\end{table}

\newpage
{\large \noindent \textbf{Optimización de latencia}}\\
\textbf{Técnicas aplicadas}\\

\begin{enumerate}

    \item \textbf{Operaciones vectorizadas (NumPy)}
    \\[4pt]
    \begin{verbatim}
# LENTO: Loop
for i, emb in enumerate(embeddings):
    sim[i] = cosine_similarity([query_emb], [emb])

# RÁPIDO: Vectorizado
sims = cosine_similarity([query_emb], embeddings)[0]
    \end{verbatim}
    \textit{Speedup}: $\sim$100x.\\

    \item \textbf{\textit{Lazy loading} del modelo}
    \\[4pt]
    \begin{verbatim}
def _load_model(self):
    if self.model is None:
        self.model = SentenceTransformer(model_name)
    \end{verbatim}
    Ahorro: No cargar modelo si no hay \textit{requests}.\\

    \item \textbf{\textit{Batch processing}}
    \\[4pt]
    \begin{verbatim}
embeddings = model.encode(texts, batch_size=32)
    \end{verbatim}
    \textit{Speedup}: $\sim$2x para múltiples textos.\\

    \newpage
    \item \textbf{Async I/O (FastAPI)}
    \\[4pt]
    \begin{verbatim}
@app.post("/buscar")
async def buscar(request: QueryRequest):
    ...
    \end{verbatim}
    Permite manejar múltiples \textit{requests} concurrentes.\\

\end{enumerate}

{\large \noindent \textbf{\textit{Profile} de latencia}}\\

\textbf{\textit{Total latency}}: 40ms\\

\textit{Breakdown}:
\begin{itemize}
    \item Preprocesamiento: 2ms (5\%).
    \item Generación de \textit{embedding}: 15ms (37.5\%).
    \item Búsqueda por centroides: 3ms (7.5\%).
    \item \textit{Re-ranking}: 10ms (25\%).
    \item Detección de patrones: 5ms (12.5\%).
    \item Construcción de respuesta: 3ms (7.5\%).
    \item \textit{Overhead} (FastAPI): 2ms (5\%).
\end{itemize}

\vspace{1em}

\textbf{Cuellos de botella}:
\begin{enumerate}
    \item Generación de \textit{embedding} (37.5\%) $\leftarrow$ Mayor oportunidad.
    \item \textit{Re-ranking} (25\%).
\end{enumerate}


\newpage
{\large \noindent \textbf{Gestión de memoria}}

\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.6}
\begin{tabular}{|p{6cm}|p{3.5cm}|}
\hline
\textbf{Componente} & \textbf{Memoria} \\ \hline

Modelo \textit{transformer} & $\sim$420 MB \\ \hline
\textit{Embeddings} en cache & $\sim$65 KB \\ \hline
Centroides & $\sim$5 KB \\ \hline
\textit{FastAPI} + \textit{Uvicorn} & $\sim$50 MB \\ \hline
Python \textit{runtime} & $\sim$30 MB \\ \hline

\textbf{Total} & $\sim$500 MB \\ \hline

\end{tabular}
\caption[Memoria por componente]{Resumen de memoria utilizada por componente, elaboración propia.}
\end{table}

\textbf{Optimizaciones}
\begin{enumerate}
    \item Modelo ligero (MiniLM)
    \begin{itemize}
        \item 384 dimensiones vs 768 (BERT base).
        \item 420 MB vs 800 MB.
        \item Ahorro: 47.5\%.
    \end{itemize}

    \item \textit{Embeddings} comprimidos
    \begin{itemize}
        \item Formato .npz comprimido.
        \item 50 KB vs $\sim$100 KB sin comprimir.
        \item Ahorro: 50\%.
    \end{itemize}

    \item \textit{Garbage collection} optimizado
    \begin{verbatim}
    import gc
    gc.collect()  # Después de carga inicial
    \end{verbatim}
\end{enumerate}

\newpage
{\large \noindent \textbf{Escalabilidad}}\\
\textbf{Escalabilidad horizontal}\\
API \textit{stateless} permite múltiples instancias:\\

\begin{center}
    \includegraphics[width=0.75\textwidth]{Images/Cap5/2_API_Stateless.png}
    \captionof{figure}[API Stateless]{API \textit{Stateless}, elaboración propia.} 
\end{center}

\textbf{Configuración}:
\begin{verbatim}
# Instancia 1
uvicorn app.main:app --port 8001 &

# Instancia 2
uvicorn app.main:app --port 8002 &

# Instancia 3
uvicorn app.main:app --port 8003 &

# Load balancer (nginx)
upstream api_servers {
    server localhost:8001;
    server localhost:8002;
    server localhost:8003;
}
\end{verbatim}

\noindent \textbf{Escalabilidad con \textit{workers}}:
\begin{verbatim}
uvicorn app.main:app \
    --host 0.0.0.0 \
    --port 8000 \
    --workers 4
\end{verbatim}

\textbf{\textit{Throughput}}:
\begin{itemize}
    \item 1 \textit{worker}: $\sim$25 req/s.
    \item 4 \textit{workers}: $\sim$90 req/s (3.6x).
\end{itemize}

\newpage
\noindent \textbf{Limitaciones}
\begin{itemize}
    \item Modelo en memoria: $\sim$420 MB por \textit{worker}.
    \item 4 \textit{workers}: $\sim$1.7 GB memoria.
    \item Máximo recomendado: 8 \textit{workers} en servidor 8GB RAM.
\end{itemize}

\vspace{1em}

{\Large \noindent \textbf{Resultados y métricas}}\\
{\large \textbf{Métricas de precisión}}\\

\noindent \textbf{\textit{Dataset} de evaluación}\\
100 \textit{queries} de prueba en 3 categorías:
\begin{itemize}
    \item 40 \textit{queries} de emergencias (Grupo A).
    \item 30 \textit{queries} de saludos (Grupo B).
    \item 30 \textit{queries} de comunicación (Grupo C).
\end{itemize}

\textbf{Métricas Calculadas}

\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.6}
\begin{tabular}{|p{7cm}|p{3cm}|}
\hline
\textbf{Métrica} & \textbf{Valor} \\ \hline

\textit{Accuracy} (clasificación de grupos) & 92\% \\ \hline
\textit{Precision} (promedio) & 91\% \\ \hline
\textit{Recall} (promedio) & 90\% \\ \hline
\textit{F1-Score} (promedio) & 90.5\% \\ \hline
Similitud promedio (\textit{matches}) & 0.87 \\ \hline

\end{tabular}
\caption[Métricas de precisión]{Resumen de métricas de desempeño del modelo, elaboración propia.}
\end{table}

\textbf{Matriz de confusión}\\
\begin{center}
    \includegraphics[width=0.75\textwidth]{Images/Cap5/3_Matriz_Confusión.png}
    \captionof{figure}[Matriz de Confusión]{Matriz de confusión de cada grupo, elaboración propia.} 
\end{center}

Observaciones:
\begin{itemize}
    \item Grupo A (Emergencias): Mejor precisión (95\%).
    \item Confusión menor entre grupos similares.
    \item Errores en casos ambiguos.
\end{itemize}

{\large \noindent \textbf{Métricas de rendimiento}}\\

\noindent \textbf{Latencia}
\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.6}
\begin{tabular}{|p{5cm}|p{2cm}|p{2.5cm}|p{2cm}|}
\hline
\textbf{Métrica} & \textbf{Min} & \textbf{Promedio} & \textbf{Max} \\ \hline

Latencia (ms) & 35ms & 40ms & 48ms \\ \hline
Latencia P95 (ms) & -- & 45ms & -- \\ \hline
Latencia P99 (ms) & -- & 47ms & -- \\ \hline

\end{tabular}
\caption[Latencias]{Resumen de latencias medidas en entorno de pruebas, elaboración propia.}
\end{table}

\textbf{Objetivo}: <50ms (cumplido).\\

\noindent \textbf{\textit{Throughput}}
\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.6}
\begin{tabular}{|p{7cm}|p{3cm}|}
\hline
\textbf{Configuración} & \textbf{REQ/s} \\ \hline

1 \textit{worker} (single-core) & 25 req/s \\ \hline
4 \textit{workers} (4-core) & 90 req/s \\ \hline
8 \textit{workers} (8-core) & 160 req/s \\ \hline

\end{tabular}
\caption[Throughput por configuración]{Capacidad de procesamiento según número de \textit{workers}, elaboración propia.}
\end{table}

\textbf{Objetivo}: >20 req/s (cumplido).

\newpage
\noindent \textbf{Memoria}
\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.6}
\begin{tabular}{|p{6cm}|p{3.5cm}|}
\hline
\textbf{Métrica} & \textbf{Valor} \\ \hline

Memoria base (\textit{startup}) & $\sim$500 MB \\ \hline
Memoria por \textit{request} & +2 MB \\ \hline
Memoria después de 1000 \textit{requests} & $\sim$520 MB \\ \hline
Crecimiento & Estable \\ \hline

\end{tabular}
\caption[Memoria]{Consumo de memoria durante operación, elaboración propia.}
\end{table}

Sin \textit{memory leaks} detectados.\\

{\large \noindent \textbf{Métricas de usabilidad}}\\

\textbf{Swagger UI}
\begin{itemize}[label= \checkmark]
    \item Documentación automática.
    \item Testing interactivo.
    \item Ejemplos de \textit{requests}.
    \item \textit{Schemas} completos.
    \item Respuestas de error documentadas.
\end{itemize}

\textbf{API \textit{Consistency}}
\begin{itemize}[label= \checkmark]
    \item Formato JSON consistente.
    \item Campos opcionales claramente marcados.
    \item Validación automática de \textit{requests}.
    \item Mensajes de error descriptivos.
    \item HTTP \textit{status codes} apropiados.
\end{itemize}

\vspace{1em}

\newpage
{\large \noindent \textbf{Comparación con alternativas}}\\

\textbf{Ventajas del prototipo}
\begin{itemize}[label= \checkmark]
    \item Mayor precisión (92\% vs 60--75\%).
    \item Manejo de paráfrasis.
    \item Detección de nombres propios.
    \item Sistema de deletreo automático.
    \item API bien documentada.
    \item \textit{Tests} exhaustivos.
    \item Fácil de escalar.
\end{itemize}

\vspace{0.7em}

\textbf{Desventajas}
\begin{itemize}
    \item Mayor latencia (40ms vs 5--25ms)
    \item Mayor uso de memoria ($\sim$500MB vs 50--200MB)
    \item Requiere modelo pre-entrenado
\end{itemize}