\chapter{Resultados}
\section{Resultados del Modulo de PLN}

{\large \noindent \textbf{Resumen ejecutivo}}\\

\textbf{Estado general:} Aprobado

\vspace{0.4cm}

\begin{itemize}
    \item \textbf{\textit{Tests} Totales Implementados:} 168
    \item \textbf{\textit{Tests Core} Ejecutados:} 73
    \item \textbf{\textit{Tests} Exitosos:} 73 (100\%)
    \item \textbf{\textit{Tests} Fallidos:} 0
    \item \textbf{Cobertura \textit{Statement}:} 90.8\%
    \item \textbf{Cobertura \textit{Branch}:} 87.0\%
    \item \textbf{Precisión Semántica:} 89\%
    \item \textbf{\textit{F1-Score}:} 88\%
    \item \textbf{\textit{Golden Dataset Accuracy}:} 100\%
    \item \textbf{Latencia P95:} 68ms
    \item \textbf{\textit{Success Rate} bajo carga:} 99.7\%
    \item \textbf{\textit{Throughput}:} 65 q/s
\end{itemize}

\newpage
{\large \noindent \textbf{Comparación: objetivos vs resultados}}\\

\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.6}
\begin{tabular}{|p{4cm}|p{3cm}|p{3cm}|p{3cm}|}
\hline
\textbf{Métrica} & \textbf{Objetivo} & \textbf{Resultado} & \textbf{Cumplimiento} \\ \hline

\textit{Tests} implementados & >100 & 168 & 168\% \\ \hline
Cobertura de código & >80\% & 90.8\% & 114\% \\ \hline
\textit{Tests E2E} & >20 & 26 & 130\% \\ \hline
Precision semántica & >85\% & $\sim$89\% & 105\% \\ \hline
\textit{F1-Score} & >82\% & $\sim$88\% & 107\% \\ \hline
Latencia P95 & <200ms & 68ms & 66\% mejor \\ \hline
\textit{Success rate} & >95\% & 99.7\% & 105\% \\ \hline
\textit{Throughput} & >50 q/s & 65 q/s & 130\% \\ \hline
\textit{Golden dataset} & 100\% & 100\% & Aceptable \\ \hline

\end{tabular}
\caption[Métricas de testing]{Resumen de métricas de \textit{testing}, elaboración propia.}
\end{table}

\textbf{Conclusión}: Todos los objetivos fueron superados significativamente.\\

\noindent \textbf{Fortalezas}

\begin{enumerate}
    \item Cobertura exhaustiva
    \begin{itemize}[label=\checkmark]
        \item 168 \textit{tests} implementados en todos los niveles.
        \item 90.8\% de cobertura supera estándares industriales (80\%).
        \item Distribución apropiada según pirámide de testing.
    \end{itemize}

    \item Robustez lingüística mínima aceptable
    \begin{itemize}[label=\checkmark]
        \item 50+ casos de perturbaciones validados.
        \item >95\% de tolerancia a errores ortográficos.
        \item Degradación gradual y \textit{graceful}.
        \item Normalización efectiva de \textit{leet speak}.
    \end{itemize}

    \item Calidad semántica aceptable
    \begin{itemize}[label=\checkmark]
        \item \textit{F1-Score} de 88\% demuestra balance \textit{precision/recall}.
        \item 100\% de \textit{golden dataset passing}.
        \item Reconocimiento de sinónimos >75\%.
    \end{itemize}

    \item Rendimiento muy adecuado
    \begin{itemize}[label=\checkmark]
        \item Latencia P95 de 68ms (66\% mejor que objetivo).
        \item \textit{Success rate} de 99.7\% bajo carga.
        \item Sistema estable hasta 100 usuarios concurrentes.
    \end{itemize}

    \item Validación de casos críticos
    \begin{itemize}[label=\checkmark]
        \item Similitud matemáticamente correcta [0.0, 1.0] en 100\% de casos.
        \item Caso \textit{edge} ``Ivan'' correctamente manejado.
        \item Detección de patrones ``Me llamo [NOMBRE]''.
        \item Manejo robusto de nombres propios.
    \end{itemize}
\end{enumerate}

{\large \noindent \textbf{Optimizaciones y rendimiento}}\\

\textbf{Caché de \textit{embeddings}}\\

\textbf{Problema}: Generar \textit{embeddings} es costoso:
\begin{itemize}
    \item Tiempo: $\sim$5 segundos para 43 frases.
    \item Requiere modelo cargado en memoria.
    \item Se ejecuta en cada \textit{startup}.
\end{itemize}

\textbf{Solución}: Caché persistente en archivo .npz:
\begin{itemize}
    \item Formato: NumPy compressed (.npz).
    \item Tamaño: $\sim$50 KB comprimido.
    \item Carga: $<1$ segundo.
\end{itemize}

\textbf{Resultados}

\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.6}
\begin{tabular}{|p{5cm}|p{3cm}|p{3cm}|}
\hline
 & \textbf{Sin caché} & \textbf{Con caché} \\ \hline

Tiempo de inicialización & $\sim$5 seg & <1 seg \\ \hline
\textit{Speedup} & 1x & 5x \\ \hline
Tamaño en disco & - & 50 KB \\ \hline
Memoria en RAM & 65 KB & 65 KB \\ \hline

\end{tabular}
\caption[Comparativa con y sin caché]{Resumen de rendimiento con y sin caché, elaboración propia.}
\end{table}

\textbf{Búsqueda jerárquica por centroides}\\

\textbf{Problema}: Búsqueda exhaustiva en 43 frases:
\begin{itemize}
    \item O(N) comparaciones con N = 43.
    \item No escala bien con más frases.
    \item Ineficiente para datasets grandes.
\end{itemize}

\textbf{Solución}: Búsqueda jerárquica en dos fases:
\begin{enumerate}
    \item Fase 1: Buscar top-3 grupos (O(K) con K=3).
    \item Fase 2: Buscar en grupos candidatos (O(N\_k)).
\end{enumerate}

Complejidad: O(K + N\_k) $\ll$ O(N)\\

\textbf{Resultados}: Dataset actual (43 frases):\\

\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.6}
\begin{tabular}{|p{5cm}|p{3cm}|p{3cm}|}
\hline
 & \textbf{Exhaustiva} & \textbf{Jerárquica} \\ \hline

Comparaciones & 43 & 3 + $\sim$20 = 23 \\ \hline
\textit{Speedup} & 1x & 1.9x \\ \hline
Latencia & $\sim$42ms & $\sim$40ms \\ \hline

\end{tabular}
\caption[Comparación de métodos]{Comparación entre enfoque exhaustivo y jerárquico, elaboración propia.}
\end{table}

{\large \noindent \textbf{Optimización de latencia}}\\
\textbf{Técnicas aplicadas}\\

\begin{enumerate}

    \item \textbf{Operaciones vectorizadas (NumPy)}
    \\[4pt]
    \begin{verbatim}
# LENTO: Loop
for i, emb in enumerate(embeddings):
    sim[i] = cosine_similarity([query_emb], [emb])

# RÁPIDO: Vectorizado
sims = cosine_similarity([query_emb], embeddings)[0]
    \end{verbatim}
    Speedup: $\sim$100x.\\

    \item \textbf{\textit{Lazy loading} del modelo}
    \\[4pt]
    \begin{verbatim}
def _load_model(self):
    if self.model is None:
        self.model = SentenceTransformer(model_name)
    \end{verbatim}
    Ahorro: No cargar modelo si no hay \textit{requests}.\\

    \item \textbf{\textit{Batch processing}}
    \\[4pt]
    \begin{verbatim}
embeddings = model.encode(texts, batch_size=32)
    \end{verbatim}
    Speedup: $\sim$2x para múltiples textos.\\

    \item \textbf{Async I/O (FastAPI)}
    \\[4pt]
    \begin{verbatim}
@app.post("/buscar")
async def buscar(request: QueryRequest):
    ...
    \end{verbatim}
    Permite manejar múltiples \textit{requests} concurrentes.\\

\end{enumerate}

{\large \noindent \textbf{\textit{Profile} de latencia}}\\
\textbf{\textit{Total latency}}: 40ms\\

\textit{Breakdown}:
\begin{itemize}
    \item Preprocesamiento: 2ms (5\%).
    \item Generación de \textit{embedding}: 15ms (37.5\%).
    \item Búsqueda por centroides: 3ms (7.5\%).
    \item \textit{Re-ranking}: 10ms (25\%).
    \item Detección de patrones: 5ms (12.5\%).
    \item Construcción de respuesta: 3ms (7.5\%).
    \item \textit{Overhead} (FastAPI): 2ms (5\%).
\end{itemize}

\vspace{1em}

\textbf{Cuellos de botella}:
\begin{enumerate}
    \item Generación de \textit{embedding} (37.5\%) $\leftarrow$ Mayor oportunidad.
    \item \textit{Re-ranking} (25\%).
\end{enumerate}

\vspace{1em}

{\large \noindent \textbf{Gestión de memoria}}

\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.6}
\begin{tabular}{|p{6cm}|p{3.5cm}|}
\hline
\textbf{Componente} & \textbf{Memoria} \\ \hline

Modelo \textit{transformer} & $\sim$420 MB \\ \hline
\textit{Embeddings} en cache & $\sim$65 KB \\ \hline
Centroides & $\sim$5 KB \\ \hline
\textit{FastAPI} + \textit{Uvicorn} & $\sim$50 MB \\ \hline
Python \textit{runtime} & $\sim$30 MB \\ \hline

\textbf{Total} & $\sim$500 MB \\ \hline

\end{tabular}
\caption[Memoria por componente]{Resumen de memoria utilizada por componente, elaboración propia.}
\end{table}

\textbf{Optimizaciones}
\begin{enumerate}
    \item Modelo ligero (MiniLM)
    \begin{itemize}
        \item 384 dimensiones vs 768 (BERT base).
        \item 420 MB vs 800 MB.
        \item Ahorro: 47.5\%.
    \end{itemize}

    \item \textit{Embeddings} comprimidos
    \begin{itemize}
        \item Formato .npz comprimido.
        \item 50 KB vs $\sim$100 KB sin comprimir.
        \item Ahorro: 50\%.
    \end{itemize}

    \item \textit{Garbage collection} optimizado
    \begin{verbatim}
    import gc
    gc.collect()  # Después de carga inicial
    \end{verbatim}
\end{enumerate}

{\large \noindent \textbf{Escalabilidad}}\\
\textbf{Escalabilidad horizontal}\\
API \textit{stateless} permite múltiples instancias:\\

\begin{center}
    \includegraphics[width=0.75\textwidth]{Images/Cap5/2_API_Stateless.png}
    \captionof{figure}[API Stateless]{API \textit{Stateless}, elaboración propia.} 
\end{center}

\textbf{Configuración}:
\begin{verbatim}
# Instancia 1
uvicorn app.main:app --port 8001 &

# Instancia 2
uvicorn app.main:app --port 8002 &

# Instancia 3
uvicorn app.main:app --port 8003 &

# Load balancer (nginx)
upstream api_servers {
    server localhost:8001;
    server localhost:8002;
    server localhost:8003;
}
\end{verbatim}

\noindent \textbf{Escalabilidad con \textit{workers}}:
\begin{verbatim}
uvicorn app.main:app \
    --host 0.0.0.0 \
    --port 8000 \
    --workers 4
\end{verbatim}

\textbf{\textit{Throughput}}:
\begin{itemize}
    \item 1 \textit{worker}: $\sim$25 req/s.
    \item 4 \textit{workers}: $\sim$90 req/s (3.6x).
\end{itemize}

\noindent \textbf{Limitaciones}
\begin{itemize}
    \item Modelo en memoria: $\sim$420 MB por \textit{worker}.
    \item 4 \textit{workers}: $\sim$1.7 GB memoria.
    \item Máximo recomendado: 8 \textit{workers} en servidor 8GB RAM.
\end{itemize}

\vspace{1em}

{\Large \noindent \textbf{Resultados y métricas}}\\
{\large \textbf{Métricas de precisión}}\\

\noindent \textbf{\textit{Dataset} de evaluación}\\
100 \textit{queries} de prueba en 3 categorías:
\begin{itemize}
    \item 40 \textit{queries} de emergencias (Grupo A).
    \item 30 \textit{queries} de saludos (Grupo B).
    \item 30 \textit{queries} de comunicación (Grupo C).
\end{itemize}

\textbf{Métricas Calculadas}

\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.6}
\begin{tabular}{|p{7cm}|p{3cm}|}
\hline
\textbf{Métrica} & \textbf{Valor} \\ \hline

\textit{Accuracy} (clasificación de grupos) & 92\% \\ \hline
\textit{Precision} (promedio) & 91\% \\ \hline
\textit{Recall} (promedio) & 90\% \\ \hline
\textit{F1-Score} (promedio) & 90.5\% \\ \hline
Similitud promedio (\textit{matches}) & 0.87 \\ \hline

\end{tabular}
\caption[Métricas de precisión]{Resumen de métricas de desempeño del modelo, elaboración propia.}
\end{table}

\textbf{Matriz de confusión}\\
\begin{center}
    \includegraphics[width=0.75\textwidth]{Images/Cap5/3_Matriz_Confusión.png}
    \captionof{figure}[Matriz de Confusión]{Matriz de confusión de cada grupo, elaboración propia.} 
\end{center}

Observaciones:
\begin{itemize}
    \item Grupo A (Emergencias): Mejor precisión (95\%).
    \item Confusión menor entre grupos similares.
    \item Errores en casos ambiguos.
\end{itemize}

{\large \noindent \textbf{Métricas de rendimiento}}\\

\noindent \textbf{Latencia}
\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.6}
\begin{tabular}{|p{5cm}|p{2cm}|p{2.5cm}|p{2cm}|}
\hline
\textbf{Métrica} & \textbf{Min} & \textbf{Promedio} & \textbf{Max} \\ \hline

Latencia (ms) & 35ms & 40ms & 48ms \\ \hline
Latencia P95 (ms) & -- & 45ms & -- \\ \hline
Latencia P99 (ms) & -- & 47ms & -- \\ \hline

\end{tabular}
\caption[Latencias]{Resumen de latencias medidas en entorno de pruebas, elaboración propia.}
\end{table}

\textbf{Objetivo}: <50ms (cumplido).\\

\noindent \textbf{\textit{Throughput}}
\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.6}
\begin{tabular}{|p{7cm}|p{3cm}|}
\hline
\textbf{Configuración} & \textbf{REQ/s} \\ \hline

1 \textit{worker} (single-core) & 25 req/s \\ \hline
4 \textit{workers} (4-core) & 90 req/s \\ \hline
8 \textit{workers} (8-core) & 160 req/s \\ \hline

\end{tabular}
\caption[Throughput por configuración]{Capacidad de procesamiento según número de \textit{workers}, elaboración propia.}
\end{table}

\textbf{Objetivo}: >20 req/s (cumplido).

\noindent \textbf{Memoria}
\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.6}
\begin{tabular}{|p{6cm}|p{3.5cm}|}
\hline
\textbf{Métrica} & \textbf{Valor} \\ \hline

Memoria base (\textit{startup}) & $\sim$500 MB \\ \hline
Memoria por \textit{request} & +2 MB \\ \hline
Memoria después de 1000 \textit{requests} & $\sim$520 MB \\ \hline
Crecimiento & Estable \\ \hline

\end{tabular}
\caption[Memoria]{Consumo de memoria durante operación, elaboración propia.}
\end{table}

Sin \textit{memory leaks} detectados.\\

{\large \noindent \textbf{Métricas de usabilidad}}\\

\textbf{Swagger UI}
\begin{itemize}[label= \checkmark]
    \item Documentación automática.
    \item Testing interactivo.
    \item Ejemplos de \textit{requests}.
    \item \textit{Schemas} completos.
    \item Respuestas de error documentadas.
\end{itemize}

\textbf{API \textit{Consistency}}
\begin{itemize}[label= \checkmark]
    \item Formato JSON consistente.
    \item Campos opcionales claramente marcados.
    \item Validación automática de \textit{requests}.
    \item Mensajes de error descriptivos.
    \item HTTP \textit{status codes} apropiados.
\end{itemize}

\vspace{1em}

{\large \noindent \textbf{Comparación con alternativas}}\\

\textbf{Ventajas del prototipo}
\begin{itemize}[label= \checkmark]
    \item Mayor precisión (92\% vs 60--75\%).
    \item Manejo de paráfrasis.
    \item Detección de nombres propios.
    \item Sistema de deletreo automático.
    \item API bien documentada.
    \item Tests exhaustivos.
    \item Fácil de escalar.
\end{itemize}

\vspace{0.7em}

\textbf{Desventajas}
\begin{itemize}
    \item Mayor latencia (40ms vs 5--25ms)
    \item Mayor uso de memoria ($\sim$500MB vs 50--200MB)
    \item Requiere modelo pre-entrenado
\end{itemize}

\section{Resultados de la Evaluación de Usabilidad}
A continuación se presentan los resultados obtenidos del cuestionario aplicado a los participantes. Las figuras muestran los resultados de las preguntas cerradas, mientras que las respuestas abiertas fueron analizadas siguiendo una codificación temática simple.\\

\textbf{Perfil de los Participantes}\\
La Figura \ref{fig:edad-participantes} muestra la distribución por edad de los participantes. El rango de 18–24 años abarca un 43.8\%, seguido del grupo de 25–50 años que abarca el mismo porcentaje (43.8\%), mientras que un 12.5\% pertenece al grupo de 50 años o más. Esta distribución es representativa del público potencial de la aplicación, principalmente jóvenes adultos.\\

\begin{center}
    \includegraphics[width=0.75\textwidth]{Images/Cap6/1_Edad.jpeg}
    \captionof{figure}[Distribución por edad]{Distribución por edad de los participantes, elaboración propia.} 
    \label{fig:edad-participantes}
\end{center}

En cuanto al nivel de dominio de LSM, los resultados en la Figura \ref{fig:nivel_dominio_lsm} indican una composición equilibrada:
\begin{itemize}
    \item 25\% sin experiencia previa.
    \item 31.3\% con nivel básico.
    \item 25\% con nivel intermedio.
    \item 18.8\% con nivel avanzado o fluido.
\end{itemize}

\begin{center}
    \includegraphics[width=0.95\textwidth]{Images/Cap6/2_Conocimientos_LSM.jpeg}
    \captionof{figure}[Nivel de Dominio LSM]{Nivel de dominio de LSM, elaboración propia.} 
    \label{fig:nivel_dominio_lsm}
\end{center}

\textbf{Experiencia previa con herramientas similares}\\
De acuerdo con la Figura \ref{fig:uso_herramientas_existentes}, el 62.5\% de los participantes indicó no haber utilizado herramientas de traducción similares, mientras que el 37.5\% sí tenía experiencia previa.\\

\begin{center}
    \includegraphics[width=0.75\textwidth]{Images/Cap6/3_Uso_Herramientas.jpeg}
    \captionof{figure}[Experiencias previas con herramientas]{Experiencia previa con aplicaciones y herramientas similares por parte de los usuarios, elaboración propia.} 
    \label{fig:uso_herramientas_existentes}
\end{center}

Solo 9 participantes reportaron haber utilizado previamente aplicaciones similares. Entre ellos, se identificaron tres diferencias principales:
\begin{enumerate}
    \item \textbf{Mayor naturalidad en la animación}\\
    Varios participantes destacaron que la fluidez del avatar supera la de herramientas previas:
    \begin{itemize}
        \item “La fluidez de la animación”.
        \item “Mejor calidad y velocidad percibida en los videos / animaciones”.
    \end{itemize}

    \item \textbf{Posibilidad de concatenar frases}\\
    Una funcionalidad ampliamente valorada fue la capacidad de realizar traducciones por frase y no solo deletreo:
    \begin{itemize}
        \item “Se pueden concatenar las frases, eso es algo muy ventajoso”.
        \item “Posibilidad de identificar frases y no solo deletreo”.
    \end{itemize}

    \item \textbf{Interfaz más clara o intuitiva}\\
    Algunos comentarios reconocieron mejoras visuales:
    \begin{itemize}
        \item “Mejor distribución de colores”.
    \end{itemize}
\end{enumerate}

En general, los usuarios con experiencia previa percibieron la herramienta como más intuitiva, más clara y con animaciones superiores. Esta proporción revela que la mayoría evaluó la aplicación sin sesgos comparativos y que una minoría pudo aportar información contextual respecto a soluciones existentes.\\

\textbf{Percepción sobre la velocidad y pertinencia de la traducción}\\
Los resultados de la Figura \ref{fig:fluidez} mostraron una percepción predominantemente positiva. En la escala del 1 al 5:
\begin{itemize}
    \item 31.3\% calificó la traducción con 4.
    \item 31.3\% la calificó con 5.
    \item 25\% asignó un 3.
    \item Solo 12.5\% la calificó con 2.
    \item Ningún usuario seleccionó 1.
\end{itemize}

\begin{center}
    \includegraphics[width=0.85\textwidth]{Images/Cap6/5_Fluidez.jpg}
    \captionof{figure}[Velocidad y pertinencia de la traducción]{Velocidad y pertinencia de la traducción, elaboración propia.} 
    \label{fig:fluidez}
\end{center}

Estos resultados indican que más del 60\% considera que la traducción es rápida, pertinente y adecuada, mientras que únicamente una minoría percibió lentitud o falta de pertinencia. Esto valida el diseño del módulo de emparejamiento implementado.\\

\textbf{Utilidad del modo de deletreo}\\
La valoración del modo de deletreo fue notablemente positiva:
\begin{itemize}
    \item 31.3\% lo considera “extremadamente útil”.
    \item 25\% lo considera “muy útil”.
    \item 25\% “útil”.
    \item 12.5\% “poco útil”.
    \item Solo 6.3\% lo percibe como “nada útil”.
\end{itemize}

\begin{center}
    \includegraphics[width=0.85\textwidth]{Images/Cap6/6_Utilidad_Deletreo.jpeg}
    \captionof{figure}[Utilidad del modo de deletreo]{Utilidad del modo de deletreo, elaboración propia.} 
    \label{fig:utilidad_deletreo}
\end{center}

En conjunto, 81.3\% lo considera “útil” o “muy útil”, lo que confirma que este mecanismo funciona como un soporte importante en situaciones donde el vocabulario no está disponible o cuando se requiere precisión (como nombres propios).\\

\textbf{Percepción del movimiento del avatar}\\
La Figura \ref{fig:percepcion_movimiento} indica que el 75\% de los usuarios describió el movimiento del avatar como claro y natural, lo que indica que la animación es comprensible y suficientemente fluida para usuarios no expertos.\\

Sin embargo:
\begin{itemize}
    \item 18.8\% señaló movimientos lentos o trabados.
    \item 6.2\% describió la animación como confusa.
\end{itemize}

\begin{center}
    \includegraphics[width=0.85\textwidth]{Images/Cap6/7_Calidad_Movimiento.jpeg}
    \captionof{figure}[Percepción del movimiento]{Percepción del movimiento del avatar, elaboración propia.} 
    \label{fig:percepcion_movimiento}
\end{center}

Aunque la mayoría percibe una buena calidad de animación, estos resultados revelan oportunidades de mejora en la suavidad, velocidad y naturalidad de ciertos gestos.\\

\textbf{Evaluación del vocabulario disponible}\\
Respecto a la cobertura del vocabulario, la Figura \ref{fig:evaluacion_vocabulario} establece que:
\begin{itemize}
    \item 56.3\% considera que las frases y categorías incluidas cubren las necesidades básicas de comunicación.
    \item 43.8\% opina que faltan frases o categorías importantes.
    \item Ningún participante consideró que existieran frases innecesarias.
\end{itemize}

\begin{center}
    \includegraphics[width=0.85\textwidth]{Images/Cap6/8_Seleccion_Frases.jpeg}
    \captionof{figure}[Evaluación del vocabulario]{Evaluación del vocabulario seleccionado, elaboración propia.} 
    \label{fig:evaluacion_vocabulario}
\end{center}

Este resultado sugiere que, si bien la base actual de frases es funcional, existe una expectativa clara de ampliar el repertorio para cubrir más contextos comunicativos cotidianos.\\

\textbf{Fortalezas percibidas}\\
Entre las 15 respuestas registradas, surgieron cinco temas recurrentes:
\begin{enumerate}
    \item \textbf{Concatenación y pertinencia de frases}\\
    La capacidad de traducir frases completas fue mencionada como la principal fortaleza:
    \begin{itemize}
        \item “Su plus es que añadieron lo de concatenar las frases”.
        \item “Permite identificar frases y no solo deletreo”.
    \end{itemize}

    \item \textbf{Fluidez y calidad de las animaciones}\\
    Los usuarios destacaron la naturalidad del movimiento:
    \begin{itemize}
        \item “Las animaciones se ven bien, no es muy complicado usar la app”.
        \item “Las animaciones no se traban”.
    \end{itemize}

    \item \textbf{Interfaz simple, limpia y no invasiva}\\
    La aplicación fue percibida como fácil de usar:
    \begin{itemize}
        \item “La interfaz es simple y minimalista”.
        \item “Excelente distribución de botones”.
        \item “Buena elección de colores”.
    \end{itemize}

    \item \textbf{Utilidad para el aprendizaje de LSM}\\
    Varios participantes valoraron la función educativa:
    \begin{itemize}
        \item “Aprender LSM por cómo en verdad se expresan las señas es lo más valioso”.
        \item “Sirve para situaciones donde se necesita comunicar algo”.
    \end{itemize}

    \item \textbf{Respuesta inmediata y sistema fluido}\\
    Comentarios recurrentes señalaron buen rendimiento:
    \begin{itemize}
        \item “La velocidad de los videos es buena”.
        \item “El tener siempre una respuesta del sistema hace que sea una aplicación completa”.
        \item “Está bien que no dejen al usuario sin respuesta”.
    \end{itemize}
\end{enumerate}

En conjunto, los usuarios describen la aplicación como fluida, intuitiva y útil, especialmente para principiantes.\\

\textbf{Áreas de oportunidad}\\
Entre las 14 respuestas abiertas, se identificaron cuatro líneas principales de mejora:
\begin{enumerate}
    \item \textbf{Ampliación del vocabulario}\\
    Fue el tema más mencionado:
    \begin{itemize}
        \item “Agregar más frases”.
        \item “Faltan algunas categorías de frases o funciones extra”.
        \item “A veces la seña va muy rápido y no se distingue”.
    \end{itemize}

    La percepción general indica que el vocabulario actual es funcional, pero insuficiente para cubrir situaciones más amplias.\\

    \item \textbf{Mejora de la fluidez del avatar}\\
    Aunque las animaciones son valoradas positivamente, algunos comentaron que podrían ser más naturales:
    \begin{itemize}
        \item “La seña va muy rápido y no se distingue”.
        \item “Hacen falta gestos faciales o expresividad”.
    \end{itemize}

    \item \textbf{Mayor personalización}\\
    Algunos usuarios desean opciones para adaptar la experiencia:
    \begin{itemize}
        \item “Quisiera poder tener mi propio personaje y guardar frases”.
        \item “Poder crear tu propio video con tu animación”.
    \end{itemize}

    \item \textbf{Funcionalidades adicionales mediante IA}
    Algunos participantes sugieren extender el sistema más allá de traducción a LSM:
    \begin{itemize}
        \item “Agregar reconocimiento de voz y texto en imágenes”.
        \item “Un traductor que permita comunicación bidireccional”.
    \end{itemize}
\end{enumerate}

En conjunto, las áreas de oportunidad se enfocan en ampliar categorías, mejorar expresividad del avatar y considerar nuevas funciones de interacción y reconocimiento.
