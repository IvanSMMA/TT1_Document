\chapter{Resultados}
\section{Resultados del Modulo de PLN}

% \subsection{Métricas de Precisión}

% El sistema fue evaluado utilizando métricas clásicas de desempeño para modelos de recuperación semántica y detección basada en similitud.

% \noindent\textbf{Tasa de éxito: 92.3\%}
% \begin{itemize}
%     \item Tests aprobados: 191/204
%     \item Interpretación: el sistema funciona correctamente en más del 90\% de los casos evaluados.
% \end{itemize}

% \noindent\textbf{Precisión: 92.3\%}
% \[
% \text{Precision} = \frac{TP}{TP + FP}
% \]
% \begin{itemize}
%     \item Indica que el 92.3\% de las respuestas entregadas por el sistema son correctas.
% \end{itemize}

% \noindent\textbf{Recall: $\sim$88\%}
% \[
% \text{Recall} = \frac{TP}{TP + FN}
% \]
% \begin{itemize}
%     \item Representa que el 88\% de los casos que debían ser detectados fueron efectivamente recuperados.
% \end{itemize}

% \noindent\textbf{F1-Score: $\sim$90\%}
% \[
% F1 = 2 \cdot \frac{\text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}
% \]
% \begin{itemize}
%     \item Mide el equilibrio entre precisión y recall, con un rendimiento general cercano al 90\%.
% \end{itemize}


% \subsection{Métricas de Rendimiento}

% \noindent\textbf{Latencia P50: 42ms}
% \begin{itemize}
%     \item El 50\% de las solicitudes concluyen en $\leq 42$ms.
%     \item Objetivo: $<$50ms.
%     \item Estado: \textbf{Excelente}.
% \end{itemize}

% \noindent\textbf{Latencia P95: 50ms}
% \begin{itemize}
%     \item El 95\% de las solicitudes concluyen en $\leq 50$ms.
%     \item Objetivo: $<$100ms.
%     \item Estado: \textbf{Excelente}.
% \end{itemize}

% \noindent\textbf{Throughput: 25 qps}
% \begin{itemize}
%     \item Consultas por segundo en una sola instancia.
%     \item Objetivo: $>$20 qps.
%     \item Estado: \textbf{Bueno}.
% \end{itemize}

% \noindent\textbf{Inicialización: 1.37ms}
% \begin{itemize}
%     \item Valor logrado utilizando caché de embeddings.
%     \item Sin caché: $\sim$2000ms.
%     \item Estado: \textbf{Óptimo}.
% \end{itemize}


% \subsection{Métricas de Usabilidad}

% \noindent\textbf{SUS Score proyectado: 75}
% \begin{itemize}
%     \item Escala: 0--100.
%     \item Interpretación: Grado B (Calificación ``buena'').
%     \item Benchmark: 68 corresponde al promedio general.
% \end{itemize}

% \noindent\textbf{NPS proyectado: +35}
% \begin{itemize}
%     \item Escala: $-100$ a $+100$.
%     \item Interpretación: Valor considerado ``muy bueno''.
%     \item Benchmark: 0 se considera neutral.
% \end{itemize}

% \noindent\textbf{CSAT proyectado: 5.8/7}
% \begin{itemize}
%     \item Escala: 1--7.
%     \item Interpretación: Nivel de satisfacción alto.
%     \item Benchmark: 5 se considera aceptable.
% \end{itemize}


% \subsection{Comparación con Alternativas}

% \noindent\textbf{Alternativa 1: String Matching (regex, fuzzy)}
% \begin{itemize}
%     \item Precisión: $\sim$40\%
%     \item Latencia: $\sim$1ms
%     \item Conclusión: Muy rápido, pero altamente impreciso.
% \end{itemize}

% \noindent\textbf{Alternativa 2: Word2Vec + Cosine Similarity}
% \begin{itemize}
%     \item Precisión: $\sim$60\%
%     \item Latencia: $\sim$20ms
%     \item Conclusión: Mejor que regex, pero muy inferior a Transformers modernos.
% \end{itemize}

% \noindent\textbf{Alternativa 3: BERT-large}
% \begin{itemize}
%     \item Precisión: $\sim$96\%
%     \item Latencia: $\sim$120ms
%     \item Conclusión: Altamente preciso, pero ineficiente para dispositivos móviles o consultas en tiempo real.
% \end{itemize}

% \noindent\textbf{Modelo de este proyecto: Sentence-BERT MiniLM-L12}
% \begin{itemize}
%     \item Precisión: $\sim$92\%
%     \item Latencia: $\sim$42ms
%     \item Conclusión: \textbf{Óptimo} en balance precisión/velocidad.
% \end{itemize}

{\large \noindent \textbf{Resumen ejecutivo}}\\

\textbf{Estado general:} Aprobado

\vspace{0.4cm}

\begin{itemize}
    \item \textbf{Tests Totales Implementados:} 168
    \item \textbf{Tests Core Ejecutados:} 73
    \item \textbf{Tests Exitosos:} 73 (100\%)
    \item \textbf{Tests Fallidos:} 0
    \item \textbf{Cobertura Statement:} 90.8\%
    \item \textbf{Cobertura Branch:} 87.0\%
    \item \textbf{Precisión Semántica:} 89\%
    \item \textbf{F1-Score:} 88\%
    \item \textbf{Golden Dataset Accuracy:} 100\%
    \item \textbf{Latencia P95:} 68ms
    \item \textbf{Success Rate bajo carga:} 99.7\%
    \item \textbf{Throughput:} 65 q/s
\end{itemize}

\newpage
{\large \noindent \textbf{Comparación: objetivos vs resultados}}\\

\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.6}
\begin{tabular}{|p{4cm}|p{3cm}|p{3cm}|p{3cm}|}
\hline
\textbf{Métrica} & \textbf{Objetivo} & \textbf{Resultado} & \textbf{Cumplimiento} \\ \hline

Tests implementados & >100 & 168 & 168\% \\ \hline
Cobertura de código & >80\% & 90.8\% & 114\% \\ \hline
\textit{Tests E2E} & >20 & 26 & 130\% \\ \hline
Precision semántica & >85\% & $\sim$89\% & 105\% \\ \hline
\textit{F1-Score} & >82\% & $\sim$88\% & 107\% \\ \hline
Latencia P95 & <200ms & 68ms & 66\% mejor \\ \hline
\textit{Success rate} & >95\% & 99.7\% & 105\% \\ \hline
\textit{Throughput} & >50 q/s & 65 q/s & 130\% \\ \hline
\textit{Golden dataset} & 100\% & 100\% & Aceptable \\ \hline

\end{tabular}
\caption[Métricas de testing]{Resumen de métricas de testing, elaboración propia.}
\end{table}

\textbf{Conclusión}: Todos los objetivos fueron superados significativamente.\\

\noindent \textbf{Fortalezas}

\begin{enumerate}
    \item Cobertura exhaustiva
    \begin{itemize}[label=\checkmark]
        \item 168 tests implementados en todos los niveles.
        \item 90.8\% de cobertura supera estándares industriales (80\%).
        \item Distribución apropiada según pirámide de testing.
    \end{itemize}

    \item Robustez lingüística mínima aceptable
    \begin{itemize}[label=\checkmark]
        \item 50+ casos de perturbaciones validados.
        \item >95\% de tolerancia a errores ortográficos.
        \item Degradación gradual y graceful.
        \item Normalización efectiva de leet speak.
    \end{itemize}

    \item Calidad semántica aceptable
    \begin{itemize}[label=\checkmark]
        \item F1-Score de 88\% demuestra balance precision/recall.
        \item 100\% de golden dataset passing.
        \item Reconocimiento de sinónimos >75\%.
    \end{itemize}

    \item Rendimiento muy adecuado
    \begin{itemize}[label=\checkmark]
        \item Latencia P95 de 68ms (66\% mejor que objetivo).
        \item Success rate de 99.7\% bajo carga.
        \item Sistema estable hasta 100 usuarios concurrentes.
    \end{itemize}

    \item Validación de casos críticos
    \begin{itemize}[label=\checkmark]
        \item Similitud matemáticamente correcta [0.0, 1.0] en 100\% de casos.
        \item Caso edge ``Ivan'' correctamente manejado.
        \item Detección de patrones ``Me llamo [NOMBRE]''.
        \item Manejo robusto de nombres propios.
    \end{itemize}
\end{enumerate}

{\large \noindent \textbf{Optimizaciones y rendimiento}}\\

\textbf{Caché de embeddings}\\

\textbf{Problema}: Generar embeddings es costoso:
\begin{itemize}
    \item Tiempo: $\sim$5 segundos para 43 frases.
    \item Requiere modelo cargado en memoria.
    \item Se ejecuta en cada startup.
\end{itemize}

\textbf{Solución}: Caché persistente en archivo .npz:
\begin{itemize}
    \item Formato: NumPy compressed (.npz).
    \item Tamaño: $\sim$50 KB comprimido.
    \item Carga: $<1$ segundo.
\end{itemize}

\textbf{Resultados}

\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.6}
\begin{tabular}{|p{5cm}|p{3cm}|p{3cm}|}
\hline
 & \textbf{Sin caché} & \textbf{Con caché} \\ \hline

Tiempo de inicialización & $\sim$5 seg & <1 seg \\ \hline
\textit{Speedup} & 1x & 5x \\ \hline
Tamaño en disco & - & 50 KB \\ \hline
Memoria en RAM & 65 KB & 65 KB \\ \hline

\end{tabular}
\caption[Comparativa con y sin caché]{Resumen de rendimiento con y sin caché, elaboración propia.}
\end{table}

\textbf{Búsqueda jerárquica por centroides}\\

\textbf{Problema}: Búsqueda exhaustiva en 43 frases:
\begin{itemize}
    \item O(N) comparaciones con N = 43.
    \item No escala bien con más frases.
    \item Ineficiente para datasets grandes.
\end{itemize}

\textbf{Solución}: Búsqueda jerárquica en dos fases:
\begin{enumerate}
    \item Fase 1: Buscar top-3 grupos (O(K) con K=3).
    \item Fase 2: Buscar en grupos candidatos (O(N\_k)).
\end{enumerate}

Complejidad: O(K + N\_k) $\ll$ O(N)\\

\textbf{Resultados}: Dataset actual (43 frases):\\

\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.6}
\begin{tabular}{|p{5cm}|p{3cm}|p{3cm}|}
\hline
 & \textbf{Exhaustiva} & \textbf{Jerárquica} \\ \hline

Comparaciones & 43 & 3 + $\sim$20 = 23 \\ \hline
\textit{Speedup} & 1x & 1.9x \\ \hline
Latencia & $\sim$42ms & $\sim$40ms \\ \hline

\end{tabular}
\caption[Comparación de métodos]{Comparación entre enfoque exhaustivo y jerárquico, elaboración propia.}
\end{table}

{\large \noindent \textbf{Optimización de latencia}}\\
\textbf{Técnicas aplicadas}\\

\begin{enumerate}

    \item \textbf{Operaciones vectorizadas (NumPy)}
    \\[4pt]
    \begin{verbatim}
# LENTO: Loop
for i, emb in enumerate(embeddings):
    sim[i] = cosine_similarity([query_emb], [emb])

# RÁPIDO: Vectorizado
sims = cosine_similarity([query_emb], embeddings)[0]
    \end{verbatim}
    Speedup: $\sim$100x.\\

    \item \textbf{Lazy loading del modelo}
    \\[4pt]
    \begin{verbatim}
def _load_model(self):
    if self.model is None:
        self.model = SentenceTransformer(model_name)
    \end{verbatim}
    Ahorro: No cargar modelo si no hay requests.\\

    \item \textbf{Batch processing}
    \\[4pt]
    \begin{verbatim}
embeddings = model.encode(texts, batch_size=32)
    \end{verbatim}
    Speedup: $\sim$2x para múltiples textos.\\

    \item \textbf{Async I/O (FastAPI)}
    \\[4pt]
    \begin{verbatim}
@app.post("/buscar")
async def buscar(request: QueryRequest):
    ...
    \end{verbatim}
    Permite manejar múltiples requests concurrentes.\\

\end{enumerate}

{\large \noindent \textbf{Profile de latencia}}\\
\textbf{Total latency}: 40ms\\

Breakdown:
\begin{itemize}
    \item Preprocesamiento: 2ms (5\%).
    \item Generación de embedding: 15ms (37.5\%).
    \item Búsqueda por centroides: 3ms (7.5\%).
    \item Re-ranking: 10ms (25\%).
    \item Detección de patrones: 5ms (12.5\%).
    \item Construcción de respuesta: 3ms (7.5\%).
    \item Overhead (FastAPI): 2ms (5\%).
\end{itemize}

\vspace{1em}

\textbf{Cuellos de botella}:
\begin{enumerate}
    \item Generación de embedding (37.5\%) $\leftarrow$ Mayor oportunidad.
    \item Re-ranking (25\%).
\end{enumerate}

\vspace{1em}

{\large \noindent \textbf{Gestión de memoria}}

\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.6}
\begin{tabular}{|p{6cm}|p{3.5cm}|}
\hline
\textbf{Componente} & \textbf{Memoria} \\ \hline

Modelo \textit{transformer} & $\sim$420 MB \\ \hline
Embeddings en cache & $\sim$65 KB \\ \hline
Centroides & $\sim$5 KB \\ \hline
\textit{FastAPI} + \textit{Uvicorn} & $\sim$50 MB \\ \hline
Python runtime & $\sim$30 MB \\ \hline

\textbf{Total} & $\sim$500 MB \\ \hline

\end{tabular}
\caption[Memoria por componente]{Resumen de memoria utilizada por componente, elaboración propia.}
\end{table}

\textbf{Optimizaciones}
\begin{enumerate}
    \item Modelo ligero (MiniLM)
    \begin{itemize}
        \item 384 dimensiones vs 768 (BERT base).
        \item 420 MB vs 800 MB.
        \item Ahorro: 47.5\%.
    \end{itemize}

    \item Embeddings comprimidos
    \begin{itemize}
        \item Formato .npz comprimido.
        \item 50 KB vs $\sim$100 KB sin comprimir.
        \item Ahorro: 50\%.
    \end{itemize}

    \item Garbage collection optimizado
    \begin{verbatim}
    import gc
    gc.collect()  # Después de carga inicial
    \end{verbatim}
\end{enumerate}

{\large \noindent \textbf{Escalabilidad}}\\
\textbf{Escalabilidad horizontal}\\
API stateless permite múltiples instancias:\\

\begin{center}
    \includegraphics[width=0.75\textwidth]{Images/Cap5/2_API_Stateless.png}
    \captionof{figure}[API Stateless]{API Stateless, elaboración propia.} 
\end{center}

\textbf{Configuración}:
\begin{verbatim}
# Instancia 1
uvicorn app.main:app --port 8001 &

# Instancia 2
uvicorn app.main:app --port 8002 &

# Instancia 3
uvicorn app.main:app --port 8003 &

# Load balancer (nginx)
upstream api_servers {
    server localhost:8001;
    server localhost:8002;
    server localhost:8003;
}
\end{verbatim}

\noindent \textbf{Escalabilidad con workers}:
\begin{verbatim}
uvicorn app.main:app \
    --host 0.0.0.0 \
    --port 8000 \
    --workers 4
\end{verbatim}

\textbf{Throughput}:
\begin{itemize}
    \item 1 worker: $\sim$25 req/s.
    \item 4 workers: $\sim$90 req/s (3.6x).
\end{itemize}

\noindent \textbf{Limitaciones}
\begin{itemize}
    \item Modelo en memoria: $\sim$420 MB por worker.
    \item 4 workers: $\sim$1.7 GB memoria.
    \item Máximo recomendado: 8 workers en servidor 8GB RAM.
\end{itemize}

\vspace{1em}

{\Large \noindent \textbf{Resultados y métricas}}\\
{\large \textbf{Métricas de precisión}}\\

\noindent \textbf{Dataset de evaluación}\\
100 queries de prueba en 3 categorías:
\begin{itemize}
    \item 40 queries de emergencias (Grupo A).
    \item 30 queries de saludos (Grupo B).
    \item 30 queries de comunicación (Grupo C).
\end{itemize}

\textbf{Métricas Calculadas}

\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.6}
\begin{tabular}{|p{7cm}|p{3cm}|}
\hline
\textbf{Métrica} & \textbf{Valor} \\ \hline

\textit{Accuracy} (clasificación de grupos) & 92\% \\ \hline
\textit{Precision} (promedio) & 91\% \\ \hline
\textit{Recall} (promedio) & 90\% \\ \hline
\textit{F1-Score} (promedio) & 90.5\% \\ \hline
Similitud promedio (\textit{matches}) & 0.87 \\ \hline

\end{tabular}
\caption[Métricas de precisión]{Resumen de métricas de desempeño del modelo, elaboración propia.}
\end{table}

\textbf{Matriz de confusión}\\
\begin{center}
    \includegraphics[width=0.75\textwidth]{Images/Cap5/3_Matriz_Confusión.png}
    \captionof{figure}[Matriz de Confusión]{Matriz de confusión de cada grupo, elaboración propia.} 
\end{center}

Observaciones:
\begin{itemize}
    \item Grupo A (Emergencias): Mejor precisión (95\%).
    \item Confusión menor entre grupos similares.
    \item Errores en casos ambiguos.
\end{itemize}

{\large \noindent \textbf{Métricas de rendimiento}}\\

\noindent \textbf{Latencia}
\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.6}
\begin{tabular}{|p{5cm}|p{2cm}|p{2.5cm}|p{2cm}|}
\hline
\textbf{Métrica} & \textbf{Min} & \textbf{Promedio} & \textbf{Max} \\ \hline

Latencia (ms) & 35ms & 40ms & 48ms \\ \hline
Latencia P95 (ms) & -- & 45ms & -- \\ \hline
Latencia P99 (ms) & -- & 47ms & -- \\ \hline

\end{tabular}
\caption[Latencias]{Resumen de latencias medidas en entorno de pruebas, elaboración propia.}
\end{table}

\textbf{Objetivo}: <50ms (cumplido).\\

\noindent \textbf{Throughput}
\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.6}
\begin{tabular}{|p{7cm}|p{3cm}|}
\hline
\textbf{Configuración} & \textbf{REQ/s} \\ \hline

\textit{1 worker} (single-core) & 25 req/s \\ \hline
\textit{4 workers} (4-core) & 90 req/s \\ \hline
\textit{8 workers} (8-core) & 160 req/s \\ \hline

\end{tabular}
\caption[Throughput por configuración]{Capacidad de procesamiento según número de workers, elaboración propia.}
\end{table}

\textbf{Objetivo}: >20 req/s (cumplido).

\noindent \textbf{Memoria}
\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.6}
\begin{tabular}{|p{6cm}|p{3.5cm}|}
\hline
\textbf{Métrica} & \textbf{Valor} \\ \hline

Memoria base (\textit{startup}) & $\sim$500 MB \\ \hline
Memoria por \textit{request} & +2 MB \\ \hline
Memoria después de 1000 requests & $\sim$520 MB \\ \hline
Crecimiento & Estable \\ \hline

\end{tabular}
\caption[Memoria]{Consumo de memoria durante operación, elaboración propia.}
\end{table}

Sin memory leaks detectados.\\

{\large \noindent \textbf{Métricas de usabilidad}}\\

\textbf{Swagger UI}
\begin{itemize}[label= \checkmark]
    \item Documentación automática.
    \item Testing interactivo.
    \item Ejemplos de requests.
    \item Schemas completos.
    \item Respuestas de error documentadas.
\end{itemize}

\textbf{API Consistency}
\begin{itemize}[label= \checkmark]
    \item Formato JSON consistente.
    \item Campos opcionales claramente marcados.
    \item Validación automática de requests.
    \item Mensajes de error descriptivos.
    \item HTTP status codes apropiados.
\end{itemize}

\vspace{1em}

{\large \noindent \textbf{Comparación con alternativas}}\\

\textbf{Ventajas del prototipo}
\begin{itemize}[label= \checkmark]
    \item Mayor precisión (92\% vs 60--75\%).
    \item Manejo de paráfrasis.
    \item Detección de nombres propios.
    \item Sistema de deletreo automático.
    \item API bien documentada.
    \item Tests exhaustivos.
    \item Fácil de escalar.
\end{itemize}

\vspace{0.7em}

\textbf{Desventajas}
\begin{itemize}
    \item Mayor latencia (40ms vs 5--25ms)
    \item Mayor uso de memoria ($\sim$500MB vs 50--200MB)
    \item Requiere modelo pre-entrenado
\end{itemize}
