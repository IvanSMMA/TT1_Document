\chapter{Introducción}
\label{sec:Intro}

\section{Motivación}
En México la comunicación es un derecho fundamental para todas las personas, ya que mediante ella se pueden establecer vínculos, expresar necesidades e intercambiar información y pensamientos. Sin embargo, las personas de la comunidad sorda enfrentan barreras para poder comunicarse de manera efectiva. \\

Si bien la Lengua de Señas Mexicana (LSM) es el principal medio de comunicación para las personas con discapacidad auditiva en México, ya sea en interacciones cotidianas o en situaciones de emergencia, las personas dependen de soluciones tecnológicas para poder comunicarse. \\

Existen herramientas digitales (ver \autoref{sec:edoArte}) que permiten la traducción de español a Lenguas de Señas, pero en su mayoría son interpretes de Lenguas de Señas de otros países (como el de España, Brasil y Estados Unidos), los cuales en algunos casos presentan imprecisiones o incompatibilidad debido a las versiones de los sistemas operativos empleados. En el caso de las herramientas que emplean animaciones 3D, las mismas se muestran fragmentadas, causando que se dificulte la comprensión de los mensajes.\\

La motivación de este Trabajo Terminal es ayudar a mejorar la accesibilidad de las personas sordas, a la par que se fomenta la inclusión social y tecnológica para esta comunidad, empleando técnicas de Inteligencia Artificial, Procesamiento de Lenguaje Natural y Modelado 3D para obtener una traducción más fluida y natural, basándose en las Heurísticas de Usabilidad de Nielsen y la norma ISO 9241-210.\\


\newpage
\section{Problemática}
La comunicación es una habilidad fundamental que permite a los seres humanos poder interactuar con su entorno y compartir ideas a través de un sistema de símbolos \cite{ref1}. No obstante, a menudo existen barreras en la comunicación que limitan el acceso a la información y dificultan la capacidad de las personas para poder expresarse y comunicarse \cite{ref2}. \\

A pesar de las barreras, las personas sordas han desarrollado su propio medio de comunicación que les permite superar las limitaciones fisiológicas y establecer una conexión efectiva con quienes comparten este lenguaje. En el caso de México, la LSM es el principal medio de comunicación para las personas sordas en el país, con un estimado de 2.3 millones personas que padecen de esta discapacidad \cite{ref3}, lo que evidencia la magnitud de la población que depende de este lenguaje para poder llevar a cabo el proceso de comunicación. Esta lengua posee su propia sintaxis, gramática, léxico y está compuesta por una combinación de señas, expresiones faciales y movimientos corporales que permiten transmitir ideas, mensajes, emociones y sentimientos \cite{ref4}.\\

La Ley General para la Inclusión de las Personas con Discapacidad establece que los medios de comunicación deben implementar tecnologías o intérpretes de Lengua de Señas Mexicana para facilitar el acceso a contenido para la comunidad sorda \cite{ref4}. En este contexto, las ciencias de la computación enfrentan un reto importante en cuanto a la creación de recursos digitales que respondan a estas necesidades específicas de accesibilidad e inclusión, concretamente en tareas de procesamiento de lenguaje y traducción automática.\\

Actualmente existen diversos proyectos relacionados con la traducción de Lengua de Señas, sin embargo, la mayoría presentan limitaciones significativas. Una de las principales dificultades es la falta de fluidez en las animaciones de la traducción del español a Lengua de Señas, ya que los traductores actuales no logran representar el lenguaje de señas de manera continua. Como resultado, las animaciones suelen presentar cortes entre palabras o frases, lo que resulta en una traducción fragmentada y poco natural.\\

Estas deficiencias dificultan la comprensión de los mensajes por parte de los usuarios, ya que la secuencia de señas no se presenta con la fluidez y precisión necesarias para lograr una comunicación efectiva. Además, algunos de estos proyectos están orientados a Lenguas de Señas de otros países y fueron desarrollados para versiones antiguas de Android, por lo que no son compatibles con las versiones más recientes del sistema operativo (ver \autoref{sec:edoArte}).

\section{Objetivos}
\subsection{Objetivo General}
Desarrollar un prototipo de aplicación móvil en Android que, utilizando técnicas de Procesamiento de Lenguaje Natural (PLN) y Modelado 3D, traduzca oraciones específicas empleadas en situaciones de emergencia, así como expresiones cotidianas como saludos y agradecimientos, del español a la Lengua de Señas Mexicana (LSM).

\subsection{Objetivo Especifícos}
\begin{itemize}
    \item Desarrollar el módulo de procesamiento de texto mediante técnicas de PLN, para interpretar oraciones específicas en español y transformarlas en sentencias manipulables para la traducción a la Lengua de Señas Mexicana (LSM).
    \item Construir un módulo de animación 3D que represente visualmente las señas en LSM, a partir de las oraciones procesadas.
    \item Implementar el módulo de animación 3D utilizando Inteligencia Artificial (IA), buscando obtener una representación fluida de la Lengua de Señas en los avatares.
    \item Crear una aplicación móvil en Android, versión 14, que integre los módulos de PLN, módulo de generación de animaciones 3D y transiciones fluidas entre los componentes del prototipo.
    \item Validar la funcionalidad y usabilidad de la aplicación móvil mediante pruebas con personas con discapacidad auditiva y personas oyentes, en escenarios simulados de emergencia.
\end{itemize}

\section{Alcance}
\subsection{Alcance General}
El Trabajo Terminal consiste en el desarrollo de un prototipo de aplicación móvil que traduzca frases de español a LSM mediante animaciones 3D. La aplicación tendrá un conjunto predefinido de frases comunes para saludos, agradecimientos y situaciones de emergencia. En caso de no contar con una frase específica, se empleará la dactilología (representación de las letras de una palabra empleando las manos) para poder garantizar la comunicación.

\subsection{Alcance Especifíco}
Se hará uso de una interfaz de usuario simple e intuitiva, basándose en las Heurísticas de Usabilidad de Nielsen y la norma ISO 9241-210, que sea de utilidad para la población objetivo. Mediante técnicas de Procesamiento de Lenguaje Natural (PLN) se pretende hacer un procesamiento del dataset que contiene las frases en español, para posteriormente realizar el modelado de las animaciones 3D empleando Mediapipe; dichas animaciones serán fluidas para mostrar una comunicación natural y fácil de entender.

\subsection{Delimitación}
Es importante aclarar que la traducción será únicamente de un canal de comunicación: de español a LSM. Lo anterior por la razón de que la traducción de LSM a español es más compleja por las diferencias estructurales y gramaticales entre ambos lenguajes.\\

Dado que la Lengua de Señas Mexicana (LSM) es una lengua viva y en constante evolución, en el presente trabajo se emplea como referencia la versión correspondiente al uso y documentación vigente durante el año 2024. Esto incluye señas reconocidas por la comunidad sorda mexicana y recursos de enseñanza y divulgación disponibles en ese periodo, tales como diccionarios digitales, materiales educativos y registros videográficos oficiales. Esta aclaración permite contextualizar los elementos lingüísticos empleados, considerando que la LSM puede presentar cambios o incorporaciones en años posteriores.

\section{Justificación}
En México la comunicación inclusiva es un reto para las personas con discapacidad auditiva, debido a que la mayoría de la población no conoce la Lengua de Señas Mexicana (LSM), lo que condiciona a la comunidad sorda para poder expresar sus ideas y pensamientos, acceder a servicios esenciales o recibir apoyo en situaciones de emergencia. Pese a que ha habido avances tecnológicos a lo largo de los últimos años, las herramientas de traducción de español a LSM existentes presentan limitaciones, siendo las más importantes la falta de fluidez en las animaciones y la incompatibilidad entre versiones del sistema operativo de Android. \\

Este Trabajo Terminal busca desarrollar un prototipo de aplicación móvil que traduzca frases en español a LSM con animaciones en 3D fluidas, empleando técnicas de PLN y modelado 3D. Al mejorar la calidad de la comunicación entre personas oyentes y personas con discapacidad auditiva, se contribuye a la accesibilidad, a eliminar barreras de comunicación y fomentar la comunicación inclusiva.\\

\newpage

Se espera que este desarrollo sirva de referencia para sentar las bases de futuras investigaciones relacionadas a la traducción e interpretación de lenguas de señas empleando técnicas de Inteligencia Artificial (IA).\\

\section{Propuesta de solución}
Este proyecto consiste en desarrollar un prototipo que aborde las cuestiones planteadas en el apartado de la problemática, con un enfoque en mejorar la fluidez y precisión de las animaciones de LSM mediante el uso de la Inteligencia Artificial. La aplicación busca facilitar la interacción entre personas oyentes y personas con discapacidad auditiva, integrando técnicas de Procesamiento de Lenguaje Natural y modelado 3D.\\

El traductor estará enfocado en un conjunto limitado de frases predefinidas, como expresiones de emergencia, saludos y agradecimientos. En caso de no encontrar la frase deseada, el sistema utilizará el alfabeto dactilológico de LSM para deletrear la palabra o frase, asegurando siempre una respuesta en la comunicación.\\

El uso de aplicaciones de Procesamiento de Lenguaje Natural (PLN) es fundamental para el procesamiento del español a LSM, ya que permitirá que el sistema no solo reconozca palabras aisladas, sino también frases y oraciones completas, adaptando la traducción al contexto y mejorando la comunicación en situaciones más complejas.\\

El prototipo estará diseñado para la última versión de Android, Android 14, debido a que este es el sistema operativo más utilizado en México \cite{ref5}, por lo que la solución propuesta tendrá un mayor alcance y beneficiará a una mayor cantidad de usuarios. De acuerdo con el Instituto Federal de Telecomunicaciones (IFT), el sistema operativo más utilizado por las personas en México es Android con 84.6\%, en comparación con iOS que es utilizado por el 6.8\% \cite{ref6}.\\

Para el desarrollo del prototipo se utilizará Media Pipe \cite{ref7}, una biblioteca eficiente para procesamiento de gestos y movimientos corporales, ideal para capturar de manera precisa los gestos de la Lengua de Señas Mexicana. Esto permitirá obtener datos precisos de las señas, garantizando una traducción más confiable y fluida, mientras se mantiene un rendimiento óptimo incluso en dispositivos de gama media.\\

Finalmente, se busca crear representaciones visuales en 3D para poder facilitar la visualización de señas. Las personas con discapacidad auditiva podrán visualizar una animación asociada a una de las frases que están incluidas dentro del prototipo.

\textbf{Productos Esperados}
\begin{itemize}
    \item Dataset normalizado de LSM.
    \item Set de animaciones con avatares 3D fluidos e interactivos.
    \item Aplicación móvil en Android.
    \item Documentación del sistema.\\
\end{itemize}

\begin{center}
    \includegraphics[width=0.8\textwidth]{Images/Cap 1/diacajanegra.png}
    \captionof{figure}[Diagrama de contexto de la App]{Diagrama de contexto de la App, elaboración propia.}
\end{center}

\newpage
\section{Estado del arte}
\label{sec:edoArte}
Se han realizado diversas investigaciones referentes a la problemática de la comunicación entre personas oyentes y personas con discapacidad auditiva. En algunos trabajos, se han desarrollado sistemas de software que emplean diferentes tecnologías y herramientas, destacando principalmente las técnicas de Procesamiento de Lenguaje Natural (PLN), \textit{Computer Vision}, Modelado 3D y técnicas de Inteligencia Artificial. A continuación, se describen los trabajos relacionados: \begin{itemize}
    \item \textbf{\textit{Translation of Spanish Text to Mexican Sign Language Glossed Text Using Rules and Deep Learning}}: en este trabajo se presenta una arquitectura para traducir de español a Lengua de Señas Mexicana (LSM), cuyos resultados fueron evaluados con las métricas BLEU y WER. En este artículo se encontró que la traducción con técnicas tradicionales tiene un mejor desempeño que el aprendizaje profundo \cite{ref8}.
    \item \textbf{\textit{Resource Creation for Automatic Translation System from Texts in Spanish into Mexican Sign Language}}: este artículo presenta la creación de recursos lingüísticos para la traducción automática del español escrito a LSM, así como el sistema que la implementa. En colaboración con la Casa de la Cultura de los Sordos (CDMX), se tradujeron 150 oraciones pertenecientes a 13 estructuras gramaticales reconocidas por el sistema, identificando 100 signos que pueden representar una oración completa. Se observó que, ante la falta de un signo específico, las personas sordas tienden a deletrear la palabra. El sistema traduce de forma literal al buscar y reproducir palabras en su base de datos, además de contar con signos que representan expresiones completas \cite{ref9}.
    \item \textbf{Aplicación “Voz y Señas”}: esta aplicación, desarrollada para el Sistema Operativo Android 7.0 por el Instituto de Pedagogia en conjunto con TecnoPrótesis y Bienestar Incluyente A.C., permite traducir la LSM por medio del habla o escribiendo texto. Sus objetivos son favorecer la comunicación entre una persona sorda y una persona oyente, y ser una herramienta auxiliar en los procesos de alfabetización, redacción de textos y comprensión lectora \cite{ref10}. 
    \item \textbf{Hetah}: servicio en línea que funciona como traductor de Lengua de Señas Colombiana (LSC), que permite la comunicación entre personas oyentes y personas con discapacidad auditiva mediante un Avatar 3D. Se debe ingresar la frase que se desea traducir y posteriormente, el avatar realizará la traducción mediante gestos \cite{ref11}. 
    \item \textbf{\textit{Hand Talk}}: consiste en una aplicación móvil que traduce lenguajes orales, tanto en texto como en audio, a lenguas de señas como la Lengua de Señas Americana (ASL) o la Lengua de Señas Brasileña (LIBRAS), mediante un avatar 3D que es impulsado por IA. Tiene por objetivo facilitar el proceso de comunicación entre personas oyentes y sordas \cite{ref12}. 
    \item \textbf{\textit{Sign4ALL}}: es una aplicación móvil que es capaz de traducir señas, capaz de reconocer e interpretar el alfabeto de la lengua de señas española (LSE), desarrollada por la Universidad de Alicante. Mediante técnicas de Deep Learning y Visión Artificial, la aplicación captura e interpreta signos de los brazos y las manos, para traducirlos al idioma español castellano, obteniendo una precisión del 80\% \cite{ref13}.
    \item \textbf{\textit{SignAloud}}: sistema de Inteligencia Artificial que emplea guantes capaces de reconocer gestos de las manos correspondientes a palabras y frases en Lenguaje de Señas Americana. Dichos guantes contienen sensores que registran la posición y el movimiento de las manos, para generar datos que son enviados de forma inalámbrica a una computadora central. La computadora analiza los datos de los gestos empleando redes neuronales, y si los datos coinciden con un gesto, la palabra o frase asociada se pronuncia en un altavoz \cite{ref14}.
    \item \textbf{Sistema traductor de la Lengua de Señas Mexicana mediante dactilología y de español a español signado}: sistema de Inteligencia Artificial capaz de ayudar a entablar un diálogo entre una persona sorda y otra oyente, mediante la traducción de las señas de dactilología a texto plano en español y de forma análoga, la traducción del texto plano a español a español signado \cite{ref15}.
\end{itemize}

Los estudios analizados anteriormente indican que ya habido trabajos que han intentado auxiliar el proceso de comunicación entre una persona oyente y una persona sorda, aunque en su mayorían han sido a lenguas de señas de otros países como lo son la Lengua de Señas Colombiana (LSC), la Lengua de Señas Española (LSE), la Lengua de Señas Americana (ASL) y la Lengua de Señas Brasileña (LIBRAS). El enfoque del prototipo propuesto en el presente Trabajo Terminal es la Lengua de Señas Mexicana (LSM), empleando técnicas de IA, PLN y Modelado 3D para crear animaciones optimizadas que permitan establecer comunicación entre personas oyentes y personas con discapacidad auditiva. \\

\newpage
La siguiente tabla muestra una comparación detallada entre los proyectos descritos anteriormente y el proyecto propuesto, tomando en cuenta los siguientes parámetros: \textbf{A)} Análisis textual PLN, \textbf{B)} \textit{Computer Vision}, \textbf{C)} Sistema Experto, \textbf{D)} IA Generativa, \textbf{E)} \textit{Deep Learning}, \textbf{F)} Respuesta Gráfica (P. ej. Avatar), \textbf{G)} Animación Fluida (sin cortes), \textbf{H)} Uso de Hardware, \textbf{I)} Audio (\textit{IN/OUT}).

\begin{table}[H]
    \centering
    \begin{tabular}{|p{6cm}|p{0.5cm}|p{0.5cm}|p{0.5cm}|p{0.5cm}|p{0.5cm}|p{0.5cm}|p{0.5cm}|p{0.5cm}|p{0.5cm}|}
        \hline
        \textbf{Proyecto} & \textbf{A} & \textbf{B} & \textbf{C} & \textbf{D} & \textbf{E} & \textbf{F} & \textbf{G} & \textbf{H} & \textbf{I}\\
        \hline
        \textit{Translation of Spanish Text to Mexican Sign Language Glossed Text Using Rules and Deep Learning} & X &  & X &  &  &  &  &  &\\
        \hline
        \textit{Resource Creation for Automatic Translation System from Texts in Spanish into Mexican Sign Language} & X &  & X &  &  &  &  &  &\\
        \hline
        Aplicación “Voz y Señas” & X &  & X &  &  &  &  &  &\\
        \hline
        Hetah & X &  & X &  &  & X &  &  &\\
        \hline
        \textit{Hand Talk} &  & X &  &  & X & X &  &  & X\\
        \hline
        \textit{Sign4ALL} &  & X &  &  & X & X &  &  & X\\
        \hline
        \textit{SignAloud} &  &  &  &  &  &  &  & X & \\
        \hline
        Sistema traductor de la Lengua de Señas Mexicana mediante dactilología y de español a español signado & X & X &  & X &  &  &  &  & \\
        \hline
        Prototipo de aplicación móvil de apoyo para la traducción de español a Lengua de Señas Mexicana (LSM), empleando técnicas de Procesamiento de Lenguaje Natural (PLN) y Modelado 3D (Proyecto Propuesto) & X &  &  & X & X & X & X &  & \\
        \hline
    \end{tabular}
    \caption[Tabla comparativa entre investigaciones]{Tabla comparativa entre investigaciones, elaboración propia.}
    \label{tabla:edo_arte}
\end{table}

\newpage
\section{Metodología}
El proyecto se desarrollará bajo la metodología Scrum, un marco de trabajo ágil que organiza la colaboración del equipo a través de roles, artefactos y reglas que garantizan su correcta implementación \cite{ref16}\cite{ref17}. Uno de sus principios clave es la configuración de equipos autogestionados y multifuncionales, lo que permite tomar decisiones autónomas sin depender de directrices externas \cite{ref17}.\\

La estructura de Scrum se basa en ciclos iterativos llamados Sprints, en los cuales se genera un incremento funcional del producto. Cada Sprint se gestiona como un proyecto independiente con objetivos específicos \cite{ref17}. Además, estos ciclos incluyen cinco elementos clave: reunión de planeación, \textit{Daily Scrum}, trabajo de desarrollo, revisión del Sprint y retrospectiva del Sprint, asegurando así una mejora continua en cada iteración. Para este desarrollo, los Sprints tendrán una duración de entre dos y cuatro semanas, lo que facilitará una transición progresiva hacia esta metodología y garantizará un avance constante.\\

Otro punto a destacar es que Scrum define tres roles esenciales. En primer lugar, el \textit{Scrum Master} guía la implementación de la metodología y facilita la resolución de impedimentos sin gestionar directamente el desarrollo \cite{ref18}. En segundo lugar, el \textit{Product Owner} representa a los interesados y gestiona el \textit{Product Backlog}, priorizando las funcionalidades para maximizar el valor del producto \cite{ref18}. Por último, el equipo de desarrollo transforma estos requerimientos en incrementos funcionales, operando sin jerarquías y con un tamaño ideal de tres a nueve integrantes \cite{ref18}.\\

En este proyecto, el equipo se encargará tanto del desarrollo técnico como de la gestión ágil del producto, transformando los requerimientos en incrementos funcionales. La estructura del equipo se distribuye en tres áreas especializadas: Juan Martin Juárez Solano, quien funge como desarrollador de Procesamiento de Lenguaje Natural (PLN) y \textit{Product Owner}, será responsable de implementar el procesamiento del lenguaje, adaptar las frases al contexto de la Lengua de Señas Mexicana (LSM) y optimizar la comunicación con los módulos de animación. Ivan Emiliano Sánchez Mancilla, desarrollador de Android y \textit{Scrum Master}, estará a cargo de estructurar la aplicación, desarrollar interfaces y conectar los distintos módulos. Sergio Ulises Rojas Alarcon, por su parte, será el responsable del desarrollo de animaciones 3D con MediaPipe, diseñando avatares e implementando los gestos. Los directores del Trabajo Terminal asumen el rol de clientes, proporcionando requerimientos y validando los entregables del equipo.\\

Esta distribución permitirá aplicar Scrum de manera eficiente, asegurando un desarrollo iterativo y coordinado, en el que cada integrante contribuirá activamente al avance del proyecto mediante la integración de sus respectivas áreas.

\begin{center}
	\makebox[\textwidth]{%
		\includegraphics[width=1\textwidth]{Images/Cap 1/metoscrum.jpg}
	}
    \captionof{figure}[Metodología Scrum]{Metodología Scrum, obtenido de \cite{ref19}.}  % Pie de foto manual
\end{center}