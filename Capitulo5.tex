\chapter{Pruebas}
\section{Pruebas del Modulo del Procesamiento de Lenguaje Natural (PLN)}

\section{Etapa 4: Sistema de testing y calidad}

\subsection{Metodología de testing}

La estrategia se basa en la pirámide de testing:

\begin{enumerate}
    \item Gran número de tests unitarios (rápidos, precisos).
    \item Menor número de tests de integración.
    \item Pocos tests de extremo a extremo (E2E).
\end{enumerate}

\noindent \textbf{Herramientas utilizadas:}
\begin{itemize}
    \item \textbf{pytest}: Framework principal de testing.
    \item \textbf{pytest-cov}: Reportes de cobertura.
    \item \textbf{pytest-benchmark}: Medición de rendimiento.
    \item \textbf{httpx}: Cliente HTTP para probar la API.
\end{itemize}

\subsection{Tests unitarios}

Los tests cubren distintas partes del sistema:

\begin{itemize}
    \item Preprocesamiento (\texttt{test\_preprocess.py})
    \item Lógica del matcher (\texttt{test\_matcher.py})
    \item Total: 84 tests unitarios
\end{itemize}

Ejemplo de test para normalización:
\begin{lstlisting}
def test_normalize_text():
    assert normalize_text("HOLA") == "hola"
    assert normalize_text("José") == "jose"
    assert normalize_text("¿Qué?") == "que"
\end{lstlisting}

Ejemplo para detección de nombres:
\begin{lstlisting}
def test_detect_nombre_comun():
    result = matcher.search_similar_phrase("Juan")
    assert result['deletreo_activado'] == True
    assert 'J' in result['deletreo']
\end{lstlisting}

\subsection{Tests de integración}

Se implementaron 24 tests de integración.

Ejemplo de prueba del endpoint \texttt{/buscar}:
\begin{lstlisting}
@pytest.mark.asyncio
async def test_buscar_endpoint(client):
    response = await client.post("/buscar", json={"texto": "hola"})
    assert response.status_code == 200
    data = response.json()
    assert data['grupo'] == "B"
    assert "hola" in data['frase_similar'].lower()
\end{lstlisting}

\subsection{Tests End-to-End}

Las pruebas de extremo a extremo se ejecutaron para validar el comportamiento del sistema en escenarios reales, incluyendo errores de usuario, variaciones de entrada y casos límite.

\noindent\textbf{Cobertura de casos:}
\begin{itemize}
    \item Errores de tipeo comunes (5 tests)
    \item Leet speak y caracteres especiales (5 tests)
    \item Nombres propios (7 tests)
    \item Capitalización variada (3 tests)
    \item Puntuación incorrecta (4 tests)
    \item Casos de deletreo (4 tests)
    \item Casos complejos (4 tests)
    \item Rendimiento de deletreo (2 tests)
    \item Consistencia de respuestas (2 tests)
\end{itemize}

\noindent\textbf{Totales:} 64 tests ejecutados y 64 aprobados (100\% de éxito).

\subsection{Tests de rendimiento}

Los benchmarks de latencia se realizaron utilizando \texttt{pytest-benchmark}:

\begin{lstlisting}
def test_single_query_latency(benchmark, matcher):
    result = benchmark(matcher.search_similar_phrase, "hola")
    # P50 < 50ms, P95 < 100ms
\end{lstlisting}

\noindent\textbf{Resultados:}
\begin{itemize}
    \item Inicialización con caché: 1.37ms
    \item Latencia por consulta (P50): 42ms
    \item Throughput sostenido: 25 qps
\end{itemize}

\subsection{Cobertura de código}

\noindent\textbf{Desglose por módulo:}
\begin{itemize}
    \item \texttt{preprocess.py}: 94\%
    \item \texttt{matcher\_improved.py}: 78\%
    \item \texttt{main.py}: 74\%
    \item \texttt{groups.py}: 59\%
    \item \textbf{Total general}: 62\%
\end{itemize}

\noindent La meta definida para módulos críticos (> 70\%) fue alcanzada exitosamente.

\subsection{Resultados globales de testing}

\noindent\textbf{Resumen estadístico:}
\begin{itemize}
    \item Tests totales: 204
    \item Aprobados: 191 (93.6\%)
    \item Fallidos: 13 (6.4\%)
    \item Duración total: 147 segundos
    \item Cobertura total: 62\%
\end{itemize}

\noindent\textbf{Interpretación:}
\begin{itemize}
    \item El sistema se encuentra en estado \textit{production-ready}.
    \item Los 13 fallos corresponden a casos menores no bloqueantes.
    \item La cobertura alcanzada es adecuada para los componentes clave.
\end{itemize}

\subsection{Optimizaciones y rendimiento}

\subsubsection{Caché de Embeddings}

\noindent\textbf{Problema:} Generar embeddings desde cero tiene un costo aproximado de 2000ms.

\noindent\textbf{Solución:} Almacenar embeddings precalculados en disco en formato \texttt{NPZ} comprimido.

\begin{lstlisting}
if cache_file.exists():
    embeddings_dict = np.load(cache_file)  # 1.37ms
else:
    embeddings_dict = self._compute_embeddings()  # ~2000ms
    np.savez_compressed(cache_file, **embeddings_dict)
\end{lstlisting}

\noindent\textbf{Ganancias obtenidas:}
\begin{itemize}
    \item Inicialización: 2000ms $\rightarrow$ 1.37ms (1460x más rápido)
    \item Tamaño en disco: 600KB $\rightarrow$ 61KB (reducción del 90\%)
\end{itemize}

\subsubsection{Búsqueda jerárquica por centroides}

\noindent\textbf{Problema:} La búsqueda lineal no escala adecuadamente con un número grande de frases.

\noindent\textbf{Solución:} Implementar una búsqueda de dos fases: comparación con centroides y luego búsqueda fina dentro del grupo.

\noindent\textbf{Beneficios:}
\begin{itemize}
    \item Comparaciones reducidas: 43 $\rightarrow$ 17 (60\% menos)
    \item Complejidad: $O(N) \rightarrow O(k + N/k)$
\end{itemize}

\subsubsection{Optimización de latencia}

\noindent\textbf{Técnicas aplicadas:}
\begin{enumerate}
    \item Caché de embeddings (1460x más rápido)
    \item Normalización de embeddings (producto punto en vez de coseno)
    \item Búsqueda jerárquica (reducción del 60\% en comparaciones)
    \item Uso de modelo compacto MiniLM en lugar de BERT-large
\end{enumerate}

\noindent\textbf{Resultados:}
\begin{itemize}
    \item P50: 42ms \checkmark \; (objetivo < 50ms)
    \item P95: 50ms \checkmark \; (objetivo < 100ms)
\end{itemize}

\subsection{Gestión de memoria}

\noindent\textbf{Distribución de uso:}
\begin{itemize}
    \item Modelo: $\sim$120MB
    \item Caché de embeddings: $\sim$61KB
    \item Runtime de Python: $\sim$30MB
    \item \textbf{Uso total}: $\sim$150MB
\end{itemize}

El sistema no presenta fugas de memoria y mantiene un uso estable bajo carga.

\subsection{Escalabilidad}

\noindent\textbf{Escalabilidad vertical:}
\begin{itemize}
    \item La latencia mejora proporcionalmente con más núcleos de CPU.
    \item La RAM adicional aporta poco beneficio, salvo para el modelo.
\end{itemize}

\noindent\textbf{Escalabilidad horizontal:}
\begin{itemize}
    \item El sistema es completamente \textit{stateless}, lo cual facilita su replicación.
    \item Compatible con balanceadores de carga como NGINX o HAProxy.
\end{itemize}

\noindent\textbf{Límites actuales:}
\begin{itemize}
    \item CPU-bound: la RAM no mejora el desempeño.
    \item Single-threaded por request.
    \item Mejor enfoque: múltiples instancias + balanceo.
\end{itemize}
